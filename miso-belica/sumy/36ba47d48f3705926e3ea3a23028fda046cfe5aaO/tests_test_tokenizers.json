[{"lineNumber": 11, "col_offset": 20, "nodeName": "TestCase", "type": "Type[unittest.TestCase]"}, {"lineNumber": 12, "col_offset": 4, "nodeName": "test_missing_language", "type": "Callable[[Any], Any]"}, {"lineNumber": 15, "col_offset": 4, "nodeName": "test_ensure_czech_tokenizer_available", "type": "Callable[[Any], Any]"}, {"lineNumber": 31, "col_offset": 4, "nodeName": "test_language_getter", "type": "Callable[[Any], Any]"}, {"lineNumber": 35, "col_offset": 4, "nodeName": "test_tokenize_sentence", "type": "Callable[[Any], Any]"}, {"lineNumber": 45, "col_offset": 4, "nodeName": "test_tokenize_sentences_with_abbreviations", "type": "Callable[[Any], Any]"}, {"lineNumber": 52, "col_offset": 4, "nodeName": "test_tokenize_paragraph", "type": "Callable[[Any], Any]"}, {"lineNumber": 68, "col_offset": 4, "nodeName": "test_slovak_alias_into_czech_tokenizer", "type": "Callable[[Any], Any]"}, {"lineNumber": 86, "col_offset": 4, "nodeName": "test_tokenize_japanese_sentence", "type": "Callable[[Any], Any]"}, {"lineNumber": 94, "col_offset": 4, "nodeName": "test_tokenize_japanese_paragraph", "type": "Callable[[Any], Any]"}, {"lineNumber": 11, "col_offset": 20, "nodeName": "unittest", "type": "module"}, {"lineNumber": 16, "col_offset": 8, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 32, "col_offset": 8, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 36, "col_offset": 8, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "words", "type": "Tuple[Any, ...]"}, {"lineNumber": 46, "col_offset": 8, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 47, "col_offset": 8, "nodeName": "sentences", "type": "Tuple[Any, ...]"}, {"lineNumber": 49, "col_offset": 8, "nodeName": "expected", "type": "Tuple[unicode, unicode]"}, {"lineNumber": 53, "col_offset": 8, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 69, "col_offset": 8, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 87, "col_offset": 8, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 90, "col_offset": 8, "nodeName": "sentence", "type": "unicode"}, {"lineNumber": 91, "col_offset": 8, "nodeName": "expected", "type": "Tuple[unicode, unicode, unicode, unicode, unicode, unicode, unicode, unicode]"}, {"lineNumber": 95, "col_offset": 8, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 101, "col_offset": 8, "nodeName": "paragraph", "type": "unicode"}, {"lineNumber": 13, "col_offset": 8, "nodeName": "assertRaises", "type": "Callable"}, {"lineNumber": 13, "col_offset": 26, "nodeName": "LookupError", "type": "Type[LookupError]"}, {"lineNumber": 13, "col_offset": 39, "nodeName": "Tokenizer", "type": "Type[sumy.nlp.tokenizers.Tokenizer]"}, {"lineNumber": 16, "col_offset": 20, "nodeName": "Tokenizer", "type": "Type[sumy.nlp.tokenizers.Tokenizer]"}, {"lineNumber": 17, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 17, "col_offset": 34, "nodeName": "language", "type": "Any"}, {"lineNumber": 19, "col_offset": 20, "nodeName": "to_sentences", "type": "Callable[[Any], Tuple[Any, ...]]"}, {"lineNumber": 29, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 29, "col_offset": 25, "nodeName": "expected", "type": "Tuple[unicode, unicode, unicode]"}, {"lineNumber": 29, "col_offset": 35, "nodeName": "sentences", "type": "Tuple[Any, ...]"}, {"lineNumber": 32, "col_offset": 20, "nodeName": "Tokenizer", "type": "Type[sumy.nlp.tokenizers.Tokenizer]"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 33, "col_offset": 36, "nodeName": "language", "type": "Any"}, {"lineNumber": 36, "col_offset": 20, "nodeName": "Tokenizer", "type": "Type[sumy.nlp.tokenizers.Tokenizer]"}, {"lineNumber": 37, "col_offset": 16, "nodeName": "to_words", "type": "Callable[[Any], Tuple[Any, ...]]"}, {"lineNumber": 43, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 43, "col_offset": 25, "nodeName": "expected", "type": "Tuple[unicode, unicode, unicode, unicode, unicode, unicode, unicode, unicode]"}, {"lineNumber": 43, "col_offset": 35, "nodeName": "words", "type": "Tuple[Any, ...]"}, {"lineNumber": 46, "col_offset": 20, "nodeName": "Tokenizer", "type": "Type[sumy.nlp.tokenizers.Tokenizer]"}, {"lineNumber": 47, "col_offset": 20, "nodeName": "to_sentences", "type": "Callable[[Any], Tuple[Any, ...]]"}, {"lineNumber": 50, "col_offset": 15, "nodeName": "expected", "type": "Tuple[unicode, unicode]"}, {"lineNumber": 50, "col_offset": 27, "nodeName": "sentences", "type": "Tuple[Any, ...]"}, {"lineNumber": 53, "col_offset": 20, "nodeName": "Tokenizer", "type": "Type[sumy.nlp.tokenizers.Tokenizer]"}, {"lineNumber": 54, "col_offset": 20, "nodeName": "to_sentences", "type": "Callable[[Any], Tuple[Any, ...]]"}, {"lineNumber": 66, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 66, "col_offset": 25, "nodeName": "expected", "type": "Tuple[unicode, unicode, unicode, unicode]"}, {"lineNumber": 66, "col_offset": 35, "nodeName": "sentences", "type": "Tuple[Any, ...]"}, {"lineNumber": 69, "col_offset": 20, "nodeName": "Tokenizer", "type": "Type[sumy.nlp.tokenizers.Tokenizer]"}, {"lineNumber": 70, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 70, "col_offset": 25, "nodeName": "language", "type": "Any"}, {"lineNumber": 72, "col_offset": 20, "nodeName": "to_sentences", "type": "Callable[[Any], Tuple[Any, ...]]"}, {"lineNumber": 84, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 84, "col_offset": 25, "nodeName": "expected", "type": "Tuple[unicode, unicode, unicode, unicode]"}, {"lineNumber": 84, "col_offset": 35, "nodeName": "sentences", "type": "Tuple[Any, ...]"}, {"lineNumber": 87, "col_offset": 20, "nodeName": "Tokenizer", "type": "Type[sumy.nlp.tokenizers.Tokenizer]"}, {"lineNumber": 88, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 88, "col_offset": 25, "nodeName": "language", "type": "Any"}, {"lineNumber": 92, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 92, "col_offset": 25, "nodeName": "expected", "type": "Tuple[unicode, unicode, unicode, unicode, unicode, unicode, unicode, unicode]"}, {"lineNumber": 95, "col_offset": 20, "nodeName": "Tokenizer", "type": "Type[sumy.nlp.tokenizers.Tokenizer]"}, {"lineNumber": 102, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 102, "col_offset": 25, "nodeName": "expected", "type": "Tuple[unicode, unicode, unicode]"}, {"lineNumber": 13, "col_offset": 8, "nodeName": "self", "type": "TestTokenizer"}, {"lineNumber": 17, "col_offset": 8, "nodeName": "self", "type": "TestTokenizer"}, {"lineNumber": 17, "col_offset": 34, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 19, "col_offset": 20, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 29, "col_offset": 8, "nodeName": "self", "type": "TestTokenizer"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "self", "type": "TestTokenizer"}, {"lineNumber": 33, "col_offset": 36, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 37, "col_offset": 16, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 43, "col_offset": 8, "nodeName": "self", "type": "TestTokenizer"}, {"lineNumber": 47, "col_offset": 20, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 54, "col_offset": 20, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 66, "col_offset": 8, "nodeName": "self", "type": "TestTokenizer"}, {"lineNumber": 70, "col_offset": 8, "nodeName": "self", "type": "TestTokenizer"}, {"lineNumber": 70, "col_offset": 25, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 72, "col_offset": 20, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 84, "col_offset": 8, "nodeName": "self", "type": "TestTokenizer"}, {"lineNumber": 88, "col_offset": 8, "nodeName": "self", "type": "TestTokenizer"}, {"lineNumber": 88, "col_offset": 25, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 92, "col_offset": 8, "nodeName": "self", "type": "TestTokenizer"}, {"lineNumber": 92, "col_offset": 35, "nodeName": "to_words", "type": "Callable[[Any], Tuple[Any, ...]]"}, {"lineNumber": 92, "col_offset": 54, "nodeName": "sentence", "type": "unicode"}, {"lineNumber": 102, "col_offset": 8, "nodeName": "self", "type": "TestTokenizer"}, {"lineNumber": 102, "col_offset": 35, "nodeName": "to_sentences", "type": "Callable[[Any], Tuple[Any, ...]]"}, {"lineNumber": 102, "col_offset": 58, "nodeName": "paragraph", "type": "unicode"}, {"lineNumber": 92, "col_offset": 35, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}, {"lineNumber": 102, "col_offset": 35, "nodeName": "tokenizer", "type": "sumy.nlp.tokenizers.Tokenizer"}]