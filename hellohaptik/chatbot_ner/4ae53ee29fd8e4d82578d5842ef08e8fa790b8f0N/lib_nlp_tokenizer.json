[{"lineNumber": 6, "col_offset": 0, "nodeName": "NLTK_TOKENIZER", "type": "str"}, {"lineNumber": 7, "col_offset": 0, "nodeName": "PRELOADED_NLTK_TOKENIZER", "type": "str"}, {"lineNumber": 10, "col_offset": 16, "nodeName": "object", "type": "Type[object]"}, {"lineNumber": 29, "col_offset": 4, "nodeName": "__metaclass__", "type": "Type[lib.singleton.Singleton]"}, {"lineNumber": 29, "col_offset": 20, "nodeName": "Singleton", "type": "Type[lib.singleton.Singleton]"}, {"lineNumber": 31, "col_offset": 42, "nodeName": "NLTK_TOKENIZER", "type": "str"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "tokenizer_selected", "type": "Any"}, {"lineNumber": 37, "col_offset": 34, "nodeName": "tokenizer_selected", "type": "Any"}, {"lineNumber": 42, "col_offset": 8, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 50, "col_offset": 15, "nodeName": "word_tokenize", "type": "Any"}, {"lineNumber": 54, "col_offset": 8, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 55, "col_offset": 8, "nodeName": "sent_tokenizer", "type": "Any"}, {"lineNumber": 55, "col_offset": 25, "nodeName": "tokenize", "type": "Any"}, {"lineNumber": 64, "col_offset": 15, "nodeName": "word_tokenize", "type": "Callable[[Any], Any]"}, {"lineNumber": 72, "col_offset": 15, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 39, "col_offset": 12, "nodeName": "NLTK_TOKENIZER", "type": "str"}, {"lineNumber": 40, "col_offset": 12, "nodeName": "PRELOADED_NLTK_TOKENIZER", "type": "str"}, {"lineNumber": 42, "col_offset": 8, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 50, "col_offset": 15, "nodeName": "nltk", "type": "Any"}, {"lineNumber": 54, "col_offset": 20, "nodeName": "load", "type": "Any"}, {"lineNumber": 55, "col_offset": 25, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 58, "col_offset": 12, "nodeName": "sentences", "type": "Any"}, {"lineNumber": 59, "col_offset": 12, "nodeName": "tokens", "type": "List[Any]"}, {"lineNumber": 60, "col_offset": 16, "nodeName": "sent", "type": "Any"}, {"lineNumber": 60, "col_offset": 24, "nodeName": "sentences", "type": "Any"}, {"lineNumber": 62, "col_offset": 19, "nodeName": "tokens", "type": "List[Any]"}, {"lineNumber": 72, "col_offset": 15, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 89, "col_offset": 15, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 89, "col_offset": 30, "nodeName": "text", "type": "Any"}, {"lineNumber": 39, "col_offset": 28, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 40, "col_offset": 38, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 42, "col_offset": 25, "nodeName": "tokenizer_dict", "type": "Dict[str, Callable[[], Any]]"}, {"lineNumber": 54, "col_offset": 20, "nodeName": "nltk", "type": "Any"}, {"lineNumber": 54, "col_offset": 30, "nodeName": "format", "type": "Callable[..., str]"}, {"lineNumber": 58, "col_offset": 24, "nodeName": "sent_tokenizer", "type": "Any"}, {"lineNumber": 58, "col_offset": 39, "nodeName": "text", "type": "Any"}, {"lineNumber": 89, "col_offset": 15, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 42, "col_offset": 25, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 42, "col_offset": 45, "nodeName": "tokenizer_selected", "type": "Any"}, {"lineNumber": 61, "col_offset": 16, "nodeName": "extend", "type": "Callable"}, {"lineNumber": 42, "col_offset": 45, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 61, "col_offset": 16, "nodeName": "tokens", "type": "List[Any]"}, {"lineNumber": 61, "col_offset": 30, "nodeName": "word_tokenize", "type": "Any"}, {"lineNumber": 61, "col_offset": 49, "nodeName": "sent", "type": "Any"}, {"lineNumber": 61, "col_offset": 30, "nodeName": "nltk", "type": "Any"}]