[{"lineNumber": 8, "col_offset": 19, "nodeName": "object", "type": "Type[object]"}, {"lineNumber": 41, "col_offset": 8, "nodeName": "text", "type": "None"}, {"lineNumber": 42, "col_offset": 8, "nodeName": "regx_to_process", "type": "lib.nlp.regex.Regex"}, {"lineNumber": 43, "col_offset": 8, "nodeName": "text_dict", "type": "Dict[nothing, nothing]"}, {"lineNumber": 44, "col_offset": 8, "nodeName": "fuzziness_threshold", "type": "int"}, {"lineNumber": 45, "col_offset": 8, "nodeName": "min_size_token_for_levenshtein", "type": "int"}, {"lineNumber": 46, "col_offset": 8, "nodeName": "tagged_text", "type": "None"}, {"lineNumber": 47, "col_offset": 8, "nodeName": "text_entity", "type": "List[nothing]"}, {"lineNumber": 48, "col_offset": 8, "nodeName": "original_text_entity", "type": "List[nothing]"}, {"lineNumber": 49, "col_offset": 8, "nodeName": "processed_text", "type": "None"}, {"lineNumber": 50, "col_offset": 8, "nodeName": "entity_name", "type": "Any"}, {"lineNumber": 50, "col_offset": 27, "nodeName": "entity_name", "type": "Any"}, {"lineNumber": 51, "col_offset": 8, "nodeName": "tag", "type": "str"}, {"lineNumber": 62, "col_offset": 8, "nodeName": "fuzziness_threshold", "type": "Any"}, {"lineNumber": 62, "col_offset": 35, "nodeName": "fuzziness", "type": "Any"}, {"lineNumber": 73, "col_offset": 8, "nodeName": "min_size_token_for_levenshtein", "type": "Any"}, {"lineNumber": 73, "col_offset": 46, "nodeName": "min_size", "type": "Any"}, {"lineNumber": 117, "col_offset": 8, "nodeName": "text", "type": "Any"}, {"lineNumber": 117, "col_offset": 20, "nodeName": "text", "type": "Any"}, {"lineNumber": 118, "col_offset": 8, "nodeName": "text", "type": "Any"}, {"lineNumber": 119, "col_offset": 8, "nodeName": "text", "type": "Any"}, {"lineNumber": 120, "col_offset": 8, "nodeName": "processed_text", "type": "str"}, {"lineNumber": 120, "col_offset": 30, "nodeName": "text", "type": "str"}, {"lineNumber": 121, "col_offset": 8, "nodeName": "text_entity_data", "type": "Tuple[List[Any], List[Optional[str]]]"}, {"lineNumber": 122, "col_offset": 8, "nodeName": "tagged_text", "type": "str"}, {"lineNumber": 122, "col_offset": 27, "nodeName": "processed_text", "type": "str"}, {"lineNumber": 123, "col_offset": 8, "nodeName": "text_entity", "type": "List[Any]"}, {"lineNumber": 124, "col_offset": 8, "nodeName": "original_text_entity", "type": "List[Optional[str]]"}, {"lineNumber": 125, "col_offset": 15, "nodeName": "text_entity_data", "type": "Tuple[List[Any], List[Optional[str]]]"}, {"lineNumber": 138, "col_offset": 8, "nodeName": "original_final_list", "type": "List[Optional[str]]"}, {"lineNumber": 139, "col_offset": 8, "nodeName": "value_final_list", "type": "List[Any]"}, {"lineNumber": 140, "col_offset": 8, "nodeName": "normalization", "type": "lib.nlp.data_normalization.Normalization"}, {"lineNumber": 145, "col_offset": 8, "nodeName": "variant_dictionary", "type": "Dict[Any, Any]"}, {"lineNumber": 146, "col_offset": 8, "nodeName": "db", "type": "Any"}, {"lineNumber": 156, "col_offset": 8, "nodeName": "variant_list", "type": "dict_keys[Any]"}, {"lineNumber": 159, "col_offset": 12, "nodeName": "variant", "type": "Any"}, {"lineNumber": 159, "col_offset": 23, "nodeName": "variant_list", "type": "dict_keys[Any]"}, {"lineNumber": 194, "col_offset": 8, "nodeName": "variant_token_list", "type": "Any"}, {"lineNumber": 195, "col_offset": 8, "nodeName": "text_token_list", "type": "Any"}, {"lineNumber": 196, "col_offset": 8, "nodeName": "original_text", "type": "List[Any]"}, {"lineNumber": 197, "col_offset": 8, "nodeName": "variant_count", "type": "int"}, {"lineNumber": 198, "col_offset": 8, "nodeName": "token_count", "type": "int"}, {"lineNumber": 41, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 42, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 42, "col_offset": 31, "nodeName": "Regex", "type": "Type[lib.nlp.regex.Regex]"}, {"lineNumber": 43, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 44, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 45, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 46, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 47, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 48, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 49, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 50, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 51, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 62, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 73, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 117, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 118, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 118, "col_offset": 20, "nodeName": "text_substitute", "type": "Callable[[Any], Any]"}, {"lineNumber": 118, "col_offset": 57, "nodeName": "text", "type": "Any"}, {"lineNumber": 119, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 120, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 120, "col_offset": 30, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 121, "col_offset": 27, "nodeName": "_text_detection_with_variants", "type": "Callable[[], Any]"}, {"lineNumber": 122, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 122, "col_offset": 27, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 123, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 123, "col_offset": 27, "nodeName": "text_entity_data", "type": "Tuple[List[Any], List[Optional[str]]]"}, {"lineNumber": 124, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 124, "col_offset": 36, "nodeName": "text_entity_data", "type": "Tuple[List[Any], List[Optional[str]]]"}, {"lineNumber": 140, "col_offset": 24, "nodeName": "Normalization", "type": "Type[lib.nlp.data_normalization.Normalization]"}, {"lineNumber": 141, "col_offset": 8, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 146, "col_offset": 13, "nodeName": "DataStore", "type": "Any"}, {"lineNumber": 147, "col_offset": 27, "nodeName": "get_similar_ngrams_dictionary", "type": "Any"}, {"lineNumber": 147, "col_offset": 60, "nodeName": "entity_name", "type": "Any"}, {"lineNumber": 148, "col_offset": 60, "nodeName": "fuzziness_threshold", "type": "int"}, {"lineNumber": 149, "col_offset": 26, "nodeName": "get_similar_ngrams_dictionary", "type": "Any"}, {"lineNumber": 149, "col_offset": 59, "nodeName": "entity_name", "type": "Any"}, {"lineNumber": 150, "col_offset": 59, "nodeName": "fuzziness_threshold", "type": "int"}, {"lineNumber": 151, "col_offset": 27, "nodeName": "get_similar_ngrams_dictionary", "type": "Any"}, {"lineNumber": 151, "col_offset": 60, "nodeName": "entity_name", "type": "Any"}, {"lineNumber": 152, "col_offset": 60, "nodeName": "fuzziness_threshold", "type": "int"}, {"lineNumber": 153, "col_offset": 8, "nodeName": "update", "type": "Callable"}, {"lineNumber": 153, "col_offset": 34, "nodeName": "trigram_variants", "type": "Any"}, {"lineNumber": 154, "col_offset": 8, "nodeName": "update", "type": "Callable"}, {"lineNumber": 154, "col_offset": 34, "nodeName": "bigram_variants", "type": "Any"}, {"lineNumber": 155, "col_offset": 8, "nodeName": "update", "type": "Callable"}, {"lineNumber": 155, "col_offset": 34, "nodeName": "unigram_variants", "type": "Any"}, {"lineNumber": 156, "col_offset": 23, "nodeName": "keys", "type": "Callable"}, {"lineNumber": 157, "col_offset": 8, "nodeName": "sort", "type": "Any"}, {"lineNumber": 160, "col_offset": 12, "nodeName": "original_text", "type": "Optional[str]"}, {"lineNumber": 161, "col_offset": 15, "nodeName": "original_text", "type": "Optional[str]"}, {"lineNumber": 166, "col_offset": 15, "nodeName": "value_final_list", "type": "List[Any]"}, {"lineNumber": 166, "col_offset": 33, "nodeName": "original_final_list", "type": "List[Optional[str]]"}, {"lineNumber": 194, "col_offset": 29, "nodeName": "tokenize", "type": "Callable[[Any], Any]"}, {"lineNumber": 195, "col_offset": 26, "nodeName": "tokenize", "type": "Callable[[Any], Any]"}, {"lineNumber": 199, "col_offset": 14, "nodeName": "token_count", "type": "int"}, {"lineNumber": 213, "col_offset": 12, "nodeName": "token_count", "type": "int"}, {"lineNumber": 51, "col_offset": 26, "nodeName": "entity_name", "type": "Any"}, {"lineNumber": 118, "col_offset": 20, "nodeName": "regx_to_process", "type": "lib.nlp.regex.Regex"}, {"lineNumber": 118, "col_offset": 57, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 121, "col_offset": 27, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 147, "col_offset": 27, "nodeName": "db", "type": "Any"}, {"lineNumber": 147, "col_offset": 60, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 147, "col_offset": 78, "nodeName": "text_dict", "type": "Any"}, {"lineNumber": 148, "col_offset": 60, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 149, "col_offset": 26, "nodeName": "db", "type": "Any"}, {"lineNumber": 149, "col_offset": 59, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 149, "col_offset": 77, "nodeName": "text_dict", "type": "Any"}, {"lineNumber": 150, "col_offset": 59, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 151, "col_offset": 27, "nodeName": "db", "type": "Any"}, {"lineNumber": 151, "col_offset": 60, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 151, "col_offset": 78, "nodeName": "text_dict", "type": "Any"}, {"lineNumber": 152, "col_offset": 60, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 153, "col_offset": 8, "nodeName": "variant_dictionary", "type": "Dict[Any, Any]"}, {"lineNumber": 154, "col_offset": 8, "nodeName": "variant_dictionary", "type": "Dict[Any, Any]"}, {"lineNumber": 155, "col_offset": 8, "nodeName": "variant_dictionary", "type": "Dict[Any, Any]"}, {"lineNumber": 156, "col_offset": 23, "nodeName": "variant_dictionary", "type": "Dict[Any, Any]"}, {"lineNumber": 157, "col_offset": 8, "nodeName": "variant_list", "type": "dict_keys[Any]"}, {"lineNumber": 160, "col_offset": 28, "nodeName": "_get_entity_from_text", "type": "Callable[[Any, Any], Any]"}, {"lineNumber": 160, "col_offset": 55, "nodeName": "variant", "type": "Any"}, {"lineNumber": 164, "col_offset": 16, "nodeName": "processed_text", "type": "Any"}, {"lineNumber": 194, "col_offset": 29, "nodeName": "tokenizer", "type": "lib.nlp.tokenizer.Tokenizer"}, {"lineNumber": 194, "col_offset": 48, "nodeName": "lower", "type": "Any"}, {"lineNumber": 195, "col_offset": 26, "nodeName": "tokenizer", "type": "lib.nlp.tokenizer.Tokenizer"}, {"lineNumber": 195, "col_offset": 45, "nodeName": "lower", "type": "Any"}, {"lineNumber": 199, "col_offset": 28, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 199, "col_offset": 32, "nodeName": "text_token_list", "type": "Any"}, {"lineNumber": 200, "col_offset": 26, "nodeName": "Levenshtein", "type": "Type[lib.nlp.levenshtein_distance.Levenshtein]"}, {"lineNumber": 206, "col_offset": 16, "nodeName": "variant_count", "type": "int"}, {"lineNumber": 210, "col_offset": 16, "nodeName": "original_text", "type": "List[nothing]"}, {"lineNumber": 211, "col_offset": 16, "nodeName": "variant_count", "type": "int"}, {"lineNumber": 51, "col_offset": 26, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 118, "col_offset": 20, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 119, "col_offset": 26, "nodeName": "lower", "type": "Any"}, {"lineNumber": 141, "col_offset": 25, "nodeName": "ngram_data", "type": "Callable[..., Any]"}, {"lineNumber": 147, "col_offset": 78, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 149, "col_offset": 77, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 151, "col_offset": 78, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 160, "col_offset": 28, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 160, "col_offset": 64, "nodeName": "lower", "type": "Any"}, {"lineNumber": 162, "col_offset": 16, "nodeName": "append", "type": "Callable"}, {"lineNumber": 163, "col_offset": 16, "nodeName": "append", "type": "Callable"}, {"lineNumber": 163, "col_offset": 43, "nodeName": "original_text", "type": "Optional[str]"}, {"lineNumber": 164, "col_offset": 16, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 164, "col_offset": 38, "nodeName": "replace", "type": "Any"}, {"lineNumber": 164, "col_offset": 66, "nodeName": "original_text", "type": "Optional[str]"}, {"lineNumber": 164, "col_offset": 81, "nodeName": "tag", "type": "str"}, {"lineNumber": 194, "col_offset": 48, "nodeName": "variant", "type": "Any"}, {"lineNumber": 195, "col_offset": 45, "nodeName": "text", "type": "Any"}, {"lineNumber": 200, "col_offset": 38, "nodeName": "variant_token_list", "type": "Any"}, {"lineNumber": 200, "col_offset": 73, "nodeName": "text_token_list", "type": "Any"}, {"lineNumber": 201, "col_offset": 38, "nodeName": "fuzziness_threshold", "type": "int"}, {"lineNumber": 205, "col_offset": 16, "nodeName": "append", "type": "Callable"}, {"lineNumber": 207, "col_offset": 19, "nodeName": "variant_count", "type": "int"}, {"lineNumber": 119, "col_offset": 26, "nodeName": "text", "type": "str"}, {"lineNumber": 141, "col_offset": 25, "nodeName": "normalization", "type": "lib.nlp.data_normalization.Normalization"}, {"lineNumber": 141, "col_offset": 50, "nodeName": "lower", "type": "Any"}, {"lineNumber": 157, "col_offset": 40, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 160, "col_offset": 64, "nodeName": "processed_text", "type": "Any"}, {"lineNumber": 162, "col_offset": 16, "nodeName": "value_final_list", "type": "List[Any]"}, {"lineNumber": 162, "col_offset": 40, "nodeName": "variant_dictionary", "type": "Dict[Any, Any]"}, {"lineNumber": 163, "col_offset": 16, "nodeName": "original_final_list", "type": "List[Optional[str]]"}, {"lineNumber": 164, "col_offset": 38, "nodeName": "processed_text", "type": "Any"}, {"lineNumber": 164, "col_offset": 81, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 200, "col_offset": 57, "nodeName": "variant_count", "type": "int"}, {"lineNumber": 200, "col_offset": 89, "nodeName": "token_count", "type": "int"}, {"lineNumber": 201, "col_offset": 38, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 202, "col_offset": 15, "nodeName": "variant_token_list", "type": "Any"}, {"lineNumber": 202, "col_offset": 52, "nodeName": "text_token_list", "type": "Any"}, {"lineNumber": 203, "col_offset": 57, "nodeName": "min_size_token_for_levenshtein", "type": "int"}, {"lineNumber": 204, "col_offset": 67, "nodeName": "fuzziness_threshold", "type": "int"}, {"lineNumber": 205, "col_offset": 16, "nodeName": "original_text", "type": "List[Any]"}, {"lineNumber": 205, "col_offset": 37, "nodeName": "text_token_list", "type": "Any"}, {"lineNumber": 207, "col_offset": 36, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 207, "col_offset": 40, "nodeName": "variant_token_list", "type": "Any"}, {"lineNumber": 208, "col_offset": 27, "nodeName": "join", "type": "Callable"}, {"lineNumber": 208, "col_offset": 36, "nodeName": "original_text", "type": "Union[List[Any], List[nothing]]"}, {"lineNumber": 119, "col_offset": 26, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 141, "col_offset": 50, "nodeName": "processed_text", "type": "Any"}, {"lineNumber": 157, "col_offset": 44, "nodeName": "tokenize", "type": "Callable[[Any], Any]"}, {"lineNumber": 157, "col_offset": 63, "nodeName": "s", "type": "Any"}, {"lineNumber": 160, "col_offset": 64, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 162, "col_offset": 59, "nodeName": "variant", "type": "Any"}, {"lineNumber": 164, "col_offset": 38, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 202, "col_offset": 34, "nodeName": "variant_count", "type": "int"}, {"lineNumber": 202, "col_offset": 68, "nodeName": "token_count", "type": "int"}, {"lineNumber": 203, "col_offset": 21, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 203, "col_offset": 57, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 204, "col_offset": 29, "nodeName": "levenshtein_distance", "type": "Callable[[], Any]"}, {"lineNumber": 204, "col_offset": 67, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 205, "col_offset": 53, "nodeName": "token_count", "type": "int"}, {"lineNumber": 141, "col_offset": 50, "nodeName": "self", "type": "TextDetector"}, {"lineNumber": 157, "col_offset": 44, "nodeName": "tokenizer", "type": "lib.nlp.tokenizer.Tokenizer"}, {"lineNumber": 203, "col_offset": 25, "nodeName": "text_token_list", "type": "Any"}, {"lineNumber": 204, "col_offset": 29, "nodeName": "levenshtein", "type": "lib.nlp.levenshtein_distance.Levenshtein"}, {"lineNumber": 203, "col_offset": 41, "nodeName": "token_count", "type": "int"}]