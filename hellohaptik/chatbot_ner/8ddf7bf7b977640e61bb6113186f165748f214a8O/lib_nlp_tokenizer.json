[{"lineNumber": 4, "col_offset": 0, "nodeName": "WORD_TOKENIZER", "type": "str"}, {"lineNumber": 7, "col_offset": 16, "nodeName": "object", "type": "Type[object]"}, {"lineNumber": 26, "col_offset": 42, "nodeName": "WORD_TOKENIZER", "type": "str"}, {"lineNumber": 32, "col_offset": 8, "nodeName": "tokenizer", "type": "None"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "tokenizer_selected", "type": "Any"}, {"lineNumber": 33, "col_offset": 34, "nodeName": "tokenizer_selected", "type": "Any"}, {"lineNumber": 45, "col_offset": 8, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 45, "col_offset": 25, "nodeName": "word_tokenize", "type": "Any"}, {"lineNumber": 53, "col_offset": 15, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 32, "col_offset": 8, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 35, "col_offset": 12, "nodeName": "WORD_TOKENIZER", "type": "str"}, {"lineNumber": 45, "col_offset": 8, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 45, "col_offset": 25, "nodeName": "nltk", "type": "Any"}, {"lineNumber": 53, "col_offset": 15, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 71, "col_offset": 11, "nodeName": "WORD_TOKENIZER", "type": "str"}, {"lineNumber": 71, "col_offset": 29, "nodeName": "tokenizer_selected", "type": "Any"}, {"lineNumber": 35, "col_offset": 28, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "tokenizer_dict", "type": "Dict[str, Callable[[], Any]]"}, {"lineNumber": 71, "col_offset": 29, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 72, "col_offset": 19, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 72, "col_offset": 34, "nodeName": "text", "type": "Any"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 37, "col_offset": 28, "nodeName": "tokenizer_selected", "type": "Any"}, {"lineNumber": 72, "col_offset": 19, "nodeName": "self", "type": "Tokenizer"}, {"lineNumber": 37, "col_offset": 28, "nodeName": "self", "type": "Tokenizer"}]