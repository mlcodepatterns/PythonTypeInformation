[{"lineNumber": 16, "col_offset": 12, "nodeName": "object", "type": "Type[object]"}, {"lineNumber": 51, "col_offset": 0, "nodeName": "RemoteAgent", "type": "Any"}, {"lineNumber": 51, "col_offset": 14, "nodeName": "remote", "type": "Any"}, {"lineNumber": 51, "col_offset": 25, "nodeName": "Agent", "type": "Type[Agent]"}, {"lineNumber": 20, "col_offset": 4, "nodeName": "env", "type": "Any"}, {"lineNumber": 23, "col_offset": 4, "nodeName": "sess", "type": "Any"}, {"lineNumber": 48, "col_offset": 11, "nodeName": "trajectory", "type": "Any"}, {"lineNumber": 51, "col_offset": 14, "nodeName": "ray", "type": "Any"}, {"lineNumber": 18, "col_offset": 11, "nodeName": "use_gpu", "type": "Any"}, {"lineNumber": 20, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 20, "col_offset": 15, "nodeName": "BatchedEnv", "type": "Any"}, {"lineNumber": 20, "col_offset": 26, "nodeName": "name", "type": "Any"}, {"lineNumber": 20, "col_offset": 32, "nodeName": "batchsize", "type": "Any"}, {"lineNumber": 21, "col_offset": 7, "nodeName": "shape", "type": "Any"}, {"lineNumber": 22, "col_offset": 6, "nodeName": "shape", "type": "Any"}, {"lineNumber": 22, "col_offset": 27, "nodeName": "shape", "type": "Any"}, {"lineNumber": 23, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 23, "col_offset": 16, "nodeName": "Session", "type": "Any"}, {"lineNumber": 34, "col_offset": 6, "nodeName": "observation_filter", "type": "Any"}, {"lineNumber": 35, "col_offset": 6, "nodeName": "reward_filter", "type": "Any"}, {"lineNumber": 36, "col_offset": 4, "nodeName": "run", "type": "Any"}, {"lineNumber": 39, "col_offset": 11, "nodeName": "get_weights", "type": "Any"}, {"lineNumber": 42, "col_offset": 4, "nodeName": "set_weights", "type": "Any"}, {"lineNumber": 42, "col_offset": 31, "nodeName": "weights", "type": "Any"}, {"lineNumber": 45, "col_offset": 17, "nodeName": "rollouts", "type": "Any"}, {"lineNumber": 45, "col_offset": 26, "nodeName": "ppo", "type": "Any"}, {"lineNumber": 45, "col_offset": 36, "nodeName": "env", "type": "Any"}, {"lineNumber": 45, "col_offset": 46, "nodeName": "horizon", "type": "Any"}, {"lineNumber": 45, "col_offset": 55, "nodeName": "observation_filter", "type": "Any"}, {"lineNumber": 46, "col_offset": 26, "nodeName": "reward_filter", "type": "Any"}, {"lineNumber": 47, "col_offset": 4, "nodeName": "add_advantage_values", "type": "Any"}, {"lineNumber": 47, "col_offset": 25, "nodeName": "trajectory", "type": "Any"}, {"lineNumber": 47, "col_offset": 37, "nodeName": "gamma", "type": "Any"}, {"lineNumber": 47, "col_offset": 44, "nodeName": "lam", "type": "Any"}, {"lineNumber": 47, "col_offset": 49, "nodeName": "reward_filter", "type": "Any"}, {"lineNumber": 19, "col_offset": 6, "nodeName": "environ", "type": "os._Environ[str]"}, {"lineNumber": 20, "col_offset": 56, "nodeName": "preprocessor", "type": "Any"}, {"lineNumber": 21, "col_offset": 7, "nodeName": "preprocessor", "type": "Any"}, {"lineNumber": 22, "col_offset": 6, "nodeName": "preprocessor", "type": "Any"}, {"lineNumber": 22, "col_offset": 27, "nodeName": "observation_space", "type": "Any"}, {"lineNumber": 23, "col_offset": 16, "nodeName": "tf", "type": "Any"}, {"lineNumber": 24, "col_offset": 9, "nodeName": "name_scope", "type": "Any"}, {"lineNumber": 30, "col_offset": 8, "nodeName": "optimizer", "type": "Any"}, {"lineNumber": 31, "col_offset": 8, "nodeName": "train_op", "type": "Any"}, {"lineNumber": 32, "col_offset": 6, "nodeName": "self", "type": "Agent"}, {"lineNumber": 32, "col_offset": 23, "nodeName": "TensorFlowVariables", "type": "Any"}, {"lineNumber": 32, "col_offset": 60, "nodeName": "loss", "type": "Any"}, {"lineNumber": 33, "col_offset": 60, "nodeName": "sess", "type": "Any"}, {"lineNumber": 34, "col_offset": 6, "nodeName": "self", "type": "Agent"}, {"lineNumber": 34, "col_offset": 32, "nodeName": "MeanStdFilter", "type": "Any"}, {"lineNumber": 34, "col_offset": 46, "nodeName": "shape", "type": "Any"}, {"lineNumber": 35, "col_offset": 6, "nodeName": "self", "type": "Agent"}, {"lineNumber": 35, "col_offset": 27, "nodeName": "MeanStdFilter", "type": "Any"}, {"lineNumber": 36, "col_offset": 4, "nodeName": "sess", "type": "Any"}, {"lineNumber": 36, "col_offset": 18, "nodeName": "global_variables_initializer", "type": "Any"}, {"lineNumber": 39, "col_offset": 11, "nodeName": "variables", "type": "Any"}, {"lineNumber": 42, "col_offset": 4, "nodeName": "variables", "type": "Any"}, {"lineNumber": 45, "col_offset": 26, "nodeName": "self", "type": "Agent"}, {"lineNumber": 45, "col_offset": 36, "nodeName": "self", "type": "Agent"}, {"lineNumber": 45, "col_offset": 55, "nodeName": "self", "type": "Agent"}, {"lineNumber": 46, "col_offset": 26, "nodeName": "self", "type": "Agent"}, {"lineNumber": 47, "col_offset": 49, "nodeName": "self", "type": "Agent"}, {"lineNumber": 19, "col_offset": 6, "nodeName": "os", "type": "module"}, {"lineNumber": 22, "col_offset": 27, "nodeName": "env", "type": "Any"}, {"lineNumber": 24, "col_offset": 9, "nodeName": "tf", "type": "Any"}, {"lineNumber": 25, "col_offset": 11, "nodeName": "name_scope", "type": "Any"}, {"lineNumber": 26, "col_offset": 8, "nodeName": "self", "type": "Agent"}, {"lineNumber": 26, "col_offset": 19, "nodeName": "ProximalPolicyLoss", "type": "Any"}, {"lineNumber": 26, "col_offset": 38, "nodeName": "observation_space", "type": "Any"}, {"lineNumber": 27, "col_offset": 38, "nodeName": "action_space", "type": "Any"}, {"lineNumber": 27, "col_offset": 61, "nodeName": "preprocessor", "type": "Any"}, {"lineNumber": 28, "col_offset": 38, "nodeName": "config", "type": "Any"}, {"lineNumber": 28, "col_offset": 46, "nodeName": "sess", "type": "Any"}, {"lineNumber": 29, "col_offset": 11, "nodeName": "name_scope", "type": "Any"}, {"lineNumber": 30, "col_offset": 8, "nodeName": "self", "type": "Agent"}, {"lineNumber": 30, "col_offset": 25, "nodeName": "AdamOptimizer", "type": "Any"}, {"lineNumber": 31, "col_offset": 8, "nodeName": "self", "type": "Agent"}, {"lineNumber": 31, "col_offset": 24, "nodeName": "minimize", "type": "Any"}, {"lineNumber": 31, "col_offset": 48, "nodeName": "loss", "type": "Any"}, {"lineNumber": 32, "col_offset": 23, "nodeName": "experimental", "type": "Any"}, {"lineNumber": 32, "col_offset": 60, "nodeName": "ppo", "type": "Any"}, {"lineNumber": 33, "col_offset": 60, "nodeName": "self", "type": "Agent"}, {"lineNumber": 34, "col_offset": 46, "nodeName": "preprocessor", "type": "Any"}, {"lineNumber": 36, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 36, "col_offset": 18, "nodeName": "tf", "type": "Any"}, {"lineNumber": 39, "col_offset": 11, "nodeName": "self", "type": "Agent"}, {"lineNumber": 42, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 22, "col_offset": 27, "nodeName": "self", "type": "Agent"}, {"lineNumber": 25, "col_offset": 11, "nodeName": "tf", "type": "Any"}, {"lineNumber": 26, "col_offset": 38, "nodeName": "env", "type": "Any"}, {"lineNumber": 27, "col_offset": 38, "nodeName": "env", "type": "Any"}, {"lineNumber": 28, "col_offset": 46, "nodeName": "self", "type": "Agent"}, {"lineNumber": 29, "col_offset": 11, "nodeName": "tf", "type": "Any"}, {"lineNumber": 30, "col_offset": 25, "nodeName": "train", "type": "Any"}, {"lineNumber": 30, "col_offset": 48, "nodeName": "config", "type": "Any"}, {"lineNumber": 31, "col_offset": 24, "nodeName": "optimizer", "type": "Any"}, {"lineNumber": 31, "col_offset": 48, "nodeName": "ppo", "type": "Any"}, {"lineNumber": 32, "col_offset": 23, "nodeName": "ray", "type": "Any"}, {"lineNumber": 27, "col_offset": 38, "nodeName": "self", "type": "Agent"}, {"lineNumber": 30, "col_offset": 25, "nodeName": "tf", "type": "Any"}, {"lineNumber": 31, "col_offset": 24, "nodeName": "self", "type": "Agent"}, {"lineNumber": 31, "col_offset": 48, "nodeName": "self", "type": "Agent"}]