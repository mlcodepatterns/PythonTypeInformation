[{"lineNumber": 15, "col_offset": 12, "nodeName": "object", "type": "Type[object]"}, {"lineNumber": 41, "col_offset": 0, "nodeName": "RemoteAgent", "type": "Any"}, {"lineNumber": 41, "col_offset": 14, "nodeName": "actor", "type": "Any"}, {"lineNumber": 41, "col_offset": 24, "nodeName": "Agent", "type": "Type[Agent]"}, {"lineNumber": 20, "col_offset": 4, "nodeName": "env", "type": "Any"}, {"lineNumber": 21, "col_offset": 4, "nodeName": "sess", "type": "Any"}, {"lineNumber": 22, "col_offset": 4, "nodeName": "ppo", "type": "Any"}, {"lineNumber": 23, "col_offset": 4, "nodeName": "optimizer", "type": "Any"}, {"lineNumber": 24, "col_offset": 4, "nodeName": "train_op", "type": "Any"}, {"lineNumber": 25, "col_offset": 4, "nodeName": "variables", "type": "Any"}, {"lineNumber": 26, "col_offset": 4, "nodeName": "observation_filter", "type": "Any"}, {"lineNumber": 27, "col_offset": 4, "nodeName": "reward_filter", "type": "Any"}, {"lineNumber": 37, "col_offset": 4, "nodeName": "trajectory", "type": "Any"}, {"lineNumber": 39, "col_offset": 11, "nodeName": "trajectory", "type": "Any"}, {"lineNumber": 41, "col_offset": 14, "nodeName": "ray", "type": "Any"}, {"lineNumber": 18, "col_offset": 11, "nodeName": "use_gpu", "type": "Any"}, {"lineNumber": 20, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 20, "col_offset": 15, "nodeName": "BatchedEnv", "type": "Any"}, {"lineNumber": 20, "col_offset": 26, "nodeName": "name", "type": "Any"}, {"lineNumber": 20, "col_offset": 32, "nodeName": "batchsize", "type": "Any"}, {"lineNumber": 21, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 21, "col_offset": 16, "nodeName": "Session", "type": "Any"}, {"lineNumber": 22, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 22, "col_offset": 15, "nodeName": "ProximalPolicyLoss", "type": "Any"}, {"lineNumber": 22, "col_offset": 34, "nodeName": "observation_space", "type": "Any"}, {"lineNumber": 22, "col_offset": 62, "nodeName": "action_space", "type": "Any"}, {"lineNumber": 22, "col_offset": 85, "nodeName": "config", "type": "Any"}, {"lineNumber": 22, "col_offset": 93, "nodeName": "sess", "type": "Any"}, {"lineNumber": 23, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 23, "col_offset": 21, "nodeName": "AdamOptimizer", "type": "Any"}, {"lineNumber": 24, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 24, "col_offset": 20, "nodeName": "minimize", "type": "Any"}, {"lineNumber": 24, "col_offset": 44, "nodeName": "loss", "type": "Any"}, {"lineNumber": 25, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 25, "col_offset": 21, "nodeName": "TensorFlowVariables", "type": "Any"}, {"lineNumber": 25, "col_offset": 58, "nodeName": "loss", "type": "Any"}, {"lineNumber": 25, "col_offset": 73, "nodeName": "sess", "type": "Any"}, {"lineNumber": 26, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 26, "col_offset": 30, "nodeName": "MeanStdFilter", "type": "Any"}, {"lineNumber": 26, "col_offset": 44, "nodeName": "shape", "type": "Any"}, {"lineNumber": 27, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 27, "col_offset": 25, "nodeName": "MeanStdFilter", "type": "Any"}, {"lineNumber": 28, "col_offset": 4, "nodeName": "run", "type": "Any"}, {"lineNumber": 31, "col_offset": 11, "nodeName": "get_weights", "type": "Any"}, {"lineNumber": 34, "col_offset": 4, "nodeName": "set_weights", "type": "Any"}, {"lineNumber": 34, "col_offset": 31, "nodeName": "weights", "type": "Any"}, {"lineNumber": 37, "col_offset": 17, "nodeName": "rollouts", "type": "Any"}, {"lineNumber": 37, "col_offset": 26, "nodeName": "ppo", "type": "Any"}, {"lineNumber": 37, "col_offset": 36, "nodeName": "env", "type": "Any"}, {"lineNumber": 37, "col_offset": 46, "nodeName": "horizon", "type": "Any"}, {"lineNumber": 37, "col_offset": 55, "nodeName": "observation_filter", "type": "Any"}, {"lineNumber": 37, "col_offset": 80, "nodeName": "reward_filter", "type": "Any"}, {"lineNumber": 38, "col_offset": 4, "nodeName": "add_advantage_values", "type": "Any"}, {"lineNumber": 38, "col_offset": 25, "nodeName": "trajectory", "type": "Any"}, {"lineNumber": 38, "col_offset": 37, "nodeName": "gamma", "type": "Any"}, {"lineNumber": 38, "col_offset": 44, "nodeName": "lam", "type": "Any"}, {"lineNumber": 38, "col_offset": 49, "nodeName": "reward_filter", "type": "Any"}, {"lineNumber": 19, "col_offset": 6, "nodeName": "environ", "type": "os._Environ[str]"}, {"lineNumber": 21, "col_offset": 16, "nodeName": "tf", "type": "Any"}, {"lineNumber": 22, "col_offset": 34, "nodeName": "env", "type": "Any"}, {"lineNumber": 22, "col_offset": 62, "nodeName": "env", "type": "Any"}, {"lineNumber": 22, "col_offset": 93, "nodeName": "self", "type": "Agent"}, {"lineNumber": 23, "col_offset": 21, "nodeName": "train", "type": "Any"}, {"lineNumber": 23, "col_offset": 44, "nodeName": "config", "type": "Any"}, {"lineNumber": 24, "col_offset": 20, "nodeName": "optimizer", "type": "Any"}, {"lineNumber": 24, "col_offset": 44, "nodeName": "ppo", "type": "Any"}, {"lineNumber": 25, "col_offset": 21, "nodeName": "experimental", "type": "Any"}, {"lineNumber": 25, "col_offset": 58, "nodeName": "ppo", "type": "Any"}, {"lineNumber": 25, "col_offset": 73, "nodeName": "self", "type": "Agent"}, {"lineNumber": 26, "col_offset": 44, "nodeName": "observation_space", "type": "Any"}, {"lineNumber": 28, "col_offset": 4, "nodeName": "sess", "type": "Any"}, {"lineNumber": 28, "col_offset": 18, "nodeName": "global_variables_initializer", "type": "Any"}, {"lineNumber": 31, "col_offset": 11, "nodeName": "variables", "type": "Any"}, {"lineNumber": 34, "col_offset": 4, "nodeName": "variables", "type": "Any"}, {"lineNumber": 37, "col_offset": 26, "nodeName": "self", "type": "Agent"}, {"lineNumber": 37, "col_offset": 36, "nodeName": "self", "type": "Agent"}, {"lineNumber": 37, "col_offset": 55, "nodeName": "self", "type": "Agent"}, {"lineNumber": 37, "col_offset": 80, "nodeName": "self", "type": "Agent"}, {"lineNumber": 38, "col_offset": 49, "nodeName": "self", "type": "Agent"}, {"lineNumber": 19, "col_offset": 6, "nodeName": "os", "type": "module"}, {"lineNumber": 22, "col_offset": 34, "nodeName": "self", "type": "Agent"}, {"lineNumber": 22, "col_offset": 62, "nodeName": "self", "type": "Agent"}, {"lineNumber": 23, "col_offset": 21, "nodeName": "tf", "type": "Any"}, {"lineNumber": 24, "col_offset": 20, "nodeName": "self", "type": "Agent"}, {"lineNumber": 24, "col_offset": 44, "nodeName": "self", "type": "Agent"}, {"lineNumber": 25, "col_offset": 21, "nodeName": "ray", "type": "Any"}, {"lineNumber": 25, "col_offset": 58, "nodeName": "self", "type": "Agent"}, {"lineNumber": 26, "col_offset": 44, "nodeName": "env", "type": "Any"}, {"lineNumber": 28, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 28, "col_offset": 18, "nodeName": "tf", "type": "Any"}, {"lineNumber": 31, "col_offset": 11, "nodeName": "self", "type": "Agent"}, {"lineNumber": 34, "col_offset": 4, "nodeName": "self", "type": "Agent"}, {"lineNumber": 26, "col_offset": 44, "nodeName": "self", "type": "Agent"}]