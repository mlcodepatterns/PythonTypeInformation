[{"lineNumber": 28, "col_offset": 13, "nodeName": "object", "type": "Type[object]"}, {"lineNumber": 31, "col_offset": 8, "nodeName": "agent", "type": "Any"}, {"lineNumber": 31, "col_offset": 21, "nodeName": "agent", "type": "Any"}, {"lineNumber": 32, "col_offset": 8, "nodeName": "environment", "type": "Any"}, {"lineNumber": 32, "col_offset": 27, "nodeName": "environment", "type": "Any"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "preprocessor", "type": "Any"}, {"lineNumber": 33, "col_offset": 28, "nodeName": "preprocessor", "type": "Any"}, {"lineNumber": 34, "col_offset": 8, "nodeName": "repeat_actions", "type": "Any"}, {"lineNumber": 34, "col_offset": 30, "nodeName": "repeat_actions", "type": "Any"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "save_model_path", "type": "None"}, {"lineNumber": 36, "col_offset": 8, "nodeName": "save_model_episodes", "type": "int"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "episode_rewards", "type": "None"}, {"lineNumber": 40, "col_offset": 8, "nodeName": "save_model_path", "type": "Any"}, {"lineNumber": 40, "col_offset": 31, "nodeName": "path", "type": "Any"}, {"lineNumber": 41, "col_offset": 8, "nodeName": "save_model_episodes", "type": "Any"}, {"lineNumber": 41, "col_offset": 35, "nodeName": "num_episodes", "type": "Any"}, {"lineNumber": 44, "col_offset": 8, "nodeName": "episode_rewards", "type": "List[Union[Any, int]]"}, {"lineNumber": 45, "col_offset": 8, "nodeName": "episode_lengths", "type": "List[int]"}, {"lineNumber": 47, "col_offset": 8, "nodeName": "episode", "type": "int"}, {"lineNumber": 31, "col_offset": 8, "nodeName": "self", "type": "Runner"}, {"lineNumber": 32, "col_offset": 8, "nodeName": "self", "type": "Runner"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "self", "type": "Runner"}, {"lineNumber": 34, "col_offset": 8, "nodeName": "self", "type": "Runner"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "self", "type": "Runner"}, {"lineNumber": 36, "col_offset": 8, "nodeName": "self", "type": "Runner"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "self", "type": "Runner"}, {"lineNumber": 40, "col_offset": 8, "nodeName": "self", "type": "Runner"}, {"lineNumber": 41, "col_offset": 8, "nodeName": "self", "type": "Runner"}, {"lineNumber": 44, "col_offset": 8, "nodeName": "self", "type": "Runner"}, {"lineNumber": 45, "col_offset": 8, "nodeName": "self", "type": "Runner"}, {"lineNumber": 47, "col_offset": 8, "nodeName": "self", "type": "Runner"}, {"lineNumber": 49, "col_offset": 12, "nodeName": "state", "type": "Any"}, {"lineNumber": 51, "col_offset": 12, "nodeName": "episode_reward", "type": "int"}, {"lineNumber": 53, "col_offset": 12, "nodeName": "timestep", "type": "int"}, {"lineNumber": 93, "col_offset": 12, "nodeName": "episode", "type": "int"}, {"lineNumber": 49, "col_offset": 20, "nodeName": "reset", "type": "Any"}, {"lineNumber": 50, "col_offset": 12, "nodeName": "reset", "type": "Any"}, {"lineNumber": 53, "col_offset": 12, "nodeName": "self", "type": "Runner"}, {"lineNumber": 55, "col_offset": 19, "nodeName": "preprocessor", "type": "Any"}, {"lineNumber": 60, "col_offset": 16, "nodeName": "action", "type": "Any"}, {"lineNumber": 62, "col_offset": 19, "nodeName": "before_execution", "type": "Any"}, {"lineNumber": 75, "col_offset": 16, "nodeName": "episode_reward", "type": "Union[Any, int]"}, {"lineNumber": 75, "col_offset": 34, "nodeName": "reward", "type": "Union[Any, int]"}, {"lineNumber": 80, "col_offset": 16, "nodeName": "timestep", "type": "int"}, {"lineNumber": 82, "col_offset": 12, "nodeName": "append", "type": "Callable"}, {"lineNumber": 82, "col_offset": 40, "nodeName": "episode_reward", "type": "Union[Any, int]"}, {"lineNumber": 83, "col_offset": 12, "nodeName": "append", "type": "Callable"}, {"lineNumber": 83, "col_offset": 40, "nodeName": "timestep", "type": "int"}, {"lineNumber": 85, "col_offset": 15, "nodeName": "save_model_path", "type": "Any"}, {"lineNumber": 89, "col_offset": 15, "nodeName": "episode_finished", "type": "Any"}, {"lineNumber": 91, "col_offset": 15, "nodeName": "episode", "type": "int"}, {"lineNumber": 91, "col_offset": 31, "nodeName": "episodes", "type": "Any"}, {"lineNumber": 93, "col_offset": 12, "nodeName": "self", "type": "Runner"}, {"lineNumber": 49, "col_offset": 20, "nodeName": "environment", "type": "Any"}, {"lineNumber": 50, "col_offset": 12, "nodeName": "agent", "type": "Any"}, {"lineNumber": 55, "col_offset": 19, "nodeName": "self", "type": "Runner"}, {"lineNumber": 56, "col_offset": 20, "nodeName": "processed_state", "type": "Any"}, {"lineNumber": 58, "col_offset": 20, "nodeName": "processed_state", "type": "Any"}, {"lineNumber": 58, "col_offset": 38, "nodeName": "state", "type": "Any"}, {"lineNumber": 60, "col_offset": 25, "nodeName": "act", "type": "Any"}, {"lineNumber": 63, "col_offset": 20, "nodeName": "action", "type": "Any"}, {"lineNumber": 65, "col_offset": 19, "nodeName": "repeat_actions", "type": "Any"}, {"lineNumber": 66, "col_offset": 20, "nodeName": "reward", "type": "int"}, {"lineNumber": 67, "col_offset": 24, "nodeName": "repeat", "type": "int"}, {"lineNumber": 76, "col_offset": 16, "nodeName": "observe", "type": "Any"}, {"lineNumber": 78, "col_offset": 19, "nodeName": "terminal", "type": "Any"}, {"lineNumber": 80, "col_offset": 16, "nodeName": "self", "type": "Runner"}, {"lineNumber": 82, "col_offset": 12, "nodeName": "episode_rewards", "type": "List[Union[Any, int]]"}, {"lineNumber": 83, "col_offset": 12, "nodeName": "episode_lengths", "type": "List[int]"}, {"lineNumber": 83, "col_offset": 40, "nodeName": "self", "type": "Runner"}, {"lineNumber": 85, "col_offset": 15, "nodeName": "self", "type": "Runner"}, {"lineNumber": 85, "col_offset": 40, "nodeName": "save_model_episodes", "type": "int"}, {"lineNumber": 91, "col_offset": 15, "nodeName": "self", "type": "Runner"}, {"lineNumber": 49, "col_offset": 20, "nodeName": "self", "type": "Runner"}, {"lineNumber": 50, "col_offset": 12, "nodeName": "self", "type": "Runner"}, {"lineNumber": 56, "col_offset": 38, "nodeName": "process", "type": "Any"}, {"lineNumber": 56, "col_offset": 64, "nodeName": "state", "type": "Any"}, {"lineNumber": 60, "col_offset": 25, "nodeName": "agent", "type": "Any"}, {"lineNumber": 60, "col_offset": 46, "nodeName": "processed_state", "type": "Any"}, {"lineNumber": 63, "col_offset": 29, "nodeName": "before_execution", "type": "Any"}, {"lineNumber": 63, "col_offset": 46, "nodeName": "self", "type": "Runner"}, {"lineNumber": 63, "col_offset": 52, "nodeName": "action", "type": "Any"}, {"lineNumber": 65, "col_offset": 19, "nodeName": "self", "type": "Runner"}, {"lineNumber": 67, "col_offset": 34, "nodeName": "xrange", "type": "Type[range]"}, {"lineNumber": 67, "col_offset": 41, "nodeName": "repeat_actions", "type": "Any"}, {"lineNumber": 69, "col_offset": 24, "nodeName": "reward", "type": "Any"}, {"lineNumber": 69, "col_offset": 34, "nodeName": "step_reward", "type": "Any"}, {"lineNumber": 70, "col_offset": 27, "nodeName": "terminal", "type": "Any"}, {"lineNumber": 73, "col_offset": 20, "nodeName": "state", "type": "Any"}, {"lineNumber": 73, "col_offset": 27, "nodeName": "reward", "type": "Any"}, {"lineNumber": 73, "col_offset": 35, "nodeName": "terminal", "type": "Any"}, {"lineNumber": 73, "col_offset": 46, "nodeName": "execute", "type": "Any"}, {"lineNumber": 76, "col_offset": 16, "nodeName": "agent", "type": "Any"}, {"lineNumber": 76, "col_offset": 41, "nodeName": "processed_state", "type": "Any"}, {"lineNumber": 76, "col_offset": 65, "nodeName": "action", "type": "Any"}, {"lineNumber": 76, "col_offset": 80, "nodeName": "reward", "type": "Union[Any, int]"}, {"lineNumber": 76, "col_offset": 97, "nodeName": "terminal", "type": "Any"}, {"lineNumber": 78, "col_offset": 31, "nodeName": "timestep", "type": "int"}, {"lineNumber": 78, "col_offset": 48, "nodeName": "max_timesteps", "type": "Any"}, {"lineNumber": 82, "col_offset": 12, "nodeName": "self", "type": "Runner"}, {"lineNumber": 83, "col_offset": 12, "nodeName": "self", "type": "Runner"}, {"lineNumber": 85, "col_offset": 40, "nodeName": "self", "type": "Runner"}, {"lineNumber": 89, "col_offset": 40, "nodeName": "episode_finished", "type": "Any"}, {"lineNumber": 89, "col_offset": 57, "nodeName": "self", "type": "Runner"}, {"lineNumber": 56, "col_offset": 38, "nodeName": "preprocessor", "type": "Any"}, {"lineNumber": 60, "col_offset": 25, "nodeName": "self", "type": "Runner"}, {"lineNumber": 67, "col_offset": 41, "nodeName": "self", "type": "Runner"}, {"lineNumber": 68, "col_offset": 24, "nodeName": "state", "type": "Any"}, {"lineNumber": 68, "col_offset": 31, "nodeName": "step_reward", "type": "Any"}, {"lineNumber": 68, "col_offset": 44, "nodeName": "terminal", "type": "Any"}, {"lineNumber": 68, "col_offset": 55, "nodeName": "execute", "type": "Any"}, {"lineNumber": 73, "col_offset": 46, "nodeName": "environment", "type": "Any"}, {"lineNumber": 73, "col_offset": 78, "nodeName": "action", "type": "Any"}, {"lineNumber": 76, "col_offset": 16, "nodeName": "self", "type": "Runner"}, {"lineNumber": 78, "col_offset": 31, "nodeName": "self", "type": "Runner"}, {"lineNumber": 56, "col_offset": 38, "nodeName": "self", "type": "Runner"}, {"lineNumber": 68, "col_offset": 55, "nodeName": "environment", "type": "Any"}, {"lineNumber": 68, "col_offset": 87, "nodeName": "action", "type": "Any"}, {"lineNumber": 73, "col_offset": 46, "nodeName": "self", "type": "Runner"}, {"lineNumber": 68, "col_offset": 55, "nodeName": "self", "type": "Runner"}]