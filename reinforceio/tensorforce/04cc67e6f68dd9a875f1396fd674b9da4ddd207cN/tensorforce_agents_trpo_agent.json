[{"lineNumber": 24, "col_offset": 16, "nodeName": "LearningAgent", "type": "Type[tensorforce.agents.learning_agent.LearningAgent]"}, {"lineNumber": 132, "col_offset": 8, "nodeName": "baseline_mode", "type": "Any"}, {"lineNumber": 132, "col_offset": 29, "nodeName": "baseline_mode", "type": "Any"}, {"lineNumber": 133, "col_offset": 8, "nodeName": "baseline", "type": "Any"}, {"lineNumber": 133, "col_offset": 24, "nodeName": "baseline", "type": "Any"}, {"lineNumber": 134, "col_offset": 8, "nodeName": "baseline_optimizer", "type": "Any"}, {"lineNumber": 134, "col_offset": 34, "nodeName": "baseline_optimizer", "type": "Any"}, {"lineNumber": 135, "col_offset": 8, "nodeName": "gae_lambda", "type": "Any"}, {"lineNumber": 135, "col_offset": 26, "nodeName": "gae_lambda", "type": "Any"}, {"lineNumber": 136, "col_offset": 8, "nodeName": "likelihood_ratio_clipping", "type": "Any"}, {"lineNumber": 136, "col_offset": 41, "nodeName": "likelihood_ratio_clipping", "type": "Any"}, {"lineNumber": 94, "col_offset": 11, "nodeName": "update_mode", "type": "Any"}, {"lineNumber": 105, "col_offset": 11, "nodeName": "memory", "type": "Any"}, {"lineNumber": 116, "col_offset": 20, "nodeName": "dict", "type": "Type[Dict[Any, Any]]"}, {"lineNumber": 132, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 133, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 134, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 135, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 136, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 138, "col_offset": 8, "nodeName": "__init__", "type": "Callable[..., None]"}, {"lineNumber": 162, "col_offset": 15, "nodeName": "PGProbRatioModel", "type": "Type[tensorforce.models.pg_prob_ratio_model.PGProbRatioModel]"}, {"lineNumber": 95, "col_offset": 26, "nodeName": "dict", "type": "Type[Dict[Any, Any]]"}, {"lineNumber": 99, "col_offset": 23, "nodeName": "update_mode", "type": "Any"}, {"lineNumber": 107, "col_offset": 21, "nodeName": "dict", "type": "Type[Dict[Any, Any]]"}, {"lineNumber": 125, "col_offset": 30, "nodeName": "ls_max_iterations", "type": "Any"}, {"lineNumber": 126, "col_offset": 28, "nodeName": "ls_accept_ratio", "type": "Any"}, {"lineNumber": 129, "col_offset": 27, "nodeName": "ls_unroll_loop", "type": "Any"}, {"lineNumber": 139, "col_offset": 19, "nodeName": "states", "type": "Any"}, {"lineNumber": 140, "col_offset": 20, "nodeName": "actions", "type": "Any"}, {"lineNumber": 141, "col_offset": 28, "nodeName": "batched_observe", "type": "Any"}, {"lineNumber": 142, "col_offset": 30, "nodeName": "batching_capacity", "type": "Any"}, {"lineNumber": 143, "col_offset": 18, "nodeName": "scope", "type": "Any"}, {"lineNumber": 144, "col_offset": 19, "nodeName": "device", "type": "Any"}, {"lineNumber": 145, "col_offset": 18, "nodeName": "saver", "type": "Any"}, {"lineNumber": 146, "col_offset": 23, "nodeName": "summarizer", "type": "Any"}, {"lineNumber": 147, "col_offset": 22, "nodeName": "execution", "type": "Any"}, {"lineNumber": 148, "col_offset": 27, "nodeName": "variable_noise", "type": "Any"}, {"lineNumber": 149, "col_offset": 33, "nodeName": "states_preprocessing", "type": "Any"}, {"lineNumber": 150, "col_offset": 32, "nodeName": "actions_exploration", "type": "Any"}, {"lineNumber": 151, "col_offset": 33, "nodeName": "reward_preprocessing", "type": "Any"}, {"lineNumber": 152, "col_offset": 24, "nodeName": "update_mode", "type": "Union[Any, Dict[Any, Any]]"}, {"lineNumber": 153, "col_offset": 19, "nodeName": "memory", "type": "Union[Dict[Any, Any], Any]"}, {"lineNumber": 154, "col_offset": 22, "nodeName": "optimizer", "type": "Dict[Any, Any]"}, {"lineNumber": 155, "col_offset": 21, "nodeName": "discount", "type": "Any"}, {"lineNumber": 156, "col_offset": 20, "nodeName": "network", "type": "Any"}, {"lineNumber": 157, "col_offset": 26, "nodeName": "distributions", "type": "Any"}, {"lineNumber": 158, "col_offset": 35, "nodeName": "entropy_regularization", "type": "Any"}, {"lineNumber": 163, "col_offset": 19, "nodeName": "states", "type": "Any"}, {"lineNumber": 164, "col_offset": 20, "nodeName": "actions", "type": "Any"}, {"lineNumber": 165, "col_offset": 18, "nodeName": "scope", "type": "Any"}, {"lineNumber": 166, "col_offset": 19, "nodeName": "device", "type": "Any"}, {"lineNumber": 167, "col_offset": 18, "nodeName": "saver", "type": "Any"}, {"lineNumber": 168, "col_offset": 23, "nodeName": "summarizer", "type": "Any"}, {"lineNumber": 169, "col_offset": 22, "nodeName": "execution", "type": "Any"}, {"lineNumber": 170, "col_offset": 30, "nodeName": "batching_capacity", "type": "Any"}, {"lineNumber": 171, "col_offset": 21, "nodeName": "discount", "type": "Any"}, {"lineNumber": 172, "col_offset": 27, "nodeName": "variable_noise", "type": "Any"}, {"lineNumber": 173, "col_offset": 33, "nodeName": "states_preprocessing", "type": "Any"}, {"lineNumber": 174, "col_offset": 32, "nodeName": "actions_exploration", "type": "Any"}, {"lineNumber": 175, "col_offset": 33, "nodeName": "reward_preprocessing", "type": "Any"}, {"lineNumber": 176, "col_offset": 24, "nodeName": "update_mode", "type": "Any"}, {"lineNumber": 177, "col_offset": 19, "nodeName": "memory", "type": "Any"}, {"lineNumber": 178, "col_offset": 22, "nodeName": "optimizer", "type": "Any"}, {"lineNumber": 179, "col_offset": 20, "nodeName": "network", "type": "Any"}, {"lineNumber": 180, "col_offset": 26, "nodeName": "distributions", "type": "Any"}, {"lineNumber": 181, "col_offset": 35, "nodeName": "entropy_regularization", "type": "Any"}, {"lineNumber": 182, "col_offset": 26, "nodeName": "baseline_mode", "type": "Any"}, {"lineNumber": 183, "col_offset": 21, "nodeName": "baseline", "type": "Any"}, {"lineNumber": 184, "col_offset": 31, "nodeName": "baseline_optimizer", "type": "Any"}, {"lineNumber": 185, "col_offset": 23, "nodeName": "gae_lambda", "type": "Any"}, {"lineNumber": 186, "col_offset": 38, "nodeName": "likelihood_ratio_clipping", "type": "Any"}, {"lineNumber": 102, "col_offset": 12, "nodeName": "update_mode", "type": "Any"}, {"lineNumber": 113, "col_offset": 23, "nodeName": "memory", "type": "Any"}, {"lineNumber": 118, "col_offset": 22, "nodeName": "dict", "type": "Type[Dict[Any, Any]]"}, {"lineNumber": 138, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 138, "col_offset": 14, "nodeName": "TRPOAgent", "type": "Type[TRPOAgent]"}, {"lineNumber": 138, "col_offset": 25, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 163, "col_offset": 19, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 164, "col_offset": 20, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 165, "col_offset": 18, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 166, "col_offset": 19, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 167, "col_offset": 18, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 168, "col_offset": 23, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 169, "col_offset": 22, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 170, "col_offset": 30, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 171, "col_offset": 21, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 172, "col_offset": 27, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 173, "col_offset": 33, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 174, "col_offset": 32, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 175, "col_offset": 33, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 176, "col_offset": 24, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 177, "col_offset": 19, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 178, "col_offset": 22, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 179, "col_offset": 20, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 180, "col_offset": 26, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 181, "col_offset": 35, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 182, "col_offset": 26, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 183, "col_offset": 21, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 184, "col_offset": 31, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 185, "col_offset": 23, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 186, "col_offset": 38, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 100, "col_offset": 19, "nodeName": "update_mode", "type": "Any"}, {"lineNumber": 120, "col_offset": 30, "nodeName": "learning_rate", "type": "Any"}, {"lineNumber": 121, "col_offset": 34, "nodeName": "cg_max_iterations", "type": "Any"}, {"lineNumber": 122, "col_offset": 27, "nodeName": "cg_damping", "type": "Any"}, {"lineNumber": 123, "col_offset": 31, "nodeName": "cg_unroll_loop", "type": "Any"}, {"lineNumber": 110, "col_offset": 33, "nodeName": "update_mode", "type": "Union[Any, Dict[Any, Any]]"}]