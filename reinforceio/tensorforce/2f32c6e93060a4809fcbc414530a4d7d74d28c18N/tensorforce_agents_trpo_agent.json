[{"lineNumber": 25, "col_offset": 16, "nodeName": "BatchAgent", "type": "Type[tensorforce.agents.batch_agent.BatchAgent]"}, {"lineNumber": 101, "col_offset": 8, "nodeName": "baseline_mode", "type": "Any"}, {"lineNumber": 101, "col_offset": 29, "nodeName": "baseline_mode", "type": "Any"}, {"lineNumber": 102, "col_offset": 8, "nodeName": "baseline", "type": "Any"}, {"lineNumber": 102, "col_offset": 24, "nodeName": "baseline", "type": "Any"}, {"lineNumber": 103, "col_offset": 8, "nodeName": "baseline_optimizer", "type": "Any"}, {"lineNumber": 103, "col_offset": 34, "nodeName": "baseline_optimizer", "type": "Any"}, {"lineNumber": 104, "col_offset": 8, "nodeName": "gae_lambda", "type": "Any"}, {"lineNumber": 104, "col_offset": 26, "nodeName": "gae_lambda", "type": "Any"}, {"lineNumber": 105, "col_offset": 8, "nodeName": "likelihood_ratio_clipping", "type": "Any"}, {"lineNumber": 105, "col_offset": 41, "nodeName": "likelihood_ratio_clipping", "type": "Any"}, {"lineNumber": 85, "col_offset": 25, "nodeName": "dict", "type": "Type[Dict[Any, Any]]"}, {"lineNumber": 101, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 102, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 103, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 104, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 105, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 107, "col_offset": 8, "nodeName": "__init__", "type": "Callable[..., None]"}, {"lineNumber": 133, "col_offset": 15, "nodeName": "PGProbRatioModel", "type": "Type[tensorforce.models.pg_prob_ratio_model.PGProbRatioModel]"}, {"lineNumber": 108, "col_offset": 24, "nodeName": "states_spec", "type": "Any"}, {"lineNumber": 109, "col_offset": 25, "nodeName": "actions_spec", "type": "Any"}, {"lineNumber": 110, "col_offset": 28, "nodeName": "batched_observe", "type": "Any"}, {"lineNumber": 112, "col_offset": 25, "nodeName": "summary_spec", "type": "Any"}, {"lineNumber": 113, "col_offset": 25, "nodeName": "network_spec", "type": "Any"}, {"lineNumber": 114, "col_offset": 21, "nodeName": "discount", "type": "Any"}, {"lineNumber": 115, "col_offset": 19, "nodeName": "device", "type": "Any"}, {"lineNumber": 116, "col_offset": 27, "nodeName": "session_config", "type": "Any"}, {"lineNumber": 117, "col_offset": 18, "nodeName": "scope", "type": "Any"}, {"lineNumber": 118, "col_offset": 23, "nodeName": "saver_spec", "type": "Any"}, {"lineNumber": 119, "col_offset": 29, "nodeName": "distributed_spec", "type": "Any"}, {"lineNumber": 120, "col_offset": 22, "nodeName": "optimizer", "type": "Dict[Any, Any]"}, {"lineNumber": 121, "col_offset": 27, "nodeName": "variable_noise", "type": "Any"}, {"lineNumber": 122, "col_offset": 38, "nodeName": "states_preprocessing_spec", "type": "Any"}, {"lineNumber": 123, "col_offset": 30, "nodeName": "explorations_spec", "type": "Any"}, {"lineNumber": 124, "col_offset": 38, "nodeName": "reward_preprocessing_spec", "type": "Any"}, {"lineNumber": 125, "col_offset": 31, "nodeName": "distributions_spec", "type": "Any"}, {"lineNumber": 126, "col_offset": 35, "nodeName": "entropy_regularization", "type": "Any"}, {"lineNumber": 128, "col_offset": 23, "nodeName": "batch_size", "type": "Any"}, {"lineNumber": 129, "col_offset": 31, "nodeName": "keep_last_timestep", "type": "Any"}, {"lineNumber": 134, "col_offset": 24, "nodeName": "states_spec", "type": "Any"}, {"lineNumber": 135, "col_offset": 25, "nodeName": "actions_spec", "type": "Any"}, {"lineNumber": 136, "col_offset": 25, "nodeName": "network_spec", "type": "Any"}, {"lineNumber": 137, "col_offset": 19, "nodeName": "device", "type": "Any"}, {"lineNumber": 138, "col_offset": 27, "nodeName": "session_config", "type": "Any"}, {"lineNumber": 139, "col_offset": 18, "nodeName": "scope", "type": "Any"}, {"lineNumber": 140, "col_offset": 23, "nodeName": "saver_spec", "type": "Any"}, {"lineNumber": 141, "col_offset": 25, "nodeName": "summary_spec", "type": "Any"}, {"lineNumber": 142, "col_offset": 29, "nodeName": "distributed_spec", "type": "Any"}, {"lineNumber": 143, "col_offset": 22, "nodeName": "optimizer", "type": "Dict[Any, Any]"}, {"lineNumber": 144, "col_offset": 21, "nodeName": "discount", "type": "Any"}, {"lineNumber": 145, "col_offset": 27, "nodeName": "variable_noise", "type": "Any"}, {"lineNumber": 146, "col_offset": 38, "nodeName": "states_preprocessing_spec", "type": "Any"}, {"lineNumber": 147, "col_offset": 30, "nodeName": "explorations_spec", "type": "Any"}, {"lineNumber": 148, "col_offset": 38, "nodeName": "reward_preprocessing_spec", "type": "Any"}, {"lineNumber": 149, "col_offset": 31, "nodeName": "distributions_spec", "type": "Any"}, {"lineNumber": 150, "col_offset": 35, "nodeName": "entropy_regularization", "type": "Any"}, {"lineNumber": 151, "col_offset": 26, "nodeName": "baseline_mode", "type": "Any"}, {"lineNumber": 152, "col_offset": 21, "nodeName": "baseline", "type": "Any"}, {"lineNumber": 153, "col_offset": 31, "nodeName": "baseline_optimizer", "type": "Any"}, {"lineNumber": 154, "col_offset": 23, "nodeName": "gae_lambda", "type": "Any"}, {"lineNumber": 155, "col_offset": 38, "nodeName": "likelihood_ratio_clipping", "type": "Any"}, {"lineNumber": 87, "col_offset": 22, "nodeName": "dict", "type": "Type[Dict[Any, Any]]"}, {"lineNumber": 107, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 107, "col_offset": 14, "nodeName": "TRPOAgent", "type": "Type[TRPOAgent]"}, {"lineNumber": 107, "col_offset": 25, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 120, "col_offset": 22, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 134, "col_offset": 24, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 135, "col_offset": 25, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 136, "col_offset": 25, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 137, "col_offset": 19, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 138, "col_offset": 27, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 139, "col_offset": 18, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 140, "col_offset": 23, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 141, "col_offset": 25, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 142, "col_offset": 29, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 143, "col_offset": 22, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 144, "col_offset": 21, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 145, "col_offset": 27, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 146, "col_offset": 38, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 147, "col_offset": 30, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 148, "col_offset": 38, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 149, "col_offset": 31, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 150, "col_offset": 35, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 151, "col_offset": 26, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 152, "col_offset": 21, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 153, "col_offset": 31, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 154, "col_offset": 23, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 155, "col_offset": 38, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 89, "col_offset": 30, "nodeName": "learning_rate", "type": "Any"}, {"lineNumber": 90, "col_offset": 34, "nodeName": "cg_max_iterations", "type": "Any"}, {"lineNumber": 91, "col_offset": 27, "nodeName": "cg_damping", "type": "Any"}, {"lineNumber": 92, "col_offset": 31, "nodeName": "cg_unroll_loop", "type": "Any"}]