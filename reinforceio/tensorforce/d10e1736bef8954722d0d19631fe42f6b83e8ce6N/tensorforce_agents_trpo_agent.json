[{"lineNumber": 25, "col_offset": 16, "nodeName": "BatchAgent", "type": "Type[tensorforce.agents.batch_agent.BatchAgent]"}, {"lineNumber": 154, "col_offset": 8, "nodeName": "network_spec", "type": "Any"}, {"lineNumber": 154, "col_offset": 28, "nodeName": "network_spec", "type": "Any"}, {"lineNumber": 155, "col_offset": 8, "nodeName": "device", "type": "Any"}, {"lineNumber": 155, "col_offset": 22, "nodeName": "device", "type": "Any"}, {"lineNumber": 156, "col_offset": 8, "nodeName": "scope", "type": "Any"}, {"lineNumber": 156, "col_offset": 21, "nodeName": "scope", "type": "Any"}, {"lineNumber": 157, "col_offset": 8, "nodeName": "saver_spec", "type": "Any"}, {"lineNumber": 157, "col_offset": 26, "nodeName": "saver_spec", "type": "Any"}, {"lineNumber": 158, "col_offset": 8, "nodeName": "summary_spec", "type": "Any"}, {"lineNumber": 158, "col_offset": 28, "nodeName": "summary_spec", "type": "Any"}, {"lineNumber": 159, "col_offset": 8, "nodeName": "distributed_spec", "type": "Any"}, {"lineNumber": 159, "col_offset": 32, "nodeName": "distributed_spec", "type": "Any"}, {"lineNumber": 160, "col_offset": 8, "nodeName": "discount", "type": "Any"}, {"lineNumber": 160, "col_offset": 24, "nodeName": "discount", "type": "Any"}, {"lineNumber": 161, "col_offset": 8, "nodeName": "normalize_rewards", "type": "Any"}, {"lineNumber": 161, "col_offset": 33, "nodeName": "normalize_rewards", "type": "Any"}, {"lineNumber": 162, "col_offset": 8, "nodeName": "variable_noise", "type": "Any"}, {"lineNumber": 162, "col_offset": 30, "nodeName": "variable_noise", "type": "Any"}, {"lineNumber": 163, "col_offset": 8, "nodeName": "distributions_spec", "type": "Any"}, {"lineNumber": 163, "col_offset": 34, "nodeName": "distributions_spec", "type": "Any"}, {"lineNumber": 164, "col_offset": 8, "nodeName": "entropy_regularization", "type": "Any"}, {"lineNumber": 164, "col_offset": 38, "nodeName": "entropy_regularization", "type": "Any"}, {"lineNumber": 165, "col_offset": 8, "nodeName": "baseline_mode", "type": "Any"}, {"lineNumber": 165, "col_offset": 29, "nodeName": "baseline_mode", "type": "Any"}, {"lineNumber": 166, "col_offset": 8, "nodeName": "baseline", "type": "Any"}, {"lineNumber": 166, "col_offset": 24, "nodeName": "baseline", "type": "Any"}, {"lineNumber": 167, "col_offset": 8, "nodeName": "baseline_optimizer", "type": "Any"}, {"lineNumber": 167, "col_offset": 34, "nodeName": "baseline_optimizer", "type": "Any"}, {"lineNumber": 168, "col_offset": 8, "nodeName": "gae_lambda", "type": "Any"}, {"lineNumber": 168, "col_offset": 26, "nodeName": "gae_lambda", "type": "Any"}, {"lineNumber": 169, "col_offset": 8, "nodeName": "likelihood_ratio_clipping", "type": "Any"}, {"lineNumber": 169, "col_offset": 41, "nodeName": "likelihood_ratio_clipping", "type": "Any"}, {"lineNumber": 135, "col_offset": 11, "nodeName": "network_spec", "type": "Any"}, {"lineNumber": 138, "col_offset": 25, "nodeName": "dict", "type": "Type[Dict[Any, Any]]"}, {"lineNumber": 154, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 155, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 156, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 157, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 158, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 159, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 160, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 161, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 162, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 163, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 164, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 165, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 166, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 167, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 168, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 169, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 171, "col_offset": 8, "nodeName": "__init__", "type": "Callable[[Any, Any, Any, Any, Any, Any, Any, Any], None]"}, {"lineNumber": 183, "col_offset": 15, "nodeName": "PGProbRatioModel", "type": "Type[tensorforce.models.pg_prob_ratio_model.PGProbRatioModel]"}, {"lineNumber": 136, "col_offset": 18, "nodeName": "TensorForceError", "type": "Type[tensorforce.exception.TensorForceError]"}, {"lineNumber": 172, "col_offset": 24, "nodeName": "states_spec", "type": "Any"}, {"lineNumber": 173, "col_offset": 25, "nodeName": "actions_spec", "type": "Any"}, {"lineNumber": 174, "col_offset": 26, "nodeName": "preprocessing", "type": "Any"}, {"lineNumber": 175, "col_offset": 24, "nodeName": "exploration", "type": "Any"}, {"lineNumber": 176, "col_offset": 33, "nodeName": "reward_preprocessing", "type": "Any"}, {"lineNumber": 177, "col_offset": 28, "nodeName": "batched_observe", "type": "Any"}, {"lineNumber": 178, "col_offset": 23, "nodeName": "batch_size", "type": "Any"}, {"lineNumber": 179, "col_offset": 31, "nodeName": "keep_last_timestep", "type": "Any"}, {"lineNumber": 184, "col_offset": 24, "nodeName": "states_spec", "type": "Any"}, {"lineNumber": 185, "col_offset": 25, "nodeName": "actions_spec", "type": "Any"}, {"lineNumber": 186, "col_offset": 25, "nodeName": "network_spec", "type": "Any"}, {"lineNumber": 187, "col_offset": 19, "nodeName": "device", "type": "Any"}, {"lineNumber": 188, "col_offset": 18, "nodeName": "scope", "type": "Any"}, {"lineNumber": 189, "col_offset": 23, "nodeName": "saver_spec", "type": "Any"}, {"lineNumber": 190, "col_offset": 25, "nodeName": "summary_spec", "type": "Any"}, {"lineNumber": 191, "col_offset": 29, "nodeName": "distributed_spec", "type": "Any"}, {"lineNumber": 192, "col_offset": 22, "nodeName": "optimizer", "type": "Dict[Any, Any]"}, {"lineNumber": 193, "col_offset": 21, "nodeName": "discount", "type": "Any"}, {"lineNumber": 194, "col_offset": 30, "nodeName": "normalize_rewards", "type": "Any"}, {"lineNumber": 195, "col_offset": 27, "nodeName": "variable_noise", "type": "Any"}, {"lineNumber": 196, "col_offset": 31, "nodeName": "distributions_spec", "type": "Any"}, {"lineNumber": 197, "col_offset": 35, "nodeName": "entropy_regularization", "type": "Any"}, {"lineNumber": 198, "col_offset": 26, "nodeName": "baseline_mode", "type": "Any"}, {"lineNumber": 199, "col_offset": 21, "nodeName": "baseline", "type": "Any"}, {"lineNumber": 200, "col_offset": 31, "nodeName": "baseline_optimizer", "type": "Any"}, {"lineNumber": 201, "col_offset": 23, "nodeName": "gae_lambda", "type": "Any"}, {"lineNumber": 202, "col_offset": 38, "nodeName": "likelihood_ratio_clipping", "type": "Any"}, {"lineNumber": 140, "col_offset": 22, "nodeName": "dict", "type": "Type[Dict[Any, Any]]"}, {"lineNumber": 171, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 171, "col_offset": 14, "nodeName": "TRPOAgent", "type": "Type[TRPOAgent]"}, {"lineNumber": 171, "col_offset": 25, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 186, "col_offset": 25, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 187, "col_offset": 19, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 188, "col_offset": 18, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 189, "col_offset": 23, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 190, "col_offset": 25, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 191, "col_offset": 29, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 192, "col_offset": 22, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 193, "col_offset": 21, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 194, "col_offset": 30, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 195, "col_offset": 27, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 196, "col_offset": 31, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 197, "col_offset": 35, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 198, "col_offset": 26, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 199, "col_offset": 21, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 200, "col_offset": 31, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 201, "col_offset": 23, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 202, "col_offset": 38, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 142, "col_offset": 30, "nodeName": "learning_rate", "type": "Any"}, {"lineNumber": 143, "col_offset": 34, "nodeName": "cg_max_iterations", "type": "Any"}, {"lineNumber": 144, "col_offset": 27, "nodeName": "cg_damping", "type": "Any"}, {"lineNumber": 145, "col_offset": 31, "nodeName": "cg_unroll_loop", "type": "Any"}]