[{"lineNumber": 25, "col_offset": 16, "nodeName": "BatchAgent", "type": "Type[tensorforce.agents.batch_agent.BatchAgent]"}, {"lineNumber": 129, "col_offset": 8, "nodeName": "network_spec", "type": "Any"}, {"lineNumber": 129, "col_offset": 28, "nodeName": "network_spec", "type": "Any"}, {"lineNumber": 130, "col_offset": 8, "nodeName": "device", "type": "Any"}, {"lineNumber": 130, "col_offset": 22, "nodeName": "device", "type": "Any"}, {"lineNumber": 131, "col_offset": 8, "nodeName": "scope", "type": "Any"}, {"lineNumber": 131, "col_offset": 21, "nodeName": "scope", "type": "Any"}, {"lineNumber": 132, "col_offset": 8, "nodeName": "saver_spec", "type": "Any"}, {"lineNumber": 132, "col_offset": 26, "nodeName": "saver_spec", "type": "Any"}, {"lineNumber": 133, "col_offset": 8, "nodeName": "summary_spec", "type": "Any"}, {"lineNumber": 133, "col_offset": 28, "nodeName": "summary_spec", "type": "Any"}, {"lineNumber": 134, "col_offset": 8, "nodeName": "distributed_spec", "type": "Any"}, {"lineNumber": 134, "col_offset": 32, "nodeName": "distributed_spec", "type": "Any"}, {"lineNumber": 135, "col_offset": 8, "nodeName": "discount", "type": "Any"}, {"lineNumber": 135, "col_offset": 24, "nodeName": "discount", "type": "Any"}, {"lineNumber": 136, "col_offset": 8, "nodeName": "normalize_rewards", "type": "Any"}, {"lineNumber": 136, "col_offset": 33, "nodeName": "normalize_rewards", "type": "Any"}, {"lineNumber": 137, "col_offset": 8, "nodeName": "variable_noise", "type": "Any"}, {"lineNumber": 137, "col_offset": 30, "nodeName": "variable_noise", "type": "Any"}, {"lineNumber": 138, "col_offset": 8, "nodeName": "distributions_spec", "type": "Any"}, {"lineNumber": 138, "col_offset": 34, "nodeName": "distributions_spec", "type": "Any"}, {"lineNumber": 139, "col_offset": 8, "nodeName": "entropy_regularization", "type": "Any"}, {"lineNumber": 139, "col_offset": 38, "nodeName": "entropy_regularization", "type": "Any"}, {"lineNumber": 140, "col_offset": 8, "nodeName": "baseline_mode", "type": "Any"}, {"lineNumber": 140, "col_offset": 29, "nodeName": "baseline_mode", "type": "Any"}, {"lineNumber": 141, "col_offset": 8, "nodeName": "baseline", "type": "Any"}, {"lineNumber": 141, "col_offset": 24, "nodeName": "baseline", "type": "Any"}, {"lineNumber": 142, "col_offset": 8, "nodeName": "baseline_optimizer", "type": "Any"}, {"lineNumber": 142, "col_offset": 34, "nodeName": "baseline_optimizer", "type": "Any"}, {"lineNumber": 143, "col_offset": 8, "nodeName": "gae_lambda", "type": "Any"}, {"lineNumber": 143, "col_offset": 26, "nodeName": "gae_lambda", "type": "Any"}, {"lineNumber": 144, "col_offset": 8, "nodeName": "likelihood_ratio_clipping", "type": "Any"}, {"lineNumber": 144, "col_offset": 41, "nodeName": "likelihood_ratio_clipping", "type": "Any"}, {"lineNumber": 110, "col_offset": 11, "nodeName": "network_spec", "type": "Any"}, {"lineNumber": 113, "col_offset": 25, "nodeName": "dict", "type": "Type[Dict[Any, Any]]"}, {"lineNumber": 129, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 130, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 131, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 132, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 133, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 134, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 135, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 136, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 137, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 138, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 139, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 140, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 141, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 142, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 143, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 144, "col_offset": 8, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 146, "col_offset": 8, "nodeName": "__init__", "type": "Callable[[Any, Any, Any, Any, Any, Any, Any, Any], None]"}, {"lineNumber": 158, "col_offset": 15, "nodeName": "PGProbRatioModel", "type": "Type[tensorforce.models.pg_prob_ratio_model.PGProbRatioModel]"}, {"lineNumber": 111, "col_offset": 18, "nodeName": "TensorForceError", "type": "Type[tensorforce.exception.TensorForceError]"}, {"lineNumber": 147, "col_offset": 24, "nodeName": "states_spec", "type": "Any"}, {"lineNumber": 148, "col_offset": 25, "nodeName": "actions_spec", "type": "Any"}, {"lineNumber": 149, "col_offset": 26, "nodeName": "preprocessing", "type": "Any"}, {"lineNumber": 150, "col_offset": 24, "nodeName": "exploration", "type": "Any"}, {"lineNumber": 151, "col_offset": 33, "nodeName": "reward_preprocessing", "type": "Any"}, {"lineNumber": 152, "col_offset": 28, "nodeName": "batched_observe", "type": "Any"}, {"lineNumber": 153, "col_offset": 23, "nodeName": "batch_size", "type": "Any"}, {"lineNumber": 154, "col_offset": 31, "nodeName": "keep_last_timestep", "type": "Any"}, {"lineNumber": 159, "col_offset": 24, "nodeName": "states_spec", "type": "Any"}, {"lineNumber": 160, "col_offset": 25, "nodeName": "actions_spec", "type": "Any"}, {"lineNumber": 161, "col_offset": 25, "nodeName": "network_spec", "type": "Any"}, {"lineNumber": 162, "col_offset": 19, "nodeName": "device", "type": "Any"}, {"lineNumber": 163, "col_offset": 18, "nodeName": "scope", "type": "Any"}, {"lineNumber": 164, "col_offset": 23, "nodeName": "saver_spec", "type": "Any"}, {"lineNumber": 165, "col_offset": 25, "nodeName": "summary_spec", "type": "Any"}, {"lineNumber": 166, "col_offset": 29, "nodeName": "distributed_spec", "type": "Any"}, {"lineNumber": 167, "col_offset": 22, "nodeName": "optimizer", "type": "Dict[Any, Any]"}, {"lineNumber": 168, "col_offset": 21, "nodeName": "discount", "type": "Any"}, {"lineNumber": 169, "col_offset": 30, "nodeName": "normalize_rewards", "type": "Any"}, {"lineNumber": 170, "col_offset": 27, "nodeName": "variable_noise", "type": "Any"}, {"lineNumber": 171, "col_offset": 31, "nodeName": "distributions_spec", "type": "Any"}, {"lineNumber": 172, "col_offset": 35, "nodeName": "entropy_regularization", "type": "Any"}, {"lineNumber": 173, "col_offset": 26, "nodeName": "baseline_mode", "type": "Any"}, {"lineNumber": 174, "col_offset": 21, "nodeName": "baseline", "type": "Any"}, {"lineNumber": 175, "col_offset": 31, "nodeName": "baseline_optimizer", "type": "Any"}, {"lineNumber": 176, "col_offset": 23, "nodeName": "gae_lambda", "type": "Any"}, {"lineNumber": 177, "col_offset": 38, "nodeName": "likelihood_ratio_clipping", "type": "Any"}, {"lineNumber": 115, "col_offset": 22, "nodeName": "dict", "type": "Type[Dict[Any, Any]]"}, {"lineNumber": 146, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 146, "col_offset": 14, "nodeName": "TRPOAgent", "type": "Type[TRPOAgent]"}, {"lineNumber": 146, "col_offset": 25, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 161, "col_offset": 25, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 162, "col_offset": 19, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 163, "col_offset": 18, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 164, "col_offset": 23, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 165, "col_offset": 25, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 166, "col_offset": 29, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 167, "col_offset": 22, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 168, "col_offset": 21, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 169, "col_offset": 30, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 170, "col_offset": 27, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 171, "col_offset": 31, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 172, "col_offset": 35, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 173, "col_offset": 26, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 174, "col_offset": 21, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 175, "col_offset": 31, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 176, "col_offset": 23, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 177, "col_offset": 38, "nodeName": "self", "type": "TRPOAgent"}, {"lineNumber": 117, "col_offset": 30, "nodeName": "learning_rate", "type": "Any"}, {"lineNumber": 118, "col_offset": 34, "nodeName": "cg_max_iterations", "type": "Any"}, {"lineNumber": 119, "col_offset": 27, "nodeName": "cg_damping", "type": "Any"}, {"lineNumber": 120, "col_offset": 31, "nodeName": "cg_unroll_loop", "type": "Any"}]