[{"lineNumber": 23, "col_offset": 21, "nodeName": "Objective", "type": "Type[tensorforce.core.objectives.objective.Objective]"}, {"lineNumber": 47, "col_offset": 8, "nodeName": "ratio_based", "type": "Any"}, {"lineNumber": 47, "col_offset": 27, "nodeName": "ratio_based", "type": "Any"}, {"lineNumber": 49, "col_offset": 8, "nodeName": "clipping_value", "type": "Union[float, Any]"}, {"lineNumber": 55, "col_offset": 8, "nodeName": "early_reduce", "type": "Any"}, {"lineNumber": 55, "col_offset": 28, "nodeName": "early_reduce", "type": "Any"}, {"lineNumber": 67, "col_offset": 8, "nodeName": "zero", "type": "Any"}, {"lineNumber": 68, "col_offset": 8, "nodeName": "one", "type": "Any"}, {"lineNumber": 70, "col_offset": 8, "nodeName": "clipping_value", "type": "Any"}, {"lineNumber": 72, "col_offset": 11, "nodeName": "ratio_based", "type": "Any"}, {"lineNumber": 96, "col_offset": 8, "nodeName": "skip_clipping", "type": "Any"}, {"lineNumber": 97, "col_offset": 8, "nodeName": "scaled", "type": "Any"}, {"lineNumber": 99, "col_offset": 8, "nodeName": "loss", "type": "Any"}, {"lineNumber": 104, "col_offset": 15, "nodeName": "loss", "type": "Any"}, {"lineNumber": 112, "col_offset": 15, "nodeName": "reference", "type": "Any"}, {"lineNumber": 115, "col_offset": 8, "nodeName": "arguments", "type": "collections.OrderedDict[str, Callable[[Any, Any, Any, Any, Any], Any]]"}, {"lineNumber": 117, "col_offset": 11, "nodeName": "ratio_based", "type": "Any"}, {"lineNumber": 127, "col_offset": 15, "nodeName": "arguments", "type": "collections.OrderedDict[str, Callable[[Any, Any, Any, Any, Any], Any]]"}, {"lineNumber": 45, "col_offset": 8, "nodeName": "__init__", "type": "Callable[..., None]"}, {"lineNumber": 47, "col_offset": 8, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 49, "col_offset": 60, "nodeName": "clipping_value", "type": "Any"}, {"lineNumber": 50, "col_offset": 8, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 50, "col_offset": 30, "nodeName": "add_module", "type": "Callable[..., Any]"}, {"lineNumber": 55, "col_offset": 8, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 60, "col_offset": 15, "nodeName": "ratio_based", "type": "Any"}, {"lineNumber": 62, "col_offset": 26, "nodeName": "log_probability", "type": "Any"}, {"lineNumber": 67, "col_offset": 15, "nodeName": "constant", "type": "Any"}, {"lineNumber": 68, "col_offset": 14, "nodeName": "constant", "type": "Any"}, {"lineNumber": 70, "col_offset": 25, "nodeName": "value", "type": "Any"}, {"lineNumber": 72, "col_offset": 11, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 75, "col_offset": 12, "nodeName": "scaling", "type": "Any"}, {"lineNumber": 76, "col_offset": 12, "nodeName": "min_value", "type": "Any"}, {"lineNumber": 77, "col_offset": 12, "nodeName": "max_value", "type": "Any"}, {"lineNumber": 80, "col_offset": 12, "nodeName": "scaling", "type": "Any"}, {"lineNumber": 80, "col_offset": 22, "nodeName": "log_probability", "type": "Any"}, {"lineNumber": 81, "col_offset": 12, "nodeName": "min_value", "type": "Any"}, {"lineNumber": 82, "col_offset": 12, "nodeName": "max_value", "type": "Any"}, {"lineNumber": 84, "col_offset": 15, "nodeName": "early_reduce", "type": "Any"}, {"lineNumber": 85, "col_offset": 12, "nodeName": "reward", "type": "Any"}, {"lineNumber": 96, "col_offset": 24, "nodeName": "equal", "type": "Any"}, {"lineNumber": 97, "col_offset": 17, "nodeName": "cond", "type": "Callable[[Any, Any, Any], Any]"}, {"lineNumber": 99, "col_offset": 16, "nodeName": "scaled", "type": "Any"}, {"lineNumber": 101, "col_offset": 15, "nodeName": "early_reduce", "type": "Any"}, {"lineNumber": 102, "col_offset": 12, "nodeName": "loss", "type": "Any"}, {"lineNumber": 107, "col_offset": 20, "nodeName": "log_probability", "type": "Any"}, {"lineNumber": 115, "col_offset": 20, "nodeName": "optimizer_arguments", "type": "Callable[..., collections.OrderedDict[Any, Any]]"}, {"lineNumber": 117, "col_offset": 11, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 125, "col_offset": 40, "nodeName": "fn_reference", "type": "Callable[[Any, Any, Any, Any, Any], Any]"}, {"lineNumber": 45, "col_offset": 30, "nodeName": "name", "type": "Any"}, {"lineNumber": 45, "col_offset": 51, "nodeName": "summary_labels", "type": "Any"}, {"lineNumber": 49, "col_offset": 32, "nodeName": "clipping_value", "type": "Any"}, {"lineNumber": 51, "col_offset": 42, "nodeName": "clipping_value", "type": "Union[float, Any]"}, {"lineNumber": 51, "col_offset": 66, "nodeName": "parameter_modules", "type": "Dict[Any, Any]"}, {"lineNumber": 60, "col_offset": 15, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 60, "col_offset": 35, "nodeName": "reference", "type": "Any"}, {"lineNumber": 62, "col_offset": 26, "nodeName": "policy", "type": "Any"}, {"lineNumber": 63, "col_offset": 19, "nodeName": "states", "type": "Any"}, {"lineNumber": 63, "col_offset": 37, "nodeName": "internals", "type": "Any"}, {"lineNumber": 63, "col_offset": 60, "nodeName": "auxiliaries", "type": "Any"}, {"lineNumber": 63, "col_offset": 81, "nodeName": "actions", "type": "Any"}, {"lineNumber": 64, "col_offset": 20, "nodeName": "early_reduce", "type": "Any"}, {"lineNumber": 67, "col_offset": 15, "nodeName": "tf", "type": "Any"}, {"lineNumber": 68, "col_offset": 14, "nodeName": "tf", "type": "Any"}, {"lineNumber": 70, "col_offset": 25, "nodeName": "clipping_value", "type": "Any"}, {"lineNumber": 73, "col_offset": 15, "nodeName": "reference", "type": "Any"}, {"lineNumber": 74, "col_offset": 16, "nodeName": "reference", "type": "Any"}, {"lineNumber": 74, "col_offset": 28, "nodeName": "log_probability", "type": "Any"}, {"lineNumber": 75, "col_offset": 22, "nodeName": "exp", "type": "Any"}, {"lineNumber": 76, "col_offset": 24, "nodeName": "one", "type": "Any"}, {"lineNumber": 77, "col_offset": 24, "nodeName": "one", "type": "Any"}, {"lineNumber": 77, "col_offset": 30, "nodeName": "clipping_value", "type": "Any"}, {"lineNumber": 81, "col_offset": 25, "nodeName": "clipping_value", "type": "Any"}, {"lineNumber": 82, "col_offset": 24, "nodeName": "log_probability", "type": "Any"}, {"lineNumber": 82, "col_offset": 42, "nodeName": "one", "type": "Any"}, {"lineNumber": 84, "col_offset": 15, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 85, "col_offset": 21, "nodeName": "expand_dims", "type": "Any"}, {"lineNumber": 88, "col_offset": 19, "nodeName": "scaling", "type": "Any"}, {"lineNumber": 88, "col_offset": 29, "nodeName": "reward", "type": "Any"}, {"lineNumber": 91, "col_offset": 30, "nodeName": "clip_by_value", "type": "Any"}, {"lineNumber": 94, "col_offset": 19, "nodeName": "minimum", "type": "Any"}, {"lineNumber": 96, "col_offset": 24, "nodeName": "math", "type": "Any"}, {"lineNumber": 96, "col_offset": 40, "nodeName": "clipping_value", "type": "Any"}, {"lineNumber": 96, "col_offset": 58, "nodeName": "zero", "type": "Any"}, {"lineNumber": 97, "col_offset": 17, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 97, "col_offset": 32, "nodeName": "skip_clipping", "type": "Any"}, {"lineNumber": 97, "col_offset": 55, "nodeName": "no_clipping", "type": "Callable[[], Any]"}, {"lineNumber": 97, "col_offset": 77, "nodeName": "apply_clipping", "type": "Callable[[], Any]"}, {"lineNumber": 101, "col_offset": 15, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 102, "col_offset": 19, "nodeName": "reduce_mean", "type": "Any"}, {"lineNumber": 107, "col_offset": 20, "nodeName": "policy", "type": "Any"}, {"lineNumber": 108, "col_offset": 19, "nodeName": "states", "type": "Any"}, {"lineNumber": 108, "col_offset": 37, "nodeName": "internals", "type": "Any"}, {"lineNumber": 108, "col_offset": 60, "nodeName": "auxiliaries", "type": "Any"}, {"lineNumber": 108, "col_offset": 81, "nodeName": "actions", "type": "Any"}, {"lineNumber": 109, "col_offset": 20, "nodeName": "early_reduce", "type": "Any"}, {"lineNumber": 125, "col_offset": 12, "nodeName": "arguments", "type": "collections.OrderedDict[str, Callable[[Any, Any, Any, Any, Any], Any]]"}, {"lineNumber": 45, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 64, "col_offset": 20, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 67, "col_offset": 44, "nodeName": "tf_dtype", "type": "Callable[[Any], Any]"}, {"lineNumber": 68, "col_offset": 43, "nodeName": "tf_dtype", "type": "Callable[[Any], Any]"}, {"lineNumber": 70, "col_offset": 25, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 75, "col_offset": 22, "nodeName": "tf", "type": "Any"}, {"lineNumber": 76, "col_offset": 31, "nodeName": "one", "type": "Any"}, {"lineNumber": 76, "col_offset": 37, "nodeName": "clipping_value", "type": "Any"}, {"lineNumber": 85, "col_offset": 21, "nodeName": "tf", "type": "Any"}, {"lineNumber": 85, "col_offset": 42, "nodeName": "reward", "type": "Any"}, {"lineNumber": 91, "col_offset": 30, "nodeName": "tf", "type": "Any"}, {"lineNumber": 92, "col_offset": 18, "nodeName": "scaling", "type": "Any"}, {"lineNumber": 92, "col_offset": 42, "nodeName": "min_value", "type": "Any"}, {"lineNumber": 92, "col_offset": 68, "nodeName": "max_value", "type": "Any"}, {"lineNumber": 94, "col_offset": 19, "nodeName": "tf", "type": "Any"}, {"lineNumber": 96, "col_offset": 24, "nodeName": "tf", "type": "Any"}, {"lineNumber": 102, "col_offset": 19, "nodeName": "math", "type": "Any"}, {"lineNumber": 102, "col_offset": 52, "nodeName": "loss", "type": "Any"}, {"lineNumber": 109, "col_offset": 20, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 115, "col_offset": 20, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 120, "col_offset": 23, "nodeName": "reference", "type": "Any"}, {"lineNumber": 67, "col_offset": 44, "nodeName": "util", "type": "module"}, {"lineNumber": 68, "col_offset": 43, "nodeName": "util", "type": "module"}, {"lineNumber": 75, "col_offset": 32, "nodeName": "log_probability", "type": "Any"}, {"lineNumber": 94, "col_offset": 33, "nodeName": "scaling", "type": "Any"}, {"lineNumber": 94, "col_offset": 43, "nodeName": "reward", "type": "Any"}, {"lineNumber": 94, "col_offset": 55, "nodeName": "clipped_scaling", "type": "Any"}, {"lineNumber": 94, "col_offset": 73, "nodeName": "reward", "type": "Any"}, {"lineNumber": 102, "col_offset": 19, "nodeName": "tf", "type": "Any"}, {"lineNumber": 120, "col_offset": 23, "nodeName": "self", "type": "PolicyGradient"}, {"lineNumber": 121, "col_offset": 27, "nodeName": "policy", "type": "Any"}, {"lineNumber": 121, "col_offset": 42, "nodeName": "states", "type": "Any"}, {"lineNumber": 121, "col_offset": 60, "nodeName": "internals", "type": "Any"}, {"lineNumber": 121, "col_offset": 83, "nodeName": "auxiliaries", "type": "Any"}, {"lineNumber": 122, "col_offset": 28, "nodeName": "actions", "type": "Any"}, {"lineNumber": 75, "col_offset": 50, "nodeName": "stop_gradient", "type": "Any"}, {"lineNumber": 75, "col_offset": 50, "nodeName": "tf", "type": "Any"}, {"lineNumber": 75, "col_offset": 73, "nodeName": "reference", "type": "Any"}]