[{"lineNumber": 28, "col_offset": 15, "nodeName": "PolicyGradientModel", "type": "Type[tensorforce.core.policy_gradient_model.PolicyGradientModel]"}, {"lineNumber": 30, "col_offset": 4, "nodeName": "allows_discrete_actions", "type": "bool"}, {"lineNumber": 31, "col_offset": 4, "nodeName": "allows_continuous_actions", "type": "bool"}, {"lineNumber": 32, "col_offset": 4, "nodeName": "default_config", "type": "Dict[nothing, nothing]"}, {"lineNumber": 32, "col_offset": 21, "nodeName": "dict", "type": "Type[Dict[Any, Any]]"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "default", "type": "Any"}, {"lineNumber": 35, "col_offset": 23, "nodeName": "default_config", "type": "Dict[nothing, nothing]"}, {"lineNumber": 36, "col_offset": 8, "nodeName": "__init__", "type": "Callable[[Any], None]"}, {"lineNumber": 36, "col_offset": 39, "nodeName": "config", "type": "Any"}, {"lineNumber": 39, "col_offset": 8, "nodeName": "create_tf_operations", "type": "Callable[[Any], None]"}, {"lineNumber": 39, "col_offset": 51, "nodeName": "config", "type": "Any"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "config", "type": "Any"}, {"lineNumber": 35, "col_offset": 23, "nodeName": "VPGModel", "type": "Type[VPGModel]"}, {"lineNumber": 41, "col_offset": 13, "nodeName": "variable_scope", "type": "Any"}, {"lineNumber": 42, "col_offset": 16, "nodeName": "name", "type": "Any"}, {"lineNumber": 42, "col_offset": 22, "nodeName": "action", "type": "Any"}, {"lineNumber": 42, "col_offset": 32, "nodeName": "items", "type": "Any"}, {"lineNumber": 43, "col_offset": 16, "nodeName": "log_prob", "type": "Any"}, {"lineNumber": 44, "col_offset": 16, "nodeName": "loss_per_instance", "type": "Any"}, {"lineNumber": 45, "col_offset": 16, "nodeName": "loss", "type": "Any"}, {"lineNumber": 36, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 36, "col_offset": 14, "nodeName": "VPGModel", "type": "Type[VPGModel]"}, {"lineNumber": 36, "col_offset": 24, "nodeName": "self", "type": "VPGModel"}, {"lineNumber": 39, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 39, "col_offset": 14, "nodeName": "VPGModel", "type": "Type[VPGModel]"}, {"lineNumber": 39, "col_offset": 24, "nodeName": "self", "type": "VPGModel"}, {"lineNumber": 41, "col_offset": 13, "nodeName": "tf", "type": "Any"}, {"lineNumber": 42, "col_offset": 32, "nodeName": "action", "type": "Any"}, {"lineNumber": 43, "col_offset": 27, "nodeName": "log_probability", "type": "Any"}, {"lineNumber": 44, "col_offset": 16, "nodeName": "self", "type": "VPGModel"}, {"lineNumber": 44, "col_offset": 41, "nodeName": "multiply", "type": "Any"}, {"lineNumber": 46, "col_offset": 16, "nodeName": "add_loss", "type": "Any"}, {"lineNumber": 46, "col_offset": 35, "nodeName": "loss", "type": "Any"}, {"lineNumber": 42, "col_offset": 32, "nodeName": "self", "type": "VPGModel"}, {"lineNumber": 43, "col_offset": 74, "nodeName": "action", "type": "Any"}, {"lineNumber": 44, "col_offset": 41, "nodeName": "tf", "type": "Any"}, {"lineNumber": 44, "col_offset": 55, "nodeName": "log_prob", "type": "Any"}, {"lineNumber": 44, "col_offset": 67, "nodeName": "reward", "type": "Any"}, {"lineNumber": 45, "col_offset": 24, "nodeName": "reduce_mean", "type": "Any"}, {"lineNumber": 46, "col_offset": 16, "nodeName": "losses", "type": "Any"}, {"lineNumber": 43, "col_offset": 27, "nodeName": "distribution", "type": "Dict[Any, Any]"}, {"lineNumber": 44, "col_offset": 67, "nodeName": "self", "type": "VPGModel"}, {"lineNumber": 45, "col_offset": 24, "nodeName": "tf", "type": "Any"}, {"lineNumber": 45, "col_offset": 52, "nodeName": "loss_per_instance", "type": "Any"}, {"lineNumber": 46, "col_offset": 16, "nodeName": "tf", "type": "Any"}, {"lineNumber": 43, "col_offset": 27, "nodeName": "self", "type": "VPGModel"}, {"lineNumber": 43, "col_offset": 45, "nodeName": "name", "type": "Any"}, {"lineNumber": 45, "col_offset": 52, "nodeName": "self", "type": "VPGModel"}]