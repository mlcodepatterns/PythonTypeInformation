[{"lineNumber": 8, "col_offset": 20, "nodeName": "TestCase", "type": "Any"}, {"lineNumber": 8, "col_offset": 20, "nodeName": "test", "type": "Any"}, {"lineNumber": 39, "col_offset": 3, "nodeName": "__name__", "type": "str"}, {"lineNumber": 8, "col_offset": 20, "nodeName": "tf", "type": "Any"}, {"lineNumber": 11, "col_offset": 4, "nodeName": "text", "type": "Any"}, {"lineNumber": 12, "col_offset": 4, "nodeName": "tokens", "type": "Any"}, {"lineNumber": 19, "col_offset": 4, "nodeName": "tokens", "type": "Any"}, {"lineNumber": 40, "col_offset": 2, "nodeName": "main", "type": "Any"}, {"lineNumber": 11, "col_offset": 11, "nodeName": "constant", "type": "Any"}, {"lineNumber": 11, "col_offset": 23, "nodeName": "text", "type": "Any"}, {"lineNumber": 12, "col_offset": 13, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 12, "col_offset": 23, "nodeName": "text", "type": "Any"}, {"lineNumber": 13, "col_offset": 32, "nodeName": "sess", "type": "Any"}, {"lineNumber": 14, "col_offset": 6, "nodeName": "tokens", "type": "Any"}, {"lineNumber": 15, "col_offset": 6, "nodeName": "tokens", "type": "List[Any]"}, {"lineNumber": 19, "col_offset": 13, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 19, "col_offset": 23, "nodeName": "text", "type": "Any"}, {"lineNumber": 20, "col_offset": 4, "nodeName": "assertAllEqual", "type": "Any"}, {"lineNumber": 20, "col_offset": 24, "nodeName": "ref_tokens", "type": "Any"}, {"lineNumber": 20, "col_offset": 36, "nodeName": "tokens", "type": "Any"}, {"lineNumber": 23, "col_offset": 4, "nodeName": "_testTokenizerOnTensor", "type": "Callable[[Any, Any, Any], Any]"}, {"lineNumber": 23, "col_offset": 32, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 23, "col_offset": 43, "nodeName": "text", "type": "Any"}, {"lineNumber": 23, "col_offset": 49, "nodeName": "ref_tokens", "type": "Any"}, {"lineNumber": 24, "col_offset": 4, "nodeName": "_testTokenizerOnString", "type": "Callable[[Any, Any, Any], Any]"}, {"lineNumber": 24, "col_offset": 32, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 24, "col_offset": 43, "nodeName": "text", "type": "Any"}, {"lineNumber": 24, "col_offset": 49, "nodeName": "ref_tokens", "type": "Any"}, {"lineNumber": 27, "col_offset": 4, "nodeName": "_testTokenizer", "type": "Callable[[Any, Any, Any], Any]"}, {"lineNumber": 33, "col_offset": 4, "nodeName": "_testTokenizer", "type": "Callable[[Any, Any, Any], Any]"}, {"lineNumber": 40, "col_offset": 2, "nodeName": "test", "type": "Any"}, {"lineNumber": 11, "col_offset": 11, "nodeName": "tf", "type": "Any"}, {"lineNumber": 13, "col_offset": 9, "nodeName": "test_session", "type": "Any"}, {"lineNumber": 14, "col_offset": 15, "nodeName": "run", "type": "Any"}, {"lineNumber": 14, "col_offset": 24, "nodeName": "tokens", "type": "Any"}, {"lineNumber": 16, "col_offset": 6, "nodeName": "assertAllEqual", "type": "Any"}, {"lineNumber": 16, "col_offset": 26, "nodeName": "ref_tokens", "type": "Any"}, {"lineNumber": 16, "col_offset": 38, "nodeName": "tokens", "type": "List[Any]"}, {"lineNumber": 20, "col_offset": 4, "nodeName": "self", "type": "TokenizerTest"}, {"lineNumber": 23, "col_offset": 4, "nodeName": "self", "type": "TokenizerTest"}, {"lineNumber": 24, "col_offset": 4, "nodeName": "self", "type": "TokenizerTest"}, {"lineNumber": 27, "col_offset": 4, "nodeName": "self", "type": "TokenizerTest"}, {"lineNumber": 28, "col_offset": 8, "nodeName": "SpaceTokenizer", "type": "Type[opennmt.tokenizers.tokenizer.SpaceTokenizer]"}, {"lineNumber": 33, "col_offset": 4, "nodeName": "self", "type": "TokenizerTest"}, {"lineNumber": 34, "col_offset": 8, "nodeName": "CharacterTokenizer", "type": "Type[opennmt.tokenizers.tokenizer.CharacterTokenizer]"}, {"lineNumber": 40, "col_offset": 2, "nodeName": "tf", "type": "Any"}, {"lineNumber": 13, "col_offset": 9, "nodeName": "self", "type": "TokenizerTest"}, {"lineNumber": 14, "col_offset": 15, "nodeName": "sess", "type": "Any"}, {"lineNumber": 15, "col_offset": 16, "nodeName": "decode", "type": "Any"}, {"lineNumber": 15, "col_offset": 42, "nodeName": "token", "type": "Any"}, {"lineNumber": 15, "col_offset": 51, "nodeName": "tokens", "type": "Any"}, {"lineNumber": 16, "col_offset": 6, "nodeName": "self", "type": "TokenizerTest"}, {"lineNumber": 15, "col_offset": 16, "nodeName": "token", "type": "Any"}]