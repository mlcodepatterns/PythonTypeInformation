[{"lineNumber": 63, "col_offset": 0, "nodeName": "create_runner", "type": "Callable[[Any, Any], Any]"}, {"lineNumber": 84, "col_offset": 25, "nodeName": "Runner", "type": "Any"}, {"lineNumber": 109, "col_offset": 2, "nodeName": "_create_directories", "type": "Callable[[Any], Any]"}, {"lineNumber": 114, "col_offset": 2, "nodeName": "_initialize_checkpointer_and_maybe_resume", "type": "Callable[[Any, Any], Any]"}, {"lineNumber": 121, "col_offset": 2, "nodeName": "_run_one_iteration", "type": "Callable[[Any, Any], Any]"}, {"lineNumber": 142, "col_offset": 2, "nodeName": "_save_tensorboard_summaries", "type": "Callable[[Any, Any, Any, Any], Any]"}, {"lineNumber": 84, "col_offset": 25, "nodeName": "run_experiment", "type": "Any"}, {"lineNumber": 53, "col_offset": 9, "nodeName": "agent_name", "type": "Any"}, {"lineNumber": 54, "col_offset": 5, "nodeName": "agent_name", "type": "Any"}, {"lineNumber": 77, "col_offset": 9, "nodeName": "base_dir", "type": "Any"}, {"lineNumber": 78, "col_offset": 9, "nodeName": "trained_agent_checkpoint_path", "type": "Any"}, {"lineNumber": 79, "col_offset": 9, "nodeName": "BisimulationRunner", "type": "Any"}, {"lineNumber": 79, "col_offset": 28, "nodeName": "base_dir", "type": "Any"}, {"lineNumber": 79, "col_offset": 38, "nodeName": "trained_agent_checkpoint_path", "type": "Any"}, {"lineNumber": 80, "col_offset": 28, "nodeName": "create_agent", "type": "Any"}, {"lineNumber": 105, "col_offset": 4, "nodeName": "_trained_agent_checkpoint_path", "type": "Any"}, {"lineNumber": 105, "col_offset": 42, "nodeName": "trained_agent_checkpoint_path", "type": "Any"}, {"lineNumber": 107, "col_offset": 4, "nodeName": "source_state_step", "type": "Any"}, {"lineNumber": 107, "col_offset": 29, "nodeName": "source_state_step", "type": "Any"}, {"lineNumber": 111, "col_offset": 4, "nodeName": "_visualize_dir", "type": "Any"}, {"lineNumber": 119, "col_offset": 4, "nodeName": "_start_iteration", "type": "int"}, {"lineNumber": 135, "col_offset": 4, "nodeName": "statistics", "type": "Any"}, {"lineNumber": 140, "col_offset": 11, "nodeName": "data_lists", "type": "Any"}, {"lineNumber": 161, "col_offset": 4, "nodeName": "eval_mode", "type": "bool"}, {"lineNumber": 164, "col_offset": 4, "nodeName": "global_step", "type": "int"}, {"lineNumber": 191, "col_offset": 4, "nodeName": "sorted_dir", "type": "Any"}, {"lineNumber": 55, "col_offset": 11, "nodeName": "BisimulationRainbowAgent", "type": "Any"}, {"lineNumber": 56, "col_offset": 8, "nodeName": "sess", "type": "Any"}, {"lineNumber": 60, "col_offset": 10, "nodeName": "ValueError", "type": "Type[ValueError]"}, {"lineNumber": 104, "col_offset": 11, "nodeName": "base_dir", "type": "Any"}, {"lineNumber": 105, "col_offset": 4, "nodeName": "self", "type": "Any"}, {"lineNumber": 106, "col_offset": 4, "nodeName": "__init__", "type": "Any"}, {"lineNumber": 106, "col_offset": 45, "nodeName": "base_dir", "type": "Any"}, {"lineNumber": 106, "col_offset": 55, "nodeName": "create_agent_fn", "type": "Any"}, {"lineNumber": 107, "col_offset": 4, "nodeName": "self", "type": "Any"}, {"lineNumber": 110, "col_offset": 4, "nodeName": "_create_directories", "type": "Any"}, {"lineNumber": 111, "col_offset": 4, "nodeName": "self", "type": "Any"}, {"lineNumber": 111, "col_offset": 26, "nodeName": "join", "type": "Callable"}, {"lineNumber": 111, "col_offset": 39, "nodeName": "_base_dir", "type": "Any"}, {"lineNumber": 112, "col_offset": 4, "nodeName": "MakeDirs", "type": "Any"}, {"lineNumber": 112, "col_offset": 22, "nodeName": "_visualize_dir", "type": "Any"}, {"lineNumber": 115, "col_offset": 4, "nodeName": "reload_checkpoint", "type": "Any"}, {"lineNumber": 116, "col_offset": 8, "nodeName": "_trained_agent_checkpoint_path", "type": "Any"}, {"lineNumber": 117, "col_offset": 4, "nodeName": "self", "type": "Any"}, {"lineNumber": 117, "col_offset": 25, "nodeName": "Checkpointer", "type": "Any"}, {"lineNumber": 117, "col_offset": 51, "nodeName": "_checkpoint_dir", "type": "Any"}, {"lineNumber": 118, "col_offset": 51, "nodeName": "checkpoint_file_prefix", "type": "Any"}, {"lineNumber": 119, "col_offset": 4, "nodeName": "self", "type": "Any"}, {"lineNumber": 135, "col_offset": 17, "nodeName": "IterationStatistics", "type": "Any"}, {"lineNumber": 136, "col_offset": 4, "nodeName": "info", "type": "Any"}, {"lineNumber": 136, "col_offset": 45, "nodeName": "iteration", "type": "Any"}, {"lineNumber": 137, "col_offset": 4, "nodeName": "num_episodes", "type": "Any"}, {"lineNumber": 137, "col_offset": 18, "nodeName": "average_reward", "type": "Any"}, {"lineNumber": 137, "col_offset": 35, "nodeName": "_run_eval_phase", "type": "Any"}, {"lineNumber": 137, "col_offset": 56, "nodeName": "statistics", "type": "Any"}, {"lineNumber": 139, "col_offset": 4, "nodeName": "_save_tensorboard_summaries", "type": "Callable[[Any, Any, Any], Any]"}, {"lineNumber": 139, "col_offset": 37, "nodeName": "iteration", "type": "Any"}, {"lineNumber": 139, "col_offset": 48, "nodeName": "num_episodes", "type": "Any"}, {"lineNumber": 139, "col_offset": 62, "nodeName": "average_reward", "type": "Any"}, {"lineNumber": 140, "col_offset": 11, "nodeName": "statistics", "type": "Any"}, {"lineNumber": 152, "col_offset": 14, "nodeName": "Summary", "type": "Any"}, {"lineNumber": 157, "col_offset": 4, "nodeName": "add_summary", "type": "Any"}, {"lineNumber": 157, "col_offset": 37, "nodeName": "summary", "type": "Any"}, {"lineNumber": 157, "col_offset": 46, "nodeName": "iteration", "type": "Any"}, {"lineNumber": 161, "col_offset": 4, "nodeName": "_agent", "type": "Any"}, {"lineNumber": 162, "col_offset": 17, "nodeName": "AgentVisualizer", "type": "Any"}, {"lineNumber": 165, "col_offset": 10, "nodeName": "global_step", "type": "int"}, {"lineNumber": 165, "col_offset": 24, "nodeName": "num_global_steps", "type": "Any"}, {"lineNumber": 166, "col_offset": 6, "nodeName": "initial_observation", "type": "Any"}, {"lineNumber": 167, "col_offset": 6, "nodeName": "action", "type": "Any"}, {"lineNumber": 168, "col_offset": 6, "nodeName": "total_reward", "type": "float"}, {"lineNumber": 169, "col_offset": 6, "nodeName": "local_step", "type": "int"}, {"lineNumber": 170, "col_offset": 6, "nodeName": "start_state", "type": "bool"}, {"lineNumber": 190, "col_offset": 4, "nodeName": "generate_video", "type": "Any"}, {"lineNumber": 191, "col_offset": 17, "nodeName": "join", "type": "Callable"}, {"lineNumber": 191, "col_offset": 30, "nodeName": "_visualize_dir", "type": "Any"}, {"lineNumber": 192, "col_offset": 4, "nodeName": "MakeDirs", "type": "Any"}, {"lineNumber": 192, "col_offset": 22, "nodeName": "sorted_dir", "type": "Any"}, {"lineNumber": 193, "col_offset": 4, "nodeName": "print_sorted_frames", "type": "Any"}, {"lineNumber": 193, "col_offset": 35, "nodeName": "sorted_dir", "type": "Any"}, {"lineNumber": 55, "col_offset": 11, "nodeName": "rainbow_agent", "type": "module"}, {"lineNumber": 56, "col_offset": 26, "nodeName": "n", "type": "Any"}, {"lineNumber": 57, "col_offset": 23, "nodeName": "summary_writer", "type": "Any"}, {"lineNumber": 58, "col_offset": 29, "nodeName": "evaluate_metric_only", "type": "Any"}, {"lineNumber": 60, "col_offset": 21, "nodeName": "format", "type": "Callable[..., str]"}, {"lineNumber": 60, "col_offset": 48, "nodeName": "agent_name", "type": "Any"}, {"lineNumber": 111, "col_offset": 26, "nodeName": "path", "type": "module"}, {"lineNumber": 111, "col_offset": 39, "nodeName": "self", "type": "Any"}, {"lineNumber": 112, "col_offset": 4, "nodeName": "gfile", "type": "Any"}, {"lineNumber": 112, "col_offset": 22, "nodeName": "self", "type": "Any"}, {"lineNumber": 115, "col_offset": 4, "nodeName": "_agent", "type": "Any"}, {"lineNumber": 116, "col_offset": 8, "nodeName": "self", "type": "Any"}, {"lineNumber": 117, "col_offset": 25, "nodeName": "checkpointer", "type": "Any"}, {"lineNumber": 135, "col_offset": 17, "nodeName": "iteration_statistics", "type": "Any"}, {"lineNumber": 136, "col_offset": 4, "nodeName": "logging", "type": "Any"}, {"lineNumber": 137, "col_offset": 35, "nodeName": "self", "type": "Any"}, {"lineNumber": 139, "col_offset": 4, "nodeName": "self", "type": "Any"}, {"lineNumber": 152, "col_offset": 14, "nodeName": "tf", "type": "Any"}, {"lineNumber": 157, "col_offset": 4, "nodeName": "_summary_writer", "type": "Any"}, {"lineNumber": 161, "col_offset": 4, "nodeName": "self", "type": "Any"}, {"lineNumber": 162, "col_offset": 17, "nodeName": "agent_visualizer", "type": "module"}, {"lineNumber": 163, "col_offset": 20, "nodeName": "_visualize_dir", "type": "Any"}, {"lineNumber": 166, "col_offset": 28, "nodeName": "reset", "type": "Any"}, {"lineNumber": 167, "col_offset": 15, "nodeName": "begin_episode", "type": "Any"}, {"lineNumber": 167, "col_offset": 41, "nodeName": "initial_observation", "type": "Any"}, {"lineNumber": 172, "col_offset": 8, "nodeName": "set_source_state", "type": "bool"}, {"lineNumber": 174, "col_offset": 8, "nodeName": "total_reward", "type": "Any"}, {"lineNumber": 174, "col_offset": 24, "nodeName": "reward", "type": "Any"}, {"lineNumber": 175, "col_offset": 8, "nodeName": "global_step", "type": "int"}, {"lineNumber": 176, "col_offset": 8, "nodeName": "local_step", "type": "int"}, {"lineNumber": 179, "col_offset": 8, "nodeName": "start_state", "type": "bool"}, {"lineNumber": 189, "col_offset": 6, "nodeName": "_end_episode", "type": "Any"}, {"lineNumber": 189, "col_offset": 24, "nodeName": "reward", "type": "Any"}, {"lineNumber": 190, "col_offset": 4, "nodeName": "visualizer", "type": "Any"}, {"lineNumber": 191, "col_offset": 17, "nodeName": "path", "type": "module"}, {"lineNumber": 191, "col_offset": 30, "nodeName": "self", "type": "Any"}, {"lineNumber": 192, "col_offset": 4, "nodeName": "gfile", "type": "Any"}, {"lineNumber": 193, "col_offset": 4, "nodeName": "visualizer", "type": "Any"}, {"lineNumber": 56, "col_offset": 26, "nodeName": "action_space", "type": "Any"}, {"lineNumber": 106, "col_offset": 4, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 106, "col_offset": 10, "nodeName": "BisimulationRunner", "type": "Any"}, {"lineNumber": 106, "col_offset": 30, "nodeName": "self", "type": "Any"}, {"lineNumber": 110, "col_offset": 4, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 110, "col_offset": 10, "nodeName": "BisimulationRunner", "type": "Any"}, {"lineNumber": 110, "col_offset": 30, "nodeName": "self", "type": "Any"}, {"lineNumber": 111, "col_offset": 26, "nodeName": "os", "type": "module"}, {"lineNumber": 112, "col_offset": 4, "nodeName": "tf", "type": "Any"}, {"lineNumber": 115, "col_offset": 4, "nodeName": "self", "type": "Any"}, {"lineNumber": 136, "col_offset": 4, "nodeName": "tf", "type": "Any"}, {"lineNumber": 157, "col_offset": 4, "nodeName": "self", "type": "Any"}, {"lineNumber": 163, "col_offset": 20, "nodeName": "self", "type": "Any"}, {"lineNumber": 166, "col_offset": 28, "nodeName": "_environment", "type": "Any"}, {"lineNumber": 167, "col_offset": 15, "nodeName": "_agent", "type": "Any"}, {"lineNumber": 172, "col_offset": 27, "nodeName": "local_step", "type": "int"}, {"lineNumber": 172, "col_offset": 41, "nodeName": "source_state_step", "type": "Any"}, {"lineNumber": 173, "col_offset": 8, "nodeName": "observation", "type": "Any"}, {"lineNumber": 173, "col_offset": 21, "nodeName": "reward", "type": "Any"}, {"lineNumber": 173, "col_offset": 29, "nodeName": "is_terminal", "type": "Any"}, {"lineNumber": 173, "col_offset": 42, "nodeName": "_", "type": "Any"}, {"lineNumber": 173, "col_offset": 46, "nodeName": "step", "type": "Any"}, {"lineNumber": 173, "col_offset": 69, "nodeName": "action", "type": "Any"}, {"lineNumber": 177, "col_offset": 8, "nodeName": "visualize", "type": "Any"}, {"lineNumber": 177, "col_offset": 29, "nodeName": "_environment", "type": "Any"}, {"lineNumber": 177, "col_offset": 48, "nodeName": "_agent", "type": "Any"}, {"lineNumber": 177, "col_offset": 61, "nodeName": "start_state", "type": "bool"}, {"lineNumber": 178, "col_offset": 29, "nodeName": "set_source_state", "type": "bool"}, {"lineNumber": 180, "col_offset": 11, "nodeName": "game_over", "type": "Any"}, {"lineNumber": 182, "col_offset": 13, "nodeName": "is_terminal", "type": "Any"}, {"lineNumber": 189, "col_offset": 6, "nodeName": "self", "type": "Any"}, {"lineNumber": 191, "col_offset": 17, "nodeName": "os", "type": "module"}, {"lineNumber": 192, "col_offset": 4, "nodeName": "tf", "type": "Any"}, {"lineNumber": 56, "col_offset": 26, "nodeName": "environment", "type": "Any"}, {"lineNumber": 153, "col_offset": 8, "nodeName": "Value", "type": "Any"}, {"lineNumber": 154, "col_offset": 8, "nodeName": "Value", "type": "Any"}, {"lineNumber": 166, "col_offset": 28, "nodeName": "self", "type": "Any"}, {"lineNumber": 167, "col_offset": 15, "nodeName": "self", "type": "Any"}, {"lineNumber": 172, "col_offset": 41, "nodeName": "self", "type": "Any"}, {"lineNumber": 173, "col_offset": 46, "nodeName": "_environment", "type": "Any"}, {"lineNumber": 177, "col_offset": 8, "nodeName": "visualizer", "type": "Any"}, {"lineNumber": 177, "col_offset": 29, "nodeName": "self", "type": "Any"}, {"lineNumber": 177, "col_offset": 48, "nodeName": "self", "type": "Any"}, {"lineNumber": 180, "col_offset": 11, "nodeName": "_environment", "type": "Any"}, {"lineNumber": 180, "col_offset": 42, "nodeName": "global_step", "type": "int"}, {"lineNumber": 180, "col_offset": 57, "nodeName": "num_global_steps", "type": "Any"}, {"lineNumber": 184, "col_offset": 10, "nodeName": "action", "type": "Any"}, {"lineNumber": 185, "col_offset": 10, "nodeName": "start_state", "type": "bool"}, {"lineNumber": 153, "col_offset": 8, "nodeName": "Summary", "type": "Any"}, {"lineNumber": 153, "col_offset": 62, "nodeName": "num_episodes", "type": "Any"}, {"lineNumber": 154, "col_offset": 8, "nodeName": "Summary", "type": "Any"}, {"lineNumber": 155, "col_offset": 38, "nodeName": "average_reward", "type": "Any"}, {"lineNumber": 173, "col_offset": 46, "nodeName": "self", "type": "Any"}, {"lineNumber": 180, "col_offset": 11, "nodeName": "self", "type": "Any"}, {"lineNumber": 183, "col_offset": 10, "nodeName": "end_episode", "type": "Any"}, {"lineNumber": 183, "col_offset": 34, "nodeName": "reward", "type": "Any"}, {"lineNumber": 184, "col_offset": 19, "nodeName": "begin_episode", "type": "Any"}, {"lineNumber": 184, "col_offset": 45, "nodeName": "observation", "type": "Any"}, {"lineNumber": 187, "col_offset": 19, "nodeName": "step", "type": "Any"}, {"lineNumber": 187, "col_offset": 36, "nodeName": "reward", "type": "Any"}, {"lineNumber": 187, "col_offset": 44, "nodeName": "observation", "type": "Any"}, {"lineNumber": 153, "col_offset": 8, "nodeName": "tf", "type": "Any"}, {"lineNumber": 154, "col_offset": 8, "nodeName": "tf", "type": "Any"}, {"lineNumber": 183, "col_offset": 10, "nodeName": "_agent", "type": "Any"}, {"lineNumber": 184, "col_offset": 19, "nodeName": "_agent", "type": "Any"}, {"lineNumber": 187, "col_offset": 19, "nodeName": "_agent", "type": "Any"}, {"lineNumber": 188, "col_offset": 53, "nodeName": "set_source_state", "type": "bool"}, {"lineNumber": 183, "col_offset": 10, "nodeName": "self", "type": "Any"}, {"lineNumber": 184, "col_offset": 19, "nodeName": "self", "type": "Any"}, {"lineNumber": 187, "col_offset": 19, "nodeName": "self", "type": "Any"}]