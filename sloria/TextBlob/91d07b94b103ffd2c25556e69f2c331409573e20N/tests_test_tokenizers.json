[{"lineNumber": 5, "col_offset": 24, "nodeName": "TestCase", "type": "Type[unittest.case.TestCase]"}, {"lineNumber": 26, "col_offset": 28, "nodeName": "TestCase", "type": "Type[unittest.case.TestCase]"}, {"lineNumber": 5, "col_offset": 24, "nodeName": "unittest", "type": "module"}, {"lineNumber": 26, "col_offset": 28, "nodeName": "unittest", "type": "module"}, {"lineNumber": 46, "col_offset": 3, "nodeName": "__name__", "type": "str"}, {"lineNumber": 10, "col_offset": 8, "nodeName": "tokenizer", "type": "text.tokenizers.WordTokenizer"}, {"lineNumber": 11, "col_offset": 8, "nodeName": "text", "type": "str"}, {"lineNumber": 29, "col_offset": 8, "nodeName": "tokenizer", "type": "text.tokenizers.SentenceTokenizer"}, {"lineNumber": 30, "col_offset": 8, "nodeName": "text", "type": "str"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "text", "type": "str"}, {"lineNumber": 40, "col_offset": 8, "nodeName": "text2", "type": "str"}, {"lineNumber": 41, "col_offset": 8, "nodeName": "tokens", "type": "Any"}, {"lineNumber": 47, "col_offset": 4, "nodeName": "main", "type": "Callable[..., unittest.TestProgram]"}, {"lineNumber": 10, "col_offset": 8, "nodeName": "self", "type": "TestWordTokenizer"}, {"lineNumber": 10, "col_offset": 25, "nodeName": "WordTokenizer", "type": "Type[text.tokenizers.WordTokenizer]"}, {"lineNumber": 11, "col_offset": 8, "nodeName": "self", "type": "TestWordTokenizer"}, {"lineNumber": 17, "col_offset": 8, "nodeName": "assert_equal", "type": "Any"}, {"lineNumber": 22, "col_offset": 8, "nodeName": "assert_equal", "type": "Any"}, {"lineNumber": 29, "col_offset": 8, "nodeName": "self", "type": "TestSentenceTokenizer"}, {"lineNumber": 29, "col_offset": 25, "nodeName": "SentenceTokenizer", "type": "Type[text.tokenizers.SentenceTokenizer]"}, {"lineNumber": 30, "col_offset": 8, "nodeName": "self", "type": "TestSentenceTokenizer"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "assert_equal", "type": "Any"}, {"lineNumber": 38, "col_offset": 8, "nodeName": "assert_equal", "type": "Any"}, {"lineNumber": 41, "col_offset": 17, "nodeName": "tokenize", "type": "Callable[[Any], Any]"}, {"lineNumber": 41, "col_offset": 41, "nodeName": "text2", "type": "str"}, {"lineNumber": 42, "col_offset": 8, "nodeName": "assert_equal", "type": "Any"}, {"lineNumber": 43, "col_offset": 8, "nodeName": "assert_equal", "type": "Any"}, {"lineNumber": 43, "col_offset": 21, "nodeName": "tokens", "type": "Any"}, {"lineNumber": 47, "col_offset": 4, "nodeName": "unittest", "type": "module"}, {"lineNumber": 17, "col_offset": 21, "nodeName": "tokenize", "type": "Callable[..., Any]"}, {"lineNumber": 17, "col_offset": 45, "nodeName": "text", "type": "str"}, {"lineNumber": 22, "col_offset": 21, "nodeName": "tokenize", "type": "Callable[..., Any]"}, {"lineNumber": 22, "col_offset": 45, "nodeName": "text", "type": "str"}, {"lineNumber": 33, "col_offset": 21, "nodeName": "tokenize", "type": "Callable[[Any], Any]"}, {"lineNumber": 33, "col_offset": 45, "nodeName": "text", "type": "str"}, {"lineNumber": 38, "col_offset": 21, "nodeName": "tokenize", "type": "Callable[[Any], Any]"}, {"lineNumber": 38, "col_offset": 45, "nodeName": "text", "type": "str"}, {"lineNumber": 41, "col_offset": 17, "nodeName": "tokenizer", "type": "text.tokenizers.SentenceTokenizer"}, {"lineNumber": 42, "col_offset": 21, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 42, "col_offset": 25, "nodeName": "tokens", "type": "Any"}, {"lineNumber": 17, "col_offset": 21, "nodeName": "tokenizer", "type": "text.tokenizers.WordTokenizer"}, {"lineNumber": 17, "col_offset": 45, "nodeName": "self", "type": "TestWordTokenizer"}, {"lineNumber": 22, "col_offset": 21, "nodeName": "tokenizer", "type": "text.tokenizers.WordTokenizer"}, {"lineNumber": 22, "col_offset": 45, "nodeName": "self", "type": "TestWordTokenizer"}, {"lineNumber": 33, "col_offset": 21, "nodeName": "tokenizer", "type": "text.tokenizers.SentenceTokenizer"}, {"lineNumber": 33, "col_offset": 45, "nodeName": "self", "type": "TestSentenceTokenizer"}, {"lineNumber": 38, "col_offset": 21, "nodeName": "tokenizer", "type": "text.tokenizers.SentenceTokenizer"}, {"lineNumber": 41, "col_offset": 17, "nodeName": "self", "type": "TestSentenceTokenizer"}, {"lineNumber": 17, "col_offset": 21, "nodeName": "self", "type": "TestWordTokenizer"}, {"lineNumber": 22, "col_offset": 21, "nodeName": "self", "type": "TestWordTokenizer"}, {"lineNumber": 33, "col_offset": 21, "nodeName": "self", "type": "TestSentenceTokenizer"}, {"lineNumber": 38, "col_offset": 21, "nodeName": "self", "type": "TestSentenceTokenizer"}]