[{"lineNumber": 31, "col_offset": 20, "nodeName": "object", "type": "Type[object]"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "vocab", "type": "Any"}, {"lineNumber": 36, "col_offset": 8, "nodeName": "inv_vocab", "type": "Dict[Any, Any]"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "unk_token", "type": "Any"}, {"lineNumber": 37, "col_offset": 25, "nodeName": "unk_token", "type": "Any"}, {"lineNumber": 53, "col_offset": 8, "nodeName": "text", "type": "Any"}, {"lineNumber": 54, "col_offset": 8, "nodeName": "text", "type": "Any"}, {"lineNumber": 55, "col_offset": 8, "nodeName": "text", "type": "Any"}, {"lineNumber": 56, "col_offset": 8, "nodeName": "output_tokens", "type": "List[Any]"}, {"lineNumber": 57, "col_offset": 8, "nodeName": "token_list", "type": "Any"}, {"lineNumber": 58, "col_offset": 12, "nodeName": "chars", "type": "Any"}, {"lineNumber": 58, "col_offset": 21, "nodeName": "token_list", "type": "Any"}, {"lineNumber": 64, "col_offset": 15, "nodeName": "output_tokens", "type": "List[Any]"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "self", "type": "WordTokenizer"}, {"lineNumber": 35, "col_offset": 21, "nodeName": "load_vocab", "type": "Any"}, {"lineNumber": 35, "col_offset": 32, "nodeName": "vocab", "type": "Any"}, {"lineNumber": 36, "col_offset": 8, "nodeName": "self", "type": "WordTokenizer"}, {"lineNumber": 36, "col_offset": 26, "nodeName": "v", "type": "Any"}, {"lineNumber": 36, "col_offset": 29, "nodeName": "k", "type": "Any"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "self", "type": "WordTokenizer"}, {"lineNumber": 53, "col_offset": 15, "nodeName": "convert_to_unicode", "type": "Any"}, {"lineNumber": 53, "col_offset": 34, "nodeName": "text", "type": "Any"}, {"lineNumber": 54, "col_offset": 15, "nodeName": "clean_text", "type": "Any"}, {"lineNumber": 54, "col_offset": 26, "nodeName": "text", "type": "Any"}, {"lineNumber": 55, "col_offset": 15, "nodeName": "tokenize_chinese_chars", "type": "Any"}, {"lineNumber": 55, "col_offset": 38, "nodeName": "text", "type": "Any"}, {"lineNumber": 57, "col_offset": 21, "nodeName": "split_on_whitespace", "type": "Any"}, {"lineNumber": 57, "col_offset": 41, "nodeName": "text", "type": "Any"}, {"lineNumber": 67, "col_offset": 15, "nodeName": "convert_by_vocab", "type": "Any"}, {"lineNumber": 67, "col_offset": 32, "nodeName": "vocab", "type": "Any"}, {"lineNumber": 67, "col_offset": 44, "nodeName": "tokens", "type": "Any"}, {"lineNumber": 67, "col_offset": 52, "nodeName": "max_seq_length", "type": "Any"}, {"lineNumber": 67, "col_offset": 68, "nodeName": "blank_id", "type": "Any"}, {"lineNumber": 67, "col_offset": 78, "nodeName": "unk_id", "type": "Any"}, {"lineNumber": 70, "col_offset": 15, "nodeName": "convert_by_vocab", "type": "Any"}, {"lineNumber": 70, "col_offset": 32, "nodeName": "inv_vocab", "type": "Dict[Any, Any]"}, {"lineNumber": 70, "col_offset": 48, "nodeName": "ids", "type": "Any"}, {"lineNumber": 59, "col_offset": 12, "nodeName": "append", "type": "Any"}, {"lineNumber": 60, "col_offset": 15, "nodeName": "chars", "type": "Any"}, {"lineNumber": 60, "col_offset": 24, "nodeName": "vocab", "type": "Any"}, {"lineNumber": 67, "col_offset": 32, "nodeName": "self", "type": "WordTokenizer"}, {"lineNumber": 70, "col_offset": 32, "nodeName": "self", "type": "WordTokenizer"}, {"lineNumber": 36, "col_offset": 35, "nodeName": "k", "type": "Any"}, {"lineNumber": 36, "col_offset": 38, "nodeName": "v", "type": "Any"}, {"lineNumber": 36, "col_offset": 43, "nodeName": "items", "type": "Any"}, {"lineNumber": 59, "col_offset": 12, "nodeName": "current_positions", "type": "Any"}, {"lineNumber": 60, "col_offset": 24, "nodeName": "self", "type": "WordTokenizer"}, {"lineNumber": 61, "col_offset": 16, "nodeName": "extend", "type": "Callable"}, {"lineNumber": 61, "col_offset": 37, "nodeName": "sub_tokens", "type": "Any"}, {"lineNumber": 63, "col_offset": 16, "nodeName": "append", "type": "Callable"}, {"lineNumber": 63, "col_offset": 37, "nodeName": "unk_token", "type": "Any"}, {"lineNumber": 36, "col_offset": 43, "nodeName": "vocab", "type": "Any"}, {"lineNumber": 61, "col_offset": 16, "nodeName": "output_tokens", "type": "List[Any]"}, {"lineNumber": 63, "col_offset": 16, "nodeName": "output_tokens", "type": "List[Any]"}, {"lineNumber": 63, "col_offset": 37, "nodeName": "self", "type": "WordTokenizer"}, {"lineNumber": 36, "col_offset": 43, "nodeName": "self", "type": "WordTokenizer"}]