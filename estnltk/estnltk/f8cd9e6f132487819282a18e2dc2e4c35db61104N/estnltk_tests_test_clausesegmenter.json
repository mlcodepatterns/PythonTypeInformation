[{"lineNumber": 8, "col_offset": 0, "nodeName": "an", "type": "estnltk.morf.PyVabamorfAnalyzer"}, {"lineNumber": 9, "col_offset": 0, "nodeName": "to", "type": "estnltk.tokenize.Tokenizer"}, {"lineNumber": 11, "col_offset": 0, "nodeName": "text1", "type": "unicode"}, {"lineNumber": 12, "col_offset": 0, "nodeName": "seg1", "type": "estnltk.clausesegmenter.ClauseSegmenter"}, {"lineNumber": 14, "col_offset": 0, "nodeName": "text2", "type": "unicode"}, {"lineNumber": 15, "col_offset": 0, "nodeName": "seg2", "type": "estnltk.clausesegmenter.ClauseSegmenter"}, {"lineNumber": 17, "col_offset": 26, "nodeName": "TestCase", "type": "Type[unittest.TestCase]"}, {"lineNumber": 19, "col_offset": 4, "nodeName": "test_segmenter_corpus", "type": "Callable[[Any], Any]"}, {"lineNumber": 23, "col_offset": 4, "nodeName": "test_segmenter_json", "type": "Callable[[Any], Any]"}, {"lineNumber": 28, "col_offset": 4, "nodeName": "test_segmenter_corpus_ignore_missing_commas", "type": "Callable[[Any], Any]"}, {"lineNumber": 32, "col_offset": 4, "nodeName": "test_segmenter_json_ignore_missing_commas", "type": "Callable[[Any], Any]"}, {"lineNumber": 8, "col_offset": 5, "nodeName": "PyVabamorfAnalyzer", "type": "Type[estnltk.morf.PyVabamorfAnalyzer]"}, {"lineNumber": 9, "col_offset": 5, "nodeName": "Tokenizer", "type": "Type[estnltk.tokenize.Tokenizer]"}, {"lineNumber": 12, "col_offset": 7, "nodeName": "ClauseSegmenter", "type": "Type[estnltk.clausesegmenter.ClauseSegmenter]"}, {"lineNumber": 15, "col_offset": 7, "nodeName": "ClauseSegmenter", "type": "Type[estnltk.clausesegmenter.ClauseSegmenter]"}, {"lineNumber": 17, "col_offset": 26, "nodeName": "unittest", "type": "module"}, {"lineNumber": 37, "col_offset": 3, "nodeName": "__name__", "type": "str"}, {"lineNumber": 20, "col_offset": 8, "nodeName": "corpus", "type": "Any"}, {"lineNumber": 24, "col_offset": 8, "nodeName": "corpus", "type": "Any"}, {"lineNumber": 25, "col_offset": 8, "nodeName": "corpus", "type": "Any"}, {"lineNumber": 29, "col_offset": 8, "nodeName": "corpus", "type": "Any"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "corpus", "type": "Any"}, {"lineNumber": 34, "col_offset": 8, "nodeName": "corpus", "type": "Any"}, {"lineNumber": 38, "col_offset": 4, "nodeName": "main", "type": "Callable[..., unittest.TestProgram]"}, {"lineNumber": 20, "col_offset": 17, "nodeName": "seg1", "type": "estnltk.clausesegmenter.ClauseSegmenter"}, {"lineNumber": 21, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 24, "col_offset": 17, "nodeName": "seg1", "type": "estnltk.clausesegmenter.ClauseSegmenter"}, {"lineNumber": 25, "col_offset": 17, "nodeName": "construct", "type": "Callable[[Any], Any]"}, {"lineNumber": 25, "col_offset": 34, "nodeName": "corpus", "type": "Any"}, {"lineNumber": 26, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 29, "col_offset": 17, "nodeName": "seg2", "type": "estnltk.clausesegmenter.ClauseSegmenter"}, {"lineNumber": 30, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 33, "col_offset": 17, "nodeName": "seg2", "type": "estnltk.clausesegmenter.ClauseSegmenter"}, {"lineNumber": 34, "col_offset": 17, "nodeName": "construct", "type": "Callable[[Any], Any]"}, {"lineNumber": 34, "col_offset": 34, "nodeName": "corpus", "type": "Any"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "assertEqual", "type": "Callable[..., None]"}, {"lineNumber": 38, "col_offset": 4, "nodeName": "unittest", "type": "module"}, {"lineNumber": 20, "col_offset": 22, "nodeName": "an", "type": "estnltk.morf.PyVabamorfAnalyzer"}, {"lineNumber": 21, "col_offset": 8, "nodeName": "self", "type": "ClauseSegmenterTest"}, {"lineNumber": 21, "col_offset": 25, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 21, "col_offset": 29, "nodeName": "clauses", "type": "Any"}, {"lineNumber": 24, "col_offset": 22, "nodeName": "to_json", "type": "Any"}, {"lineNumber": 25, "col_offset": 17, "nodeName": "Corpus", "type": "Type[estnltk.corpus.Corpus]"}, {"lineNumber": 26, "col_offset": 8, "nodeName": "self", "type": "ClauseSegmenterTest"}, {"lineNumber": 26, "col_offset": 25, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 26, "col_offset": 29, "nodeName": "clauses", "type": "Any"}, {"lineNumber": 29, "col_offset": 22, "nodeName": "an", "type": "estnltk.morf.PyVabamorfAnalyzer"}, {"lineNumber": 30, "col_offset": 8, "nodeName": "self", "type": "ClauseSegmenterTest"}, {"lineNumber": 30, "col_offset": 25, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 30, "col_offset": 29, "nodeName": "clauses", "type": "Any"}, {"lineNumber": 33, "col_offset": 22, "nodeName": "to_json", "type": "Any"}, {"lineNumber": 34, "col_offset": 17, "nodeName": "Corpus", "type": "Type[estnltk.corpus.Corpus]"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "self", "type": "ClauseSegmenterTest"}, {"lineNumber": 35, "col_offset": 25, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 35, "col_offset": 29, "nodeName": "clauses", "type": "Any"}, {"lineNumber": 20, "col_offset": 25, "nodeName": "to", "type": "estnltk.tokenize.Tokenizer"}, {"lineNumber": 20, "col_offset": 28, "nodeName": "text1", "type": "unicode"}, {"lineNumber": 21, "col_offset": 29, "nodeName": "corpus", "type": "Any"}, {"lineNumber": 26, "col_offset": 29, "nodeName": "corpus", "type": "Any"}, {"lineNumber": 29, "col_offset": 25, "nodeName": "to", "type": "estnltk.tokenize.Tokenizer"}, {"lineNumber": 29, "col_offset": 28, "nodeName": "text2", "type": "unicode"}, {"lineNumber": 30, "col_offset": 29, "nodeName": "corpus", "type": "Any"}, {"lineNumber": 35, "col_offset": 29, "nodeName": "corpus", "type": "Any"}, {"lineNumber": 24, "col_offset": 22, "nodeName": "an", "type": "estnltk.morf.PyVabamorfAnalyzer"}, {"lineNumber": 33, "col_offset": 22, "nodeName": "an", "type": "estnltk.morf.PyVabamorfAnalyzer"}, {"lineNumber": 24, "col_offset": 25, "nodeName": "to", "type": "estnltk.tokenize.Tokenizer"}, {"lineNumber": 24, "col_offset": 28, "nodeName": "text1", "type": "unicode"}, {"lineNumber": 33, "col_offset": 25, "nodeName": "to", "type": "estnltk.tokenize.Tokenizer"}, {"lineNumber": 33, "col_offset": 28, "nodeName": "text2", "type": "unicode"}]