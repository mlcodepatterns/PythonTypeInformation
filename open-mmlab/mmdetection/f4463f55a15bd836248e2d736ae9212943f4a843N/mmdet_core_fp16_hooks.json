[{"lineNumber": 99, "col_offset": 0, "nodeName": "wrap_fp16_model", "type": "Callable[[Any], Any]"}, {"lineNumber": 118, "col_offset": 0, "nodeName": "patch_norm_fp32", "type": "Callable[[Any], Any]"}, {"lineNumber": 138, "col_offset": 0, "nodeName": "patch_forward_method", "type": "Callable[..., Any]"}, {"lineNumber": 11, "col_offset": 24, "nodeName": "OptimizerHook", "type": "Any"}, {"lineNumber": 113, "col_offset": 8, "nodeName": "m", "type": "Any"}, {"lineNumber": 133, "col_offset": 8, "nodeName": "child", "type": "Any"}, {"lineNumber": 135, "col_offset": 11, "nodeName": "module", "type": "Any"}, {"lineNumber": 158, "col_offset": 11, "nodeName": "new_forward", "type": "Callable[..., Any]"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "grad_clip", "type": "Any"}, {"lineNumber": 33, "col_offset": 25, "nodeName": "grad_clip", "type": "Any"}, {"lineNumber": 34, "col_offset": 8, "nodeName": "coalesce", "type": "Any"}, {"lineNumber": 34, "col_offset": 24, "nodeName": "coalesce", "type": "Any"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "bucket_size_mb", "type": "Any"}, {"lineNumber": 35, "col_offset": 30, "nodeName": "bucket_size_mb", "type": "Any"}, {"lineNumber": 36, "col_offset": 8, "nodeName": "loss_scale", "type": "Any"}, {"lineNumber": 36, "col_offset": 26, "nodeName": "loss_scale", "type": "Any"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "distributed", "type": "Any"}, {"lineNumber": 37, "col_offset": 27, "nodeName": "distributed", "type": "Any"}, {"lineNumber": 77, "col_offset": 8, "nodeName": "scaled_loss", "type": "Any"}, {"lineNumber": 80, "col_offset": 8, "nodeName": "fp32_weights", "type": "List[Any]"}, {"lineNumber": 81, "col_offset": 12, "nodeName": "param_group", "type": "Any"}, {"lineNumber": 81, "col_offset": 27, "nodeName": "param_groups", "type": "Any"}, {"lineNumber": 85, "col_offset": 11, "nodeName": "distributed", "type": "Any"}, {"lineNumber": 88, "col_offset": 12, "nodeName": "param", "type": "Any"}, {"lineNumber": 88, "col_offset": 21, "nodeName": "fp32_weights", "type": "List[Any]"}, {"lineNumber": 109, "col_offset": 4, "nodeName": "half", "type": "Any"}, {"lineNumber": 111, "col_offset": 4, "nodeName": "patch_norm_fp32", "type": "Callable[[Any], Any]"}, {"lineNumber": 111, "col_offset": 20, "nodeName": "model", "type": "Any"}, {"lineNumber": 113, "col_offset": 13, "nodeName": "modules", "type": "Any"}, {"lineNumber": 128, "col_offset": 7, "nodeName": "isinstance", "type": "Callable[[Any, Union[Type[Any], Tuple[Union[Type[Any], Tuple[Type[Any], ...]], ...]]], bool]"}, {"lineNumber": 128, "col_offset": 18, "nodeName": "module", "type": "Any"}, {"lineNumber": 133, "col_offset": 17, "nodeName": "children", "type": "Any"}, {"lineNumber": 154, "col_offset": 11, "nodeName": "convert_output", "type": "Any"}, {"lineNumber": 156, "col_offset": 15, "nodeName": "output", "type": "Any"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 34, "col_offset": 8, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 36, "col_offset": 8, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 46, "col_offset": 40, "nodeName": "deepcopy", "type": "Callable"}, {"lineNumber": 47, "col_offset": 12, "nodeName": "param_groups", "type": "Any"}, {"lineNumber": 49, "col_offset": 8, "nodeName": "wrap_fp16_model", "type": "Callable[[Any], Any]"}, {"lineNumber": 49, "col_offset": 24, "nodeName": "model", "type": "Any"}, {"lineNumber": 53, "col_offset": 12, "nodeName": "fp32_param", "type": "Any"}, {"lineNumber": 53, "col_offset": 24, "nodeName": "fp16_param", "type": "Any"}, {"lineNumber": 53, "col_offset": 38, "nodeName": "zip", "type": "Callable"}, {"lineNumber": 53, "col_offset": 42, "nodeName": "fp32_weights", "type": "List[Any]"}, {"lineNumber": 61, "col_offset": 12, "nodeName": "fp16_param", "type": "Any"}, {"lineNumber": 61, "col_offset": 24, "nodeName": "fp32_param", "type": "Any"}, {"lineNumber": 61, "col_offset": 38, "nodeName": "zip", "type": "Callable"}, {"lineNumber": 61, "col_offset": 65, "nodeName": "fp32_weights", "type": "List[Any]"}, {"lineNumber": 74, "col_offset": 8, "nodeName": "zero_grad", "type": "Any"}, {"lineNumber": 75, "col_offset": 8, "nodeName": "zero_grad", "type": "Any"}, {"lineNumber": 77, "col_offset": 47, "nodeName": "loss_scale", "type": "Any"}, {"lineNumber": 78, "col_offset": 8, "nodeName": "backward", "type": "Any"}, {"lineNumber": 81, "col_offset": 27, "nodeName": "optimizer", "type": "Any"}, {"lineNumber": 82, "col_offset": 12, "nodeName": "fp32_weights", "type": "List[Any]"}, {"lineNumber": 83, "col_offset": 8, "nodeName": "copy_grads_to_fp32", "type": "Callable[[Any, Any], Any]"}, {"lineNumber": 83, "col_offset": 32, "nodeName": "model", "type": "Any"}, {"lineNumber": 83, "col_offset": 46, "nodeName": "fp32_weights", "type": "List[Any]"}, {"lineNumber": 85, "col_offset": 11, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 91, "col_offset": 11, "nodeName": "grad_clip", "type": "Any"}, {"lineNumber": 94, "col_offset": 8, "nodeName": "step", "type": "Any"}, {"lineNumber": 96, "col_offset": 8, "nodeName": "copy_params_to_fp16", "type": "Callable[[Any, Any], Any]"}, {"lineNumber": 96, "col_offset": 33, "nodeName": "model", "type": "Any"}, {"lineNumber": 96, "col_offset": 47, "nodeName": "fp32_weights", "type": "List[Any]"}, {"lineNumber": 109, "col_offset": 4, "nodeName": "model", "type": "Any"}, {"lineNumber": 113, "col_offset": 13, "nodeName": "model", "type": "Any"}, {"lineNumber": 114, "col_offset": 11, "nodeName": "hasattr", "type": "Callable[[Any, str], bool]"}, {"lineNumber": 114, "col_offset": 19, "nodeName": "m", "type": "Any"}, {"lineNumber": 115, "col_offset": 12, "nodeName": "fp16_enabled", "type": "bool"}, {"lineNumber": 128, "col_offset": 27, "nodeName": "_BatchNorm", "type": "Any"}, {"lineNumber": 128, "col_offset": 60, "nodeName": "GroupNorm", "type": "Any"}, {"lineNumber": 129, "col_offset": 8, "nodeName": "float", "type": "Any"}, {"lineNumber": 131, "col_offset": 12, "nodeName": "forward", "type": "Any"}, {"lineNumber": 133, "col_offset": 17, "nodeName": "module", "type": "Any"}, {"lineNumber": 134, "col_offset": 8, "nodeName": "patch_norm_fp32", "type": "Callable[[Any], Any]"}, {"lineNumber": 134, "col_offset": 24, "nodeName": "child", "type": "Any"}, {"lineNumber": 152, "col_offset": 17, "nodeName": "func", "type": "Any"}, {"lineNumber": 155, "col_offset": 12, "nodeName": "output", "type": "Any"}, {"lineNumber": 46, "col_offset": 40, "nodeName": "copy", "type": "module"}, {"lineNumber": 47, "col_offset": 12, "nodeName": "optimizer", "type": "Any"}, {"lineNumber": 49, "col_offset": 24, "nodeName": "runner", "type": "Any"}, {"lineNumber": 53, "col_offset": 56, "nodeName": "parameters", "type": "Any"}, {"lineNumber": 54, "col_offset": 15, "nodeName": "grad", "type": "Any"}, {"lineNumber": 61, "col_offset": 42, "nodeName": "parameters", "type": "Any"}, {"lineNumber": 62, "col_offset": 12, "nodeName": "copy_", "type": "Any"}, {"lineNumber": 62, "col_offset": 34, "nodeName": "data", "type": "Any"}, {"lineNumber": 74, "col_offset": 8, "nodeName": "model", "type": "Any"}, {"lineNumber": 75, "col_offset": 8, "nodeName": "optimizer", "type": "Any"}, {"lineNumber": 77, "col_offset": 22, "nodeName": "outputs", "type": "Any"}, {"lineNumber": 77, "col_offset": 47, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 78, "col_offset": 8, "nodeName": "scaled_loss", "type": "Any"}, {"lineNumber": 81, "col_offset": 27, "nodeName": "runner", "type": "Any"}, {"lineNumber": 82, "col_offset": 28, "nodeName": "param_group", "type": "Any"}, {"lineNumber": 83, "col_offset": 8, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 83, "col_offset": 32, "nodeName": "runner", "type": "Any"}, {"lineNumber": 86, "col_offset": 12, "nodeName": "allreduce_grads", "type": "Any"}, {"lineNumber": 86, "col_offset": 28, "nodeName": "fp32_weights", "type": "List[Any]"}, {"lineNumber": 86, "col_offset": 42, "nodeName": "coalesce", "type": "Any"}, {"lineNumber": 86, "col_offset": 57, "nodeName": "bucket_size_mb", "type": "Any"}, {"lineNumber": 89, "col_offset": 15, "nodeName": "grad", "type": "Any"}, {"lineNumber": 91, "col_offset": 11, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 92, "col_offset": 12, "nodeName": "clip_grads", "type": "Any"}, {"lineNumber": 92, "col_offset": 28, "nodeName": "fp32_weights", "type": "List[Any]"}, {"lineNumber": 94, "col_offset": 8, "nodeName": "optimizer", "type": "Any"}, {"lineNumber": 96, "col_offset": 8, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 96, "col_offset": 33, "nodeName": "runner", "type": "Any"}, {"lineNumber": 115, "col_offset": 12, "nodeName": "m", "type": "Any"}, {"lineNumber": 128, "col_offset": 27, "nodeName": "batchnorm", "type": "Any"}, {"lineNumber": 128, "col_offset": 60, "nodeName": "nn", "type": "Any"}, {"lineNumber": 129, "col_offset": 8, "nodeName": "module", "type": "Any"}, {"lineNumber": 130, "col_offset": 11, "nodeName": "isinstance", "type": "Callable[[Any, Union[Type[Any], Tuple[Union[Type[Any], Tuple[Type[Any], ...]], ...]]], bool]"}, {"lineNumber": 130, "col_offset": 22, "nodeName": "module", "type": "Any"}, {"lineNumber": 130, "col_offset": 30, "nodeName": "GroupNorm", "type": "Any"}, {"lineNumber": 130, "col_offset": 47, "nodeName": "__version__", "type": "Any"}, {"lineNumber": 131, "col_offset": 12, "nodeName": "module", "type": "Any"}, {"lineNumber": 131, "col_offset": 29, "nodeName": "patch_forward_method", "type": "Callable[..., Any]"}, {"lineNumber": 131, "col_offset": 50, "nodeName": "forward", "type": "Any"}, {"lineNumber": 131, "col_offset": 66, "nodeName": "half", "type": "Any"}, {"lineNumber": 132, "col_offset": 50, "nodeName": "float", "type": "Any"}, {"lineNumber": 155, "col_offset": 21, "nodeName": "cast_tensor_type", "type": "Any"}, {"lineNumber": 155, "col_offset": 38, "nodeName": "output", "type": "Any"}, {"lineNumber": 155, "col_offset": 46, "nodeName": "dst_type", "type": "Any"}, {"lineNumber": 155, "col_offset": 56, "nodeName": "src_type", "type": "Any"}, {"lineNumber": 47, "col_offset": 12, "nodeName": "runner", "type": "Any"}, {"lineNumber": 53, "col_offset": 56, "nodeName": "fp16_net", "type": "Any"}, {"lineNumber": 54, "col_offset": 15, "nodeName": "fp16_param", "type": "Any"}, {"lineNumber": 55, "col_offset": 19, "nodeName": "grad", "type": "Any"}, {"lineNumber": 56, "col_offset": 20, "nodeName": "grad", "type": "Any"}, {"lineNumber": 57, "col_offset": 16, "nodeName": "copy_", "type": "Any"}, {"lineNumber": 57, "col_offset": 38, "nodeName": "grad", "type": "Any"}, {"lineNumber": 61, "col_offset": 42, "nodeName": "fp16_net", "type": "Any"}, {"lineNumber": 62, "col_offset": 12, "nodeName": "data", "type": "Any"}, {"lineNumber": 62, "col_offset": 34, "nodeName": "fp32_param", "type": "Any"}, {"lineNumber": 74, "col_offset": 8, "nodeName": "runner", "type": "Any"}, {"lineNumber": 75, "col_offset": 8, "nodeName": "runner", "type": "Any"}, {"lineNumber": 77, "col_offset": 22, "nodeName": "runner", "type": "Any"}, {"lineNumber": 86, "col_offset": 42, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 86, "col_offset": 57, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 89, "col_offset": 15, "nodeName": "param", "type": "Any"}, {"lineNumber": 90, "col_offset": 16, "nodeName": "div_", "type": "Any"}, {"lineNumber": 90, "col_offset": 32, "nodeName": "loss_scale", "type": "Any"}, {"lineNumber": 92, "col_offset": 12, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 94, "col_offset": 8, "nodeName": "runner", "type": "Any"}, {"lineNumber": 128, "col_offset": 27, "nodeName": "modules", "type": "Any"}, {"lineNumber": 130, "col_offset": 30, "nodeName": "nn", "type": "Any"}, {"lineNumber": 130, "col_offset": 47, "nodeName": "torch", "type": "Any"}, {"lineNumber": 131, "col_offset": 50, "nodeName": "module", "type": "Any"}, {"lineNumber": 131, "col_offset": 66, "nodeName": "torch", "type": "Any"}, {"lineNumber": 132, "col_offset": 50, "nodeName": "torch", "type": "Any"}, {"lineNumber": 152, "col_offset": 23, "nodeName": "cast_tensor_type", "type": "Any"}, {"lineNumber": 152, "col_offset": 40, "nodeName": "args", "type": "Tuple[Any, ...]"}, {"lineNumber": 152, "col_offset": 46, "nodeName": "src_type", "type": "Any"}, {"lineNumber": 152, "col_offset": 56, "nodeName": "dst_type", "type": "Any"}, {"lineNumber": 153, "col_offset": 24, "nodeName": "cast_tensor_type", "type": "Any"}, {"lineNumber": 153, "col_offset": 41, "nodeName": "kwargs", "type": "Dict[str, Any]"}, {"lineNumber": 153, "col_offset": 49, "nodeName": "src_type", "type": "Any"}, {"lineNumber": 153, "col_offset": 59, "nodeName": "dst_type", "type": "Any"}, {"lineNumber": 55, "col_offset": 19, "nodeName": "fp32_param", "type": "Any"}, {"lineNumber": 56, "col_offset": 20, "nodeName": "fp32_param", "type": "Any"}, {"lineNumber": 56, "col_offset": 38, "nodeName": "new", "type": "Any"}, {"lineNumber": 57, "col_offset": 16, "nodeName": "grad", "type": "Any"}, {"lineNumber": 57, "col_offset": 38, "nodeName": "fp16_param", "type": "Any"}, {"lineNumber": 62, "col_offset": 12, "nodeName": "fp16_param", "type": "Any"}, {"lineNumber": 90, "col_offset": 16, "nodeName": "grad", "type": "Any"}, {"lineNumber": 90, "col_offset": 32, "nodeName": "self", "type": "Fp16OptimizerHook"}, {"lineNumber": 128, "col_offset": 27, "nodeName": "nn", "type": "Any"}, {"lineNumber": 56, "col_offset": 38, "nodeName": "data", "type": "Any"}, {"lineNumber": 56, "col_offset": 58, "nodeName": "size", "type": "Any"}, {"lineNumber": 57, "col_offset": 16, "nodeName": "fp32_param", "type": "Any"}, {"lineNumber": 90, "col_offset": 16, "nodeName": "param", "type": "Any"}, {"lineNumber": 56, "col_offset": 38, "nodeName": "fp32_param", "type": "Any"}, {"lineNumber": 56, "col_offset": 58, "nodeName": "fp32_param", "type": "Any"}]