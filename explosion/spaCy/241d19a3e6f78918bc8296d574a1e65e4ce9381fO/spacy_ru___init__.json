[{"lineNumber": 10, "col_offset": 23, "nodeName": "object", "type": "Type[object]"}, {"lineNumber": 48, "col_offset": 22, "nodeName": "Defaults", "type": "Any"}, {"lineNumber": 61, "col_offset": 14, "nodeName": "Language", "type": "Any"}, {"lineNumber": 11, "col_offset": 4, "nodeName": "_morph", "type": "None"}, {"lineNumber": 48, "col_offset": 22, "nodeName": "Language", "type": "Any"}, {"lineNumber": 49, "col_offset": 4, "nodeName": "lex_attr_getters", "type": "Dict[Any, Union[Any, Callable[[Any], Any]]]"}, {"lineNumber": 52, "col_offset": 4, "nodeName": "tokenizer_exceptions", "type": "Any"}, {"lineNumber": 52, "col_offset": 27, "nodeName": "TOKENIZER_EXCEPTIONS", "type": "Any"}, {"lineNumber": 53, "col_offset": 4, "nodeName": "stop_words", "type": "Any"}, {"lineNumber": 53, "col_offset": 17, "nodeName": "STOP_WORDS", "type": "Any"}, {"lineNumber": 62, "col_offset": 4, "nodeName": "lang", "type": "str"}, {"lineNumber": 64, "col_offset": 4, "nodeName": "Defaults", "type": "Type[RussianDefaults]"}, {"lineNumber": 64, "col_offset": 15, "nodeName": "RussianDefaults", "type": "Type[RussianDefaults]"}, {"lineNumber": 22, "col_offset": 8, "nodeName": "_morph", "type": "Any"}, {"lineNumber": 24, "col_offset": 8, "nodeName": "vocab", "type": "Any"}, {"lineNumber": 25, "col_offset": 8, "nodeName": "_spacy_tokenizer", "type": "Any"}, {"lineNumber": 25, "col_offset": 32, "nodeName": "spacy_tokenizer", "type": "Any"}, {"lineNumber": 39, "col_offset": 15, "nodeName": "normal_form", "type": "Any"}, {"lineNumber": 45, "col_offset": 15, "nodeName": "_morph", "type": "Any"}, {"lineNumber": 49, "col_offset": 23, "nodeName": "dict", "type": "Type[Dict[Any, Any]]"}, {"lineNumber": 49, "col_offset": 28, "nodeName": "lex_attr_getters", "type": "Any"}, {"lineNumber": 50, "col_offset": 4, "nodeName": "lex_attr_getters", "type": "Dict[Any, Union[Any, Callable[[Any], Any]]]"}, {"lineNumber": 57, "col_offset": 8, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 16, "col_offset": 15, "nodeName": "ImportError", "type": "Type[ImportError]"}, {"lineNumber": 22, "col_offset": 8, "nodeName": "RussianTokenizer", "type": "Type[RussianTokenizer]"}, {"lineNumber": 22, "col_offset": 34, "nodeName": "_create_morph", "type": "Callable[[Any], Any]"}, {"lineNumber": 22, "col_offset": 65, "nodeName": "MorphAnalyzer", "type": "Any"}, {"lineNumber": 24, "col_offset": 8, "nodeName": "self", "type": "RussianTokenizer"}, {"lineNumber": 24, "col_offset": 34, "nodeName": "nlp", "type": "Any"}, {"lineNumber": 24, "col_offset": 21, "nodeName": "vocab", "type": "Any"}, {"lineNumber": 25, "col_offset": 8, "nodeName": "self", "type": "RussianTokenizer"}, {"lineNumber": 31, "col_offset": 15, "nodeName": "Doc", "type": "Any"}, {"lineNumber": 31, "col_offset": 19, "nodeName": "vocab", "type": "Any"}, {"lineNumber": 31, "col_offset": 31, "nodeName": "words", "type": "List[Any]"}, {"lineNumber": 35, "col_offset": 15, "nodeName": "lemma_", "type": "Any"}, {"lineNumber": 35, "col_offset": 58, "nodeName": "text", "type": "Any"}, {"lineNumber": 43, "col_offset": 15, "nodeName": "_morph", "type": "Any"}, {"lineNumber": 44, "col_offset": 12, "nodeName": "_morph", "type": "Any"}, {"lineNumber": 45, "col_offset": 15, "nodeName": "cls", "type": "Type[RussianTokenizer]"}, {"lineNumber": 49, "col_offset": 28, "nodeName": "Defaults", "type": "Any"}, {"lineNumber": 50, "col_offset": 21, "nodeName": "LANG", "type": "Any"}, {"lineNumber": 57, "col_offset": 20, "nodeName": "create_tokenizer", "type": "Any"}, {"lineNumber": 57, "col_offset": 65, "nodeName": "nlp", "type": "Any"}, {"lineNumber": 58, "col_offset": 15, "nodeName": "RussianTokenizer", "type": "Type[RussianTokenizer]"}, {"lineNumber": 58, "col_offset": 32, "nodeName": "tokenizer", "type": "Any"}, {"lineNumber": 58, "col_offset": 43, "nodeName": "cls", "type": "Type[RussianDefaults]"}, {"lineNumber": 58, "col_offset": 48, "nodeName": "nlp", "type": "Any"}, {"lineNumber": 22, "col_offset": 34, "nodeName": "RussianTokenizer", "type": "Type[RussianTokenizer]"}, {"lineNumber": 24, "col_offset": 21, "nodeName": "nlp", "type": "Any"}, {"lineNumber": 24, "col_offset": 43, "nodeName": "create_vocab", "type": "Any"}, {"lineNumber": 24, "col_offset": 60, "nodeName": "nlp", "type": "Any"}, {"lineNumber": 29, "col_offset": 21, "nodeName": "token", "type": "Any"}, {"lineNumber": 31, "col_offset": 19, "nodeName": "self", "type": "RussianTokenizer"}, {"lineNumber": 35, "col_offset": 15, "nodeName": "token", "type": "Any"}, {"lineNumber": 35, "col_offset": 58, "nodeName": "token", "type": "Any"}, {"lineNumber": 43, "col_offset": 15, "nodeName": "cls", "type": "Type[RussianTokenizer]"}, {"lineNumber": 44, "col_offset": 12, "nodeName": "cls", "type": "Type[RussianTokenizer]"}, {"lineNumber": 44, "col_offset": 25, "nodeName": "morph_analyzer_class", "type": "Any"}, {"lineNumber": 49, "col_offset": 28, "nodeName": "Language", "type": "Any"}, {"lineNumber": 17, "col_offset": 18, "nodeName": "ImportError", "type": "Type[ImportError]"}, {"lineNumber": 24, "col_offset": 43, "nodeName": "cls", "type": "Type[RussianDefaults]"}, {"lineNumber": 29, "col_offset": 30, "nodeName": "_spacy_tokenizer", "type": "Any"}, {"lineNumber": 29, "col_offset": 52, "nodeName": "text", "type": "Any"}, {"lineNumber": 31, "col_offset": 48, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 31, "col_offset": 52, "nodeName": "words", "type": "List[Any]"}, {"lineNumber": 35, "col_offset": 31, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 35, "col_offset": 35, "nodeName": "lemma_", "type": "Any"}, {"lineNumber": 39, "col_offset": 15, "nodeName": "parse", "type": "Any"}, {"lineNumber": 39, "col_offset": 32, "nodeName": "word", "type": "Any"}, {"lineNumber": 57, "col_offset": 20, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 57, "col_offset": 26, "nodeName": "RussianDefaults", "type": "Type[RussianDefaults]"}, {"lineNumber": 57, "col_offset": 43, "nodeName": "cls", "type": "Type[RussianDefaults]"}, {"lineNumber": 29, "col_offset": 30, "nodeName": "self", "type": "RussianTokenizer"}, {"lineNumber": 35, "col_offset": 35, "nodeName": "token", "type": "Any"}, {"lineNumber": 39, "col_offset": 15, "nodeName": "_morph", "type": "Any"}, {"lineNumber": 39, "col_offset": 15, "nodeName": "cls", "type": "Type[RussianTokenizer]"}]