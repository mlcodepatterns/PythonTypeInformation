[{"lineNumber": 26, "col_offset": 16, "nodeName": "Head", "type": "Type[rl_coach.architectures.tensorflow_components.heads.head.Head]"}, {"lineNumber": 29, "col_offset": 51, "nodeName": "Dense", "type": "Type[rl_coach.architectures.tensorflow_components.layers.Dense]"}, {"lineNumber": 32, "col_offset": 8, "nodeName": "name", "type": "str"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "return_type", "type": "Type[rl_coach.core_types.ActionProbabilities]"}, {"lineNumber": 33, "col_offset": 27, "nodeName": "ActionProbabilities", "type": "Type[rl_coach.core_types.ActionProbabilities]"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "num_actions", "type": "Union[int, List[Any], Tuple[Any, ...], numpy.ndarray]"}, {"lineNumber": 35, "col_offset": 27, "nodeName": "shape", "type": "Union[int, List[Any], Tuple[Any, ...], numpy.ndarray]"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "batchnorm", "type": "bool"}, {"lineNumber": 37, "col_offset": 25, "nodeName": "batchnorm", "type": "bool"}, {"lineNumber": 40, "col_offset": 8, "nodeName": "output_scale", "type": "Any"}, {"lineNumber": 40, "col_offset": 28, "nodeName": "max_abs_range", "type": "Any"}, {"lineNumber": 48, "col_offset": 8, "nodeName": "pre_activation_policy_values_mean", "type": "Any"}, {"lineNumber": 55, "col_offset": 8, "nodeName": "policy_mean", "type": "Any"}, {"lineNumber": 57, "col_offset": 11, "nodeName": "is_local", "type": "bool"}, {"lineNumber": 63, "col_offset": 8, "nodeName": "output", "type": "List[Any]"}, {"lineNumber": 29, "col_offset": 28, "nodeName": "bool", "type": "Type[bool]"}, {"lineNumber": 30, "col_offset": 8, "nodeName": "__init__", "type": "Callable[..., None]"}, {"lineNumber": 30, "col_offset": 25, "nodeName": "agent_parameters", "type": "rl_coach.base_parameters.AgentParameters"}, {"lineNumber": 30, "col_offset": 43, "nodeName": "spaces", "type": "rl_coach.spaces.SpacesDefinition"}, {"lineNumber": 30, "col_offset": 51, "nodeName": "network_name", "type": "str"}, {"lineNumber": 30, "col_offset": 65, "nodeName": "head_idx", "type": "int"}, {"lineNumber": 30, "col_offset": 75, "nodeName": "loss_weight", "type": "float"}, {"lineNumber": 30, "col_offset": 88, "nodeName": "is_local", "type": "bool"}, {"lineNumber": 30, "col_offset": 98, "nodeName": "activation_function", "type": "str"}, {"lineNumber": 32, "col_offset": 8, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 35, "col_offset": 27, "nodeName": "action", "type": "rl_coach.spaces.ActionSpace"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 40, "col_offset": 8, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 40, "col_offset": 28, "nodeName": "action", "type": "rl_coach.spaces.ActionSpace"}, {"lineNumber": 43, "col_offset": 11, "nodeName": "hasattr", "type": "Callable[[Any, str], bool]"}, {"lineNumber": 43, "col_offset": 19, "nodeName": "algorithm", "type": "rl_coach.base_parameters.AlgorithmParameters"}, {"lineNumber": 48, "col_offset": 79, "nodeName": "input_layer", "type": "Any"}, {"lineNumber": 55, "col_offset": 8, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 55, "col_offset": 27, "nodeName": "multiply", "type": "Any"}, {"lineNumber": 55, "col_offset": 39, "nodeName": "policy_values_mean", "type": "Any"}, {"lineNumber": 55, "col_offset": 59, "nodeName": "output_scale", "type": "Any"}, {"lineNumber": 57, "col_offset": 11, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 63, "col_offset": 8, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 63, "col_offset": 23, "nodeName": "policy_mean", "type": "Any"}, {"lineNumber": 69, "col_offset": 15, "nodeName": "join", "type": "Callable"}, {"lineNumber": 69, "col_offset": 25, "nodeName": "result", "type": "List[str]"}, {"lineNumber": 31, "col_offset": 37, "nodeName": "dense_layer", "type": "Any"}, {"lineNumber": 31, "col_offset": 62, "nodeName": "is_training", "type": "Any"}, {"lineNumber": 35, "col_offset": 27, "nodeName": "spaces", "type": "rl_coach.spaces.SpacesDefinition"}, {"lineNumber": 40, "col_offset": 28, "nodeName": "spaces", "type": "rl_coach.spaces.SpacesDefinition"}, {"lineNumber": 43, "col_offset": 19, "nodeName": "agent_parameters", "type": "rl_coach.base_parameters.AgentParameters"}, {"lineNumber": 48, "col_offset": 44, "nodeName": "dense_layer", "type": "Any"}, {"lineNumber": 48, "col_offset": 61, "nodeName": "num_actions", "type": "Union[int, List[Any], Tuple[Any, ...], numpy.ndarray]"}, {"lineNumber": 49, "col_offset": 29, "nodeName": "batchnorm_activation_dropout", "type": "Callable[[Any, Any, Any, Any, Any, Any], List[Any]]"}, {"lineNumber": 55, "col_offset": 27, "nodeName": "tf", "type": "Any"}, {"lineNumber": 55, "col_offset": 59, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 59, "col_offset": 15, "nodeName": "action_penalty", "type": "Any"}, {"lineNumber": 60, "col_offset": 16, "nodeName": "regularizations", "type": "List[Any]"}, {"lineNumber": 63, "col_offset": 23, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 67, "col_offset": 12, "nodeName": "format", "type": "Callable[..., str]"}, {"lineNumber": 30, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 35, "col_offset": 27, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 40, "col_offset": 28, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 48, "col_offset": 44, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 48, "col_offset": 61, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 49, "col_offset": 70, "nodeName": "pre_activation_policy_values_mean", "type": "Any"}, {"lineNumber": 50, "col_offset": 68, "nodeName": "batchnorm", "type": "bool"}, {"lineNumber": 51, "col_offset": 78, "nodeName": "activation_function", "type": "str"}, {"lineNumber": 53, "col_offset": 70, "nodeName": "is_training", "type": "Any"}, {"lineNumber": 59, "col_offset": 15, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 59, "col_offset": 39, "nodeName": "action_penalty", "type": "Any"}, {"lineNumber": 60, "col_offset": 16, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 67, "col_offset": 46, "nodeName": "num_actions", "type": "Union[int, List[Any], Tuple[Any, ...], numpy.ndarray]"}, {"lineNumber": 50, "col_offset": 68, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 51, "col_offset": 78, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 53, "col_offset": 70, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 59, "col_offset": 39, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 61, "col_offset": 21, "nodeName": "action_penalty", "type": "Any"}, {"lineNumber": 67, "col_offset": 46, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 61, "col_offset": 21, "nodeName": "self", "type": "DDPGActor"}, {"lineNumber": 61, "col_offset": 43, "nodeName": "reduce_mean", "type": "Any"}, {"lineNumber": 61, "col_offset": 43, "nodeName": "tf", "type": "Any"}, {"lineNumber": 61, "col_offset": 58, "nodeName": "square", "type": "Any"}, {"lineNumber": 61, "col_offset": 68, "nodeName": "pre_activation_policy_values_mean", "type": "Any"}, {"lineNumber": 61, "col_offset": 58, "nodeName": "tf", "type": "Any"}]