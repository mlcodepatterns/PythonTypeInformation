[{"lineNumber": 24, "col_offset": 29, "nodeName": "Agent", "type": "Type[agents.agent.Agent]"}, {"lineNumber": 30, "col_offset": 8, "nodeName": "q_values", "type": "utils.Signal"}, {"lineNumber": 37, "col_offset": 15, "nodeName": "prediction", "type": "Any"}, {"lineNumber": 50, "col_offset": 46, "nodeName": "TRAIN", "type": "str"}, {"lineNumber": 51, "col_offset": 8, "nodeName": "prediction", "type": "Any"}, {"lineNumber": 52, "col_offset": 8, "nodeName": "actions_q_values", "type": "Any"}, {"lineNumber": 60, "col_offset": 8, "nodeName": "action", "type": "Any"}, {"lineNumber": 66, "col_offset": 8, "nodeName": "actions_q_values", "type": "Any"}, {"lineNumber": 72, "col_offset": 11, "nodeName": "plot_action_values_online", "type": "Any"}, {"lineNumber": 76, "col_offset": 8, "nodeName": "action_value", "type": "Dict[str, Any]"}, {"lineNumber": 26, "col_offset": 8, "nodeName": "__init__", "type": "Callable[..., None]"}, {"lineNumber": 26, "col_offset": 23, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 26, "col_offset": 29, "nodeName": "env", "type": "Any"}, {"lineNumber": 26, "col_offset": 34, "nodeName": "tuning_parameters", "type": "Any"}, {"lineNumber": 26, "col_offset": 53, "nodeName": "replicated_device", "type": "Any"}, {"lineNumber": 26, "col_offset": 72, "nodeName": "thread_id", "type": "Any"}, {"lineNumber": 27, "col_offset": 8, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 27, "col_offset": 28, "nodeName": "NetworkWrapper", "type": "Type[architectures.network_wrapper.NetworkWrapper]"}, {"lineNumber": 27, "col_offset": 43, "nodeName": "tuning_parameters", "type": "Any"}, {"lineNumber": 27, "col_offset": 62, "nodeName": "create_target_network", "type": "Any"}, {"lineNumber": 27, "col_offset": 85, "nodeName": "has_global", "type": "bool"}, {"lineNumber": 28, "col_offset": 43, "nodeName": "replicated_device", "type": "Any"}, {"lineNumber": 28, "col_offset": 67, "nodeName": "worker_device", "type": "str"}, {"lineNumber": 29, "col_offset": 8, "nodeName": "append", "type": "Callable"}, {"lineNumber": 29, "col_offset": 29, "nodeName": "main_network", "type": "architectures.network_wrapper.NetworkWrapper"}, {"lineNumber": 30, "col_offset": 8, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 30, "col_offset": 24, "nodeName": "Signal", "type": "Type[utils.Signal]"}, {"lineNumber": 31, "col_offset": 8, "nodeName": "append", "type": "Callable"}, {"lineNumber": 31, "col_offset": 28, "nodeName": "q_values", "type": "utils.Signal"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "reset_game", "type": "Callable[..., None]"}, {"lineNumber": 40, "col_offset": 15, "nodeName": "predict", "type": "Union[Callable[[Any], Any], Callable[..., Any]]"}, {"lineNumber": 43, "col_offset": 11, "nodeName": "shape", "type": "Tuple[int, ...]"}, {"lineNumber": 50, "col_offset": 46, "nodeName": "RunPhase", "type": "Type[utils.RunPhase]"}, {"lineNumber": 51, "col_offset": 21, "nodeName": "get_prediction", "type": "Callable[[Any], Any]"}, {"lineNumber": 51, "col_offset": 41, "nodeName": "curr_state", "type": "Any"}, {"lineNumber": 52, "col_offset": 27, "nodeName": "get_q_values", "type": "Callable[[Any], Any]"}, {"lineNumber": 52, "col_offset": 45, "nodeName": "prediction", "type": "Any"}, {"lineNumber": 55, "col_offset": 11, "nodeName": "phase", "type": "Any"}, {"lineNumber": 55, "col_offset": 20, "nodeName": "TRAIN", "type": "str"}, {"lineNumber": 56, "col_offset": 12, "nodeName": "exploration_policy", "type": "Any"}, {"lineNumber": 56, "col_offset": 33, "nodeName": "exploration_policy", "type": "Any"}, {"lineNumber": 58, "col_offset": 12, "nodeName": "exploration_policy", "type": "Any"}, {"lineNumber": 58, "col_offset": 33, "nodeName": "evaluation_exploration_policy", "type": "Any"}, {"lineNumber": 60, "col_offset": 17, "nodeName": "get_action", "type": "Any"}, {"lineNumber": 60, "col_offset": 47, "nodeName": "actions_q_values", "type": "Any"}, {"lineNumber": 61, "col_offset": 8, "nodeName": "_validate_action", "type": "Callable[[Any, Any], Any]"}, {"lineNumber": 61, "col_offset": 30, "nodeName": "exploration_policy", "type": "Any"}, {"lineNumber": 61, "col_offset": 50, "nodeName": "action", "type": "Any"}, {"lineNumber": 65, "col_offset": 12, "nodeName": "actions_q_values", "type": "Any"}, {"lineNumber": 66, "col_offset": 27, "nodeName": "squeeze", "type": "Any"}, {"lineNumber": 69, "col_offset": 8, "nodeName": "add_sample", "type": "Callable[[Any], None]"}, {"lineNumber": 69, "col_offset": 33, "nodeName": "actions_q_values", "type": "Any"}, {"lineNumber": 72, "col_offset": 11, "nodeName": "visualization", "type": "Any"}, {"lineNumber": 77, "col_offset": 15, "nodeName": "action", "type": "Any"}, {"lineNumber": 77, "col_offset": 23, "nodeName": "action_value", "type": "Dict[str, Any]"}, {"lineNumber": 26, "col_offset": 8, "nodeName": "Agent", "type": "Type[agents.agent.Agent]"}, {"lineNumber": 28, "col_offset": 43, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 28, "col_offset": 67, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 29, "col_offset": 8, "nodeName": "networks", "type": "List[architectures.network_wrapper.NetworkWrapper]"}, {"lineNumber": 29, "col_offset": 29, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 31, "col_offset": 8, "nodeName": "signals", "type": "List[utils.Signal]"}, {"lineNumber": 31, "col_offset": 28, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 40, "col_offset": 15, "nodeName": "online_network", "type": "Union[architectures.neon_components.general_network.GeneralNeonNetwork, architectures.tensorflow_components.general_network.GeneralTensorFlowNetwork]"}, {"lineNumber": 40, "col_offset": 56, "nodeName": "tf_input_state", "type": "Callable[[Any], Dict[Any, Any]]"}, {"lineNumber": 40, "col_offset": 76, "nodeName": "curr_state", "type": "Any"}, {"lineNumber": 44, "col_offset": 18, "nodeName": "ValueError", "type": "Type[ValueError]"}, {"lineNumber": 51, "col_offset": 21, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 52, "col_offset": 27, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 55, "col_offset": 20, "nodeName": "RunPhase", "type": "Type[utils.RunPhase]"}, {"lineNumber": 56, "col_offset": 33, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 58, "col_offset": 33, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 60, "col_offset": 17, "nodeName": "exploration_policy", "type": "Any"}, {"lineNumber": 61, "col_offset": 8, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 64, "col_offset": 37, "nodeName": "list", "type": "Type[List[Any]]"}, {"lineNumber": 65, "col_offset": 31, "nodeName": "actions_q_values", "type": "Any"}, {"lineNumber": 66, "col_offset": 27, "nodeName": "actions_q_values", "type": "Any"}, {"lineNumber": 69, "col_offset": 8, "nodeName": "q_values", "type": "utils.Signal"}, {"lineNumber": 72, "col_offset": 11, "nodeName": "tp", "type": "Any"}, {"lineNumber": 73, "col_offset": 16, "nodeName": "idx", "type": "int"}, {"lineNumber": 73, "col_offset": 21, "nodeName": "action_name", "type": "Any"}, {"lineNumber": 73, "col_offset": 36, "nodeName": "enumerate", "type": "Type[enumerate[Any]]"}, {"lineNumber": 73, "col_offset": 46, "nodeName": "actions_description", "type": "Any"}, {"lineNumber": 76, "col_offset": 40, "nodeName": "actions_q_values", "type": "Any"}, {"lineNumber": 29, "col_offset": 8, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 31, "col_offset": 8, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 40, "col_offset": 15, "nodeName": "main_network", "type": "architectures.network_wrapper.NetworkWrapper"}, {"lineNumber": 40, "col_offset": 56, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 43, "col_offset": 11, "nodeName": "array", "type": "Callable[..., numpy.ndarray]"}, {"lineNumber": 43, "col_offset": 20, "nodeName": "action", "type": "Any"}, {"lineNumber": 45, "col_offset": 16, "nodeName": "format", "type": "Callable[..., str]"}, {"lineNumber": 48, "col_offset": 21, "nodeName": "__name__", "type": "Any"}, {"lineNumber": 64, "col_offset": 11, "nodeName": "type", "type": "Type[Type[Any]]"}, {"lineNumber": 64, "col_offset": 16, "nodeName": "actions_q_values", "type": "Any"}, {"lineNumber": 64, "col_offset": 46, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 64, "col_offset": 50, "nodeName": "actions_q_values", "type": "Any"}, {"lineNumber": 65, "col_offset": 48, "nodeName": "selected_head", "type": "Any"}, {"lineNumber": 69, "col_offset": 8, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 72, "col_offset": 11, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 73, "col_offset": 46, "nodeName": "env", "type": "Any"}, {"lineNumber": 74, "col_offset": 16, "nodeName": "append", "type": "Callable"}, {"lineNumber": 76, "col_offset": 57, "nodeName": "action", "type": "Any"}, {"lineNumber": 40, "col_offset": 15, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 43, "col_offset": 11, "nodeName": "np", "type": "module"}, {"lineNumber": 48, "col_offset": 21, "nodeName": "__class__", "type": "Any"}, {"lineNumber": 65, "col_offset": 48, "nodeName": "exploration_policy", "type": "Any"}, {"lineNumber": 73, "col_offset": 46, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 74, "col_offset": 62, "nodeName": "actions_q_values", "type": "Any"}, {"lineNumber": 48, "col_offset": 21, "nodeName": "policy", "type": "Any"}, {"lineNumber": 65, "col_offset": 48, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 74, "col_offset": 16, "nodeName": "episode_running_info", "type": "Dict[Any, List[Any]]"}, {"lineNumber": 74, "col_offset": 79, "nodeName": "idx", "type": "int"}, {"lineNumber": 74, "col_offset": 16, "nodeName": "self", "type": "ValueOptimizationAgent"}, {"lineNumber": 74, "col_offset": 42, "nodeName": "action_name", "type": "Any"}]