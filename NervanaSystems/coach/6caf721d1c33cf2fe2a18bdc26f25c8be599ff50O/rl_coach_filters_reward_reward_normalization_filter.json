[{"lineNumber": 26, "col_offset": 32, "nodeName": "RewardFilter", "type": "Type[rl_coach.filters.reward.reward_filter.RewardFilter]"}, {"lineNumber": 59, "col_offset": 78, "nodeName": "RewardType", "type": "Union[Type[float], Type[int], Type[numpy.ndarray]]"}, {"lineNumber": 69, "col_offset": 76, "nodeName": "RewardSpace", "type": "Type[rl_coach.spaces.RewardSpace]"}, {"lineNumber": 38, "col_offset": 8, "nodeName": "clip_min", "type": "float"}, {"lineNumber": 38, "col_offset": 24, "nodeName": "clip_min", "type": "float"}, {"lineNumber": 39, "col_offset": 8, "nodeName": "clip_max", "type": "float"}, {"lineNumber": 39, "col_offset": 24, "nodeName": "clip_max", "type": "float"}, {"lineNumber": 40, "col_offset": 8, "nodeName": "running_rewards_stats", "type": "None"}, {"lineNumber": 60, "col_offset": 11, "nodeName": "update_internal_state", "type": "bool"}, {"lineNumber": 65, "col_offset": 8, "nodeName": "reward", "type": "Any"}, {"lineNumber": 67, "col_offset": 15, "nodeName": "reward", "type": "Any"}, {"lineNumber": 70, "col_offset": 15, "nodeName": "input_reward_space", "type": "rl_coach.spaces.RewardSpace"}, {"lineNumber": 32, "col_offset": 33, "nodeName": "float", "type": "Type[float]"}, {"lineNumber": 32, "col_offset": 55, "nodeName": "float", "type": "Type[float]"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "__init__", "type": "Callable[[], None]"}, {"lineNumber": 38, "col_offset": 8, "nodeName": "self", "type": "RewardNormalizationFilter"}, {"lineNumber": 39, "col_offset": 8, "nodeName": "self", "type": "RewardNormalizationFilter"}, {"lineNumber": 40, "col_offset": 8, "nodeName": "self", "type": "RewardNormalizationFilter"}, {"lineNumber": 48, "col_offset": 37, "nodeName": "SharedRunningStats", "type": "Type[rl_coach.architectures.tensorflow_components.shared_variables.SharedRunningStats]"}, {"lineNumber": 48, "col_offset": 56, "nodeName": "device", "type": "Any"}, {"lineNumber": 57, "col_offset": 8, "nodeName": "set_session", "type": "Any"}, {"lineNumber": 57, "col_offset": 47, "nodeName": "sess", "type": "Any"}, {"lineNumber": 59, "col_offset": 29, "nodeName": "RewardType", "type": "Union[Type[float], Type[int], Type[numpy.ndarray]]"}, {"lineNumber": 59, "col_offset": 64, "nodeName": "bool", "type": "Type[bool]"}, {"lineNumber": 65, "col_offset": 17, "nodeName": "clip", "type": "Any"}, {"lineNumber": 65, "col_offset": 25, "nodeName": "reward", "type": "Any"}, {"lineNumber": 65, "col_offset": 33, "nodeName": "clip_min", "type": "float"}, {"lineNumber": 65, "col_offset": 48, "nodeName": "clip_max", "type": "float"}, {"lineNumber": 69, "col_offset": 60, "nodeName": "RewardSpace", "type": "Type[rl_coach.spaces.RewardSpace]"}, {"lineNumber": 49, "col_offset": 70, "nodeName": "memory_backend_params", "type": "Any"}, {"lineNumber": 57, "col_offset": 8, "nodeName": "running_rewards_stats", "type": "Any"}, {"lineNumber": 61, "col_offset": 12, "nodeName": "push", "type": "Any"}, {"lineNumber": 61, "col_offset": 44, "nodeName": "reward", "type": "Union[int, float, numpy.ndarray]"}, {"lineNumber": 63, "col_offset": 18, "nodeName": "reward", "type": "Union[int, float, numpy.ndarray]"}, {"lineNumber": 63, "col_offset": 27, "nodeName": "mean", "type": "Any"}, {"lineNumber": 64, "col_offset": 23, "nodeName": "std", "type": "Any"}, {"lineNumber": 65, "col_offset": 17, "nodeName": "np", "type": "module"}, {"lineNumber": 65, "col_offset": 33, "nodeName": "self", "type": "RewardNormalizationFilter"}, {"lineNumber": 65, "col_offset": 48, "nodeName": "self", "type": "RewardNormalizationFilter"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 57, "col_offset": 8, "nodeName": "self", "type": "RewardNormalizationFilter"}, {"lineNumber": 61, "col_offset": 12, "nodeName": "running_rewards_stats", "type": "Any"}, {"lineNumber": 63, "col_offset": 27, "nodeName": "running_rewards_stats", "type": "Any"}, {"lineNumber": 64, "col_offset": 23, "nodeName": "running_rewards_stats", "type": "Any"}, {"lineNumber": 61, "col_offset": 12, "nodeName": "self", "type": "RewardNormalizationFilter"}, {"lineNumber": 63, "col_offset": 27, "nodeName": "self", "type": "RewardNormalizationFilter"}, {"lineNumber": 64, "col_offset": 23, "nodeName": "self", "type": "RewardNormalizationFilter"}]