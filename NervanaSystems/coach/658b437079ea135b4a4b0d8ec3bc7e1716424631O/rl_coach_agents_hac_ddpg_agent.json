[{"lineNumber": 27, "col_offset": 33, "nodeName": "DDPGAlgorithmParameters", "type": "Type[rl_coach.agents.ddpg_agent.DDPGAlgorithmParameters]"}, {"lineNumber": 34, "col_offset": 29, "nodeName": "DDPGAgentParameters", "type": "Type[rl_coach.agents.ddpg_agent.DDPGAgentParameters]"}, {"lineNumber": 45, "col_offset": 19, "nodeName": "DDPGAgent", "type": "Type[rl_coach.agents.ddpg_agent.DDPGAgent]"}, {"lineNumber": 30, "col_offset": 8, "nodeName": "time_limit", "type": "int"}, {"lineNumber": 31, "col_offset": 8, "nodeName": "sub_goal_testing_rate", "type": "float"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "algorithm", "type": "HACDDPGAlgorithmParameters"}, {"lineNumber": 48, "col_offset": 8, "nodeName": "sub_goal_testing_rate", "type": "Any"}, {"lineNumber": 48, "col_offset": 37, "nodeName": "sub_goal_testing_rate", "type": "Any"}, {"lineNumber": 49, "col_offset": 8, "nodeName": "graph_manager", "type": "None"}, {"lineNumber": 55, "col_offset": 8, "nodeName": "graph_manager", "type": "Any"}, {"lineNumber": 55, "col_offset": 24, "nodeName": "parent_graph_manager", "type": "Any"}, {"lineNumber": 56, "col_offset": 11, "nodeName": "is_a_highest_level_agent", "type": "bool"}, {"lineNumber": 65, "col_offset": 8, "nodeName": "action_info", "type": "rl_coach.core_types.ActionInfo"}, {"lineNumber": 66, "col_offset": 15, "nodeName": "action_info", "type": "rl_coach.core_types.ActionInfo"}, {"lineNumber": 69, "col_offset": 8, "nodeName": "graph_manager", "type": "Any"}, {"lineNumber": 69, "col_offset": 24, "nodeName": "parent_graph_manager", "type": "Any"}, {"lineNumber": 96, "col_offset": 15, "nodeName": "transition", "type": "Any"}, {"lineNumber": 101, "col_offset": 11, "nodeName": "is_a_highest_level_agent", "type": "bool"}, {"lineNumber": 29, "col_offset": 8, "nodeName": "__init__", "type": "Callable[[], None]"}, {"lineNumber": 30, "col_offset": 8, "nodeName": "self", "type": "HACDDPGAlgorithmParameters"}, {"lineNumber": 31, "col_offset": 8, "nodeName": "self", "type": "HACDDPGAlgorithmParameters"}, {"lineNumber": 36, "col_offset": 8, "nodeName": "__init__", "type": "Callable[[], None]"}, {"lineNumber": 37, "col_offset": 8, "nodeName": "self", "type": "HACDDPGAgentParameters"}, {"lineNumber": 37, "col_offset": 25, "nodeName": "HACDDPGAlgorithmParameters", "type": "Type[HACDDPGAlgorithmParameters]"}, {"lineNumber": 47, "col_offset": 8, "nodeName": "__init__", "type": "Callable[..., None]"}, {"lineNumber": 47, "col_offset": 25, "nodeName": "agent_parameters", "type": "Any"}, {"lineNumber": 47, "col_offset": 43, "nodeName": "parent", "type": "Any"}, {"lineNumber": 48, "col_offset": 8, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 48, "col_offset": 37, "nodeName": "algorithm", "type": "rl_coach.base_parameters.AlgorithmParameters"}, {"lineNumber": 49, "col_offset": 8, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 55, "col_offset": 24, "nodeName": "parent_level_manager", "type": "Any"}, {"lineNumber": 56, "col_offset": 11, "nodeName": "ap", "type": "rl_coach.base_parameters.AgentParameters"}, {"lineNumber": 57, "col_offset": 12, "nodeName": "should_test_current_sub_goal", "type": "Any"}, {"lineNumber": 59, "col_offset": 11, "nodeName": "phase", "type": "rl_coach.core_types.RunPhase"}, {"lineNumber": 59, "col_offset": 25, "nodeName": "TRAIN", "type": "Any"}, {"lineNumber": 60, "col_offset": 15, "nodeName": "should_test_current_sub_goal", "type": "Any"}, {"lineNumber": 65, "col_offset": 22, "nodeName": "choose_action", "type": "Callable[[Any], rl_coach.core_types.ActionInfo]"}, {"lineNumber": 65, "col_offset": 44, "nodeName": "curr_state", "type": "Any"}, {"lineNumber": 69, "col_offset": 24, "nodeName": "parent_level_manager", "type": "Any"}, {"lineNumber": 72, "col_offset": 15, "nodeName": "is_a_highest_level_agent", "type": "bool"}, {"lineNumber": 73, "col_offset": 47, "nodeName": "current_hrl_goal", "type": "Any"}, {"lineNumber": 74, "col_offset": 52, "nodeName": "current_hrl_goal", "type": "Any"}, {"lineNumber": 80, "col_offset": 12, "nodeName": "reward", "type": "Any"}, {"lineNumber": 80, "col_offset": 32, "nodeName": "goal_reward", "type": "Any"}, {"lineNumber": 81, "col_offset": 12, "nodeName": "game_over", "type": "Any"}, {"lineNumber": 84, "col_offset": 51, "nodeName": "should_test_current_sub_goal", "type": "Any"}, {"lineNumber": 92, "col_offset": 12, "nodeName": "sub_goal_is_missed", "type": "bool"}, {"lineNumber": 94, "col_offset": 15, "nodeName": "sub_goal_is_missed", "type": "bool"}, {"lineNumber": 98, "col_offset": 49, "nodeName": "SpacesDefinition", "type": "Type[rl_coach.spaces.SpacesDefinition]"}, {"lineNumber": 99, "col_offset": 8, "nodeName": "set_environment_parameters", "type": "Callable[[rl_coach.spaces.SpacesDefinition], None]"}, {"lineNumber": 99, "col_offset": 43, "nodeName": "spaces", "type": "rl_coach.spaces.SpacesDefinition"}, {"lineNumber": 101, "col_offset": 11, "nodeName": "ap", "type": "rl_coach.base_parameters.AgentParameters"}, {"lineNumber": 104, "col_offset": 12, "nodeName": "goal", "type": "Any"}, {"lineNumber": 104, "col_offset": 31, "nodeName": "action", "type": "Any"}, {"lineNumber": 107, "col_offset": 15, "nodeName": "is_a_highest_level_agent", "type": "bool"}, {"lineNumber": 108, "col_offset": 12, "nodeName": "reward_success_threshold", "type": "Any"}, {"lineNumber": 108, "col_offset": 58, "nodeName": "goal_reaching_reward", "type": "Any"}, {"lineNumber": 46, "col_offset": 49, "nodeName": "Union", "type": "Any"}, {"lineNumber": 48, "col_offset": 37, "nodeName": "ap", "type": "rl_coach.base_parameters.AgentParameters"}, {"lineNumber": 55, "col_offset": 24, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 56, "col_offset": 11, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 57, "col_offset": 12, "nodeName": "graph_manager", "type": "Any"}, {"lineNumber": 57, "col_offset": 76, "nodeName": "sub_goal_testing_rate", "type": "Any"}, {"lineNumber": 59, "col_offset": 11, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 59, "col_offset": 25, "nodeName": "RunPhase", "type": "Type[rl_coach.core_types.RunPhase]"}, {"lineNumber": 60, "col_offset": 15, "nodeName": "graph_manager", "type": "Any"}, {"lineNumber": 69, "col_offset": 24, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 72, "col_offset": 15, "nodeName": "ap", "type": "rl_coach.base_parameters.AgentParameters"}, {"lineNumber": 73, "col_offset": 12, "nodeName": "state", "type": "Any"}, {"lineNumber": 73, "col_offset": 47, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 74, "col_offset": 12, "nodeName": "next_state", "type": "Any"}, {"lineNumber": 74, "col_offset": 52, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 76, "col_offset": 12, "nodeName": "add_sample", "type": "Any"}, {"lineNumber": 78, "col_offset": 44, "nodeName": "get_reward_for_goal_and_state", "type": "Any"}, {"lineNumber": 79, "col_offset": 16, "nodeName": "current_hrl_goal", "type": "Any"}, {"lineNumber": 79, "col_offset": 39, "nodeName": "next_state", "type": "Any"}, {"lineNumber": 80, "col_offset": 12, "nodeName": "transition", "type": "Any"}, {"lineNumber": 81, "col_offset": 12, "nodeName": "transition", "type": "Any"}, {"lineNumber": 81, "col_offset": 35, "nodeName": "game_over", "type": "Any"}, {"lineNumber": 81, "col_offset": 59, "nodeName": "sub_goal_reached", "type": "Any"}, {"lineNumber": 84, "col_offset": 15, "nodeName": "is_a_lowest_level_agent", "type": "bool"}, {"lineNumber": 84, "col_offset": 51, "nodeName": "graph_manager", "type": "Any"}, {"lineNumber": 89, "col_offset": 34, "nodeName": "get_reward_for_goal_and_state", "type": "Any"}, {"lineNumber": 90, "col_offset": 16, "nodeName": "action", "type": "Any"}, {"lineNumber": 90, "col_offset": 35, "nodeName": "next_state", "type": "Any"}, {"lineNumber": 92, "col_offset": 37, "nodeName": "sub_goal_reached", "type": "Any"}, {"lineNumber": 95, "col_offset": 20, "nodeName": "reward", "type": "Any"}, {"lineNumber": 101, "col_offset": 11, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 104, "col_offset": 12, "nodeName": "spaces", "type": "Any"}, {"lineNumber": 104, "col_offset": 31, "nodeName": "spaces", "type": "Any"}, {"lineNumber": 105, "col_offset": 12, "nodeName": "set_target_space", "type": "Any"}, {"lineNumber": 107, "col_offset": 15, "nodeName": "ap", "type": "rl_coach.base_parameters.AgentParameters"}, {"lineNumber": 108, "col_offset": 12, "nodeName": "reward", "type": "Any"}, {"lineNumber": 108, "col_offset": 58, "nodeName": "reward_type", "type": "Any"}, {"lineNumber": 29, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 36, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 47, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 48, "col_offset": 37, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 57, "col_offset": 57, "nodeName": "rand", "type": "Any"}, {"lineNumber": 57, "col_offset": 76, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 61, "col_offset": 16, "nodeName": "change_phase", "type": "Any"}, {"lineNumber": 61, "col_offset": 53, "nodeName": "TEST", "type": "Any"}, {"lineNumber": 63, "col_offset": 16, "nodeName": "change_phase", "type": "Any"}, {"lineNumber": 63, "col_offset": 53, "nodeName": "phase", "type": "rl_coach.core_types.RunPhase"}, {"lineNumber": 65, "col_offset": 22, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 72, "col_offset": 15, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 73, "col_offset": 12, "nodeName": "transition", "type": "Any"}, {"lineNumber": 74, "col_offset": 12, "nodeName": "transition", "type": "Any"}, {"lineNumber": 76, "col_offset": 12, "nodeName": "distance_from_goal", "type": "Any"}, {"lineNumber": 76, "col_offset": 47, "nodeName": "distance_from_goal", "type": "Any"}, {"lineNumber": 77, "col_offset": 16, "nodeName": "current_hrl_goal", "type": "Any"}, {"lineNumber": 77, "col_offset": 39, "nodeName": "next_state", "type": "Any"}, {"lineNumber": 78, "col_offset": 44, "nodeName": "goal", "type": "Any"}, {"lineNumber": 79, "col_offset": 16, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 79, "col_offset": 39, "nodeName": "transition", "type": "Any"}, {"lineNumber": 81, "col_offset": 35, "nodeName": "transition", "type": "Any"}, {"lineNumber": 84, "col_offset": 15, "nodeName": "ap", "type": "rl_coach.base_parameters.AgentParameters"}, {"lineNumber": 89, "col_offset": 34, "nodeName": "goal", "type": "Any"}, {"lineNumber": 90, "col_offset": 16, "nodeName": "transition", "type": "Any"}, {"lineNumber": 90, "col_offset": 35, "nodeName": "transition", "type": "Any"}, {"lineNumber": 95, "col_offset": 20, "nodeName": "transition", "type": "Any"}, {"lineNumber": 95, "col_offset": 41, "nodeName": "time_limit", "type": "Any"}, {"lineNumber": 99, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 104, "col_offset": 12, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 104, "col_offset": 31, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 105, "col_offset": 12, "nodeName": "goal", "type": "Any"}, {"lineNumber": 105, "col_offset": 46, "nodeName": "state", "type": "Any"}, {"lineNumber": 107, "col_offset": 15, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 108, "col_offset": 12, "nodeName": "spaces", "type": "Any"}, {"lineNumber": 108, "col_offset": 58, "nodeName": "goal", "type": "Any"}, {"lineNumber": 57, "col_offset": 57, "nodeName": "random", "type": "Any"}, {"lineNumber": 61, "col_offset": 16, "nodeName": "exploration_policy", "type": "Any"}, {"lineNumber": 61, "col_offset": 53, "nodeName": "RunPhase", "type": "Type[rl_coach.core_types.RunPhase]"}, {"lineNumber": 63, "col_offset": 16, "nodeName": "exploration_policy", "type": "Any"}, {"lineNumber": 63, "col_offset": 53, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 76, "col_offset": 12, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 76, "col_offset": 47, "nodeName": "goal", "type": "Any"}, {"lineNumber": 77, "col_offset": 16, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 77, "col_offset": 39, "nodeName": "transition", "type": "Any"}, {"lineNumber": 78, "col_offset": 44, "nodeName": "spaces", "type": "Any"}, {"lineNumber": 84, "col_offset": 15, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 89, "col_offset": 34, "nodeName": "spaces", "type": "Any"}, {"lineNumber": 95, "col_offset": 41, "nodeName": "algorithm", "type": "rl_coach.base_parameters.AlgorithmParameters"}, {"lineNumber": 105, "col_offset": 12, "nodeName": "spaces", "type": "Any"}, {"lineNumber": 105, "col_offset": 46, "nodeName": "spaces", "type": "Any"}, {"lineNumber": 105, "col_offset": 64, "nodeName": "goal_name", "type": "Any"}, {"lineNumber": 108, "col_offset": 12, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 108, "col_offset": 58, "nodeName": "spaces", "type": "Any"}, {"lineNumber": 57, "col_offset": 57, "nodeName": "np", "type": "module"}, {"lineNumber": 61, "col_offset": 16, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 63, "col_offset": 16, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 76, "col_offset": 47, "nodeName": "spaces", "type": "Any"}, {"lineNumber": 78, "col_offset": 44, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 89, "col_offset": 34, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 95, "col_offset": 41, "nodeName": "ap", "type": "rl_coach.base_parameters.AgentParameters"}, {"lineNumber": 105, "col_offset": 12, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 105, "col_offset": 46, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 105, "col_offset": 64, "nodeName": "goal", "type": "Any"}, {"lineNumber": 108, "col_offset": 58, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 76, "col_offset": 47, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 95, "col_offset": 41, "nodeName": "self", "type": "HACDDPGAgent"}, {"lineNumber": 105, "col_offset": 64, "nodeName": "spaces", "type": "Any"}, {"lineNumber": 105, "col_offset": 64, "nodeName": "self", "type": "HACDDPGAgent"}]