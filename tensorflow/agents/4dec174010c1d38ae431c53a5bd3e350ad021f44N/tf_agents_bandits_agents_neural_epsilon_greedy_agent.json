[{"lineNumber": 41, "col_offset": 4, "nodeName": "GreedyRewardPredictionAgent", "type": "Any"}, {"lineNumber": 41, "col_offset": 4, "nodeName": "greedy_reward_prediction_agent", "type": "module"}, {"lineNumber": 61, "col_offset": 36, "nodeName": "mean_squared_error", "type": "Any"}, {"lineNumber": 154, "col_offset": 4, "nodeName": "_collect_policy", "type": "Any"}, {"lineNumber": 154, "col_offset": 27, "nodeName": "_policy", "type": "Any"}, {"lineNumber": 61, "col_offset": 36, "nodeName": "losses", "type": "Any"}, {"lineNumber": 133, "col_offset": 4, "nodeName": "__init__", "type": "Any"}, {"lineNumber": 152, "col_offset": 19, "nodeName": "EpsilonGreedyPolicy", "type": "Any"}, {"lineNumber": 153, "col_offset": 8, "nodeName": "_policy", "type": "Any"}, {"lineNumber": 154, "col_offset": 4, "nodeName": "self", "type": "Any"}, {"lineNumber": 154, "col_offset": 27, "nodeName": "self", "type": "Any"}, {"lineNumber": 71, "col_offset": 12, "nodeName": "Optional", "type": "Any"}, {"lineNumber": 61, "col_offset": 36, "nodeName": "v1", "type": "Any"}, {"lineNumber": 134, "col_offset": 23, "nodeName": "time_step_spec", "type": "Any"}, {"lineNumber": 135, "col_offset": 20, "nodeName": "action_spec", "type": "Any"}, {"lineNumber": 136, "col_offset": 23, "nodeName": "reward_network", "type": "Any"}, {"lineNumber": 137, "col_offset": 18, "nodeName": "optimizer", "type": "Any"}, {"lineNumber": 139, "col_offset": 12, "nodeName": "observation_and_action_constraint_splitter", "type": "Optional[Callable[[Any], Iterable[Any]]]"}, {"lineNumber": 140, "col_offset": 33, "nodeName": "accepts_per_arm_features", "type": "bool"}, {"lineNumber": 141, "col_offset": 20, "nodeName": "constraints", "type": "Iterable[tf_agents.bandits.policies.constraints.NeuralConstraint]"}, {"lineNumber": 142, "col_offset": 22, "nodeName": "error_loss_fn", "type": "Callable[..., Any]"}, {"lineNumber": 143, "col_offset": 26, "nodeName": "gradient_clipping", "type": "Optional[float]"}, {"lineNumber": 144, "col_offset": 24, "nodeName": "debug_summaries", "type": "bool"}, {"lineNumber": 145, "col_offset": 33, "nodeName": "summarize_grads_and_vars", "type": "bool"}, {"lineNumber": 146, "col_offset": 25, "nodeName": "enable_summaries", "type": "bool"}, {"lineNumber": 147, "col_offset": 25, "nodeName": "emit_policy_info", "type": "Tuple[str, ...]"}, {"lineNumber": 148, "col_offset": 27, "nodeName": "train_step_counter", "type": "Any"}, {"lineNumber": 149, "col_offset": 25, "nodeName": "laplacian_matrix", "type": "Any"}, {"lineNumber": 150, "col_offset": 35, "nodeName": "laplacian_smoothing_weight", "type": "float"}, {"lineNumber": 151, "col_offset": 13, "nodeName": "name", "type": "Optional[str]"}, {"lineNumber": 152, "col_offset": 19, "nodeName": "epsilon_greedy_policy", "type": "module"}, {"lineNumber": 153, "col_offset": 8, "nodeName": "self", "type": "Any"}, {"lineNumber": 153, "col_offset": 30, "nodeName": "epsilon", "type": "float"}, {"lineNumber": 71, "col_offset": 21, "nodeName": "Text", "type": "Type[str]"}, {"lineNumber": 61, "col_offset": 36, "nodeName": "compat", "type": "Any"}, {"lineNumber": 133, "col_offset": 4, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 133, "col_offset": 10, "nodeName": "NeuralEpsilonGreedyAgent", "type": "Any"}, {"lineNumber": 133, "col_offset": 36, "nodeName": "self", "type": "Any"}, {"lineNumber": 61, "col_offset": 36, "nodeName": "tf", "type": "Any"}]