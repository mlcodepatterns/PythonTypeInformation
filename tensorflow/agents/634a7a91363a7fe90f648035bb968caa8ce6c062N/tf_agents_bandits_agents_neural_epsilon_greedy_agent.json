[{"lineNumber": 36, "col_offset": 4, "nodeName": "GreedyRewardPredictionAgent", "type": "Any"}, {"lineNumber": 36, "col_offset": 4, "nodeName": "greedy_reward_prediction_agent", "type": "module"}, {"lineNumber": 54, "col_offset": 20, "nodeName": "mean_squared_error", "type": "Any"}, {"lineNumber": 144, "col_offset": 4, "nodeName": "_collect_policy", "type": "Any"}, {"lineNumber": 144, "col_offset": 27, "nodeName": "_policy", "type": "Any"}, {"lineNumber": 54, "col_offset": 20, "nodeName": "losses", "type": "Any"}, {"lineNumber": 124, "col_offset": 4, "nodeName": "__init__", "type": "Any"}, {"lineNumber": 142, "col_offset": 19, "nodeName": "EpsilonGreedyPolicy", "type": "Any"}, {"lineNumber": 143, "col_offset": 8, "nodeName": "_policy", "type": "Any"}, {"lineNumber": 144, "col_offset": 4, "nodeName": "self", "type": "Any"}, {"lineNumber": 144, "col_offset": 27, "nodeName": "self", "type": "Any"}, {"lineNumber": 54, "col_offset": 20, "nodeName": "v1", "type": "Any"}, {"lineNumber": 125, "col_offset": 23, "nodeName": "time_step_spec", "type": "Any"}, {"lineNumber": 126, "col_offset": 20, "nodeName": "action_spec", "type": "Any"}, {"lineNumber": 127, "col_offset": 23, "nodeName": "reward_network", "type": "Any"}, {"lineNumber": 128, "col_offset": 18, "nodeName": "optimizer", "type": "Any"}, {"lineNumber": 130, "col_offset": 12, "nodeName": "observation_and_action_constraint_splitter", "type": "Any"}, {"lineNumber": 131, "col_offset": 33, "nodeName": "accepts_per_arm_features", "type": "Any"}, {"lineNumber": 132, "col_offset": 22, "nodeName": "error_loss_fn", "type": "Any"}, {"lineNumber": 133, "col_offset": 26, "nodeName": "gradient_clipping", "type": "Any"}, {"lineNumber": 134, "col_offset": 24, "nodeName": "debug_summaries", "type": "Any"}, {"lineNumber": 135, "col_offset": 33, "nodeName": "summarize_grads_and_vars", "type": "Any"}, {"lineNumber": 136, "col_offset": 25, "nodeName": "enable_summaries", "type": "Any"}, {"lineNumber": 137, "col_offset": 25, "nodeName": "emit_policy_info", "type": "Any"}, {"lineNumber": 138, "col_offset": 27, "nodeName": "train_step_counter", "type": "Any"}, {"lineNumber": 139, "col_offset": 25, "nodeName": "laplacian_matrix", "type": "Any"}, {"lineNumber": 140, "col_offset": 35, "nodeName": "laplacian_smoothing_weight", "type": "Any"}, {"lineNumber": 141, "col_offset": 13, "nodeName": "name", "type": "Any"}, {"lineNumber": 142, "col_offset": 19, "nodeName": "epsilon_greedy_policy", "type": "module"}, {"lineNumber": 143, "col_offset": 8, "nodeName": "self", "type": "Any"}, {"lineNumber": 143, "col_offset": 30, "nodeName": "epsilon", "type": "Any"}, {"lineNumber": 54, "col_offset": 20, "nodeName": "compat", "type": "Any"}, {"lineNumber": 124, "col_offset": 4, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 124, "col_offset": 10, "nodeName": "NeuralEpsilonGreedyAgent", "type": "Any"}, {"lineNumber": 124, "col_offset": 36, "nodeName": "self", "type": "Any"}, {"lineNumber": 54, "col_offset": 20, "nodeName": "tf", "type": "Any"}]