[{"lineNumber": 11, "col_offset": 3, "nodeName": "TYPE_CHECKING", "type": "bool"}, {"lineNumber": 15, "col_offset": 21, "nodeName": "Tokenizer", "type": "Type[rasa_nlu.tokenizers.Tokenizer]"}, {"lineNumber": 15, "col_offset": 32, "nodeName": "Component", "type": "Type[rasa_nlu.components.Component]"}, {"lineNumber": 22, "col_offset": 4, "nodeName": "train", "type": "Callable[..., None]"}, {"lineNumber": 28, "col_offset": 4, "nodeName": "process", "type": "Callable[..., None]"}, {"lineNumber": 33, "col_offset": 4, "nodeName": "tokenize", "type": "Callable[[Any, Any], List[rasa_nlu.tokenizers.Token]]"}, {"lineNumber": 11, "col_offset": 3, "nodeName": "typing", "type": "module"}, {"lineNumber": 16, "col_offset": 4, "nodeName": "name", "type": "str"}, {"lineNumber": 18, "col_offset": 4, "nodeName": "provides", "type": "List[str]"}, {"lineNumber": 20, "col_offset": 4, "nodeName": "requires", "type": "List[str]"}, {"lineNumber": 25, "col_offset": 12, "nodeName": "example", "type": "Any"}, {"lineNumber": 25, "col_offset": 23, "nodeName": "training_examples", "type": "Any"}, {"lineNumber": 25, "col_offset": 23, "nodeName": "training_data", "type": "Any"}, {"lineNumber": 31, "col_offset": 8, "nodeName": "set", "type": "Any"}, {"lineNumber": 26, "col_offset": 12, "nodeName": "set", "type": "Any"}, {"lineNumber": 31, "col_offset": 8, "nodeName": "message", "type": "Any"}, {"lineNumber": 31, "col_offset": 30, "nodeName": "tokenize", "type": "Callable[[Any], List[rasa_nlu.tokenizers.Token]]"}, {"lineNumber": 36, "col_offset": 16, "nodeName": "Token", "type": "Type[rasa_nlu.tokenizers.Token]"}, {"lineNumber": 36, "col_offset": 22, "nodeName": "text", "type": "Any"}, {"lineNumber": 36, "col_offset": 30, "nodeName": "idx", "type": "Any"}, {"lineNumber": 36, "col_offset": 41, "nodeName": "t", "type": "Any"}, {"lineNumber": 36, "col_offset": 46, "nodeName": "doc", "type": "Any"}, {"lineNumber": 26, "col_offset": 12, "nodeName": "example", "type": "Any"}, {"lineNumber": 26, "col_offset": 34, "nodeName": "tokenize", "type": "Callable[[Any], List[rasa_nlu.tokenizers.Token]]"}, {"lineNumber": 31, "col_offset": 30, "nodeName": "self", "type": "SpacyTokenizer"}, {"lineNumber": 31, "col_offset": 44, "nodeName": "get", "type": "Any"}, {"lineNumber": 36, "col_offset": 22, "nodeName": "t", "type": "Any"}, {"lineNumber": 36, "col_offset": 30, "nodeName": "t", "type": "Any"}, {"lineNumber": 26, "col_offset": 34, "nodeName": "self", "type": "SpacyTokenizer"}, {"lineNumber": 26, "col_offset": 48, "nodeName": "get", "type": "Any"}, {"lineNumber": 31, "col_offset": 44, "nodeName": "message", "type": "Any"}, {"lineNumber": 26, "col_offset": 48, "nodeName": "example", "type": "Any"}]