[{"lineNumber": 11, "col_offset": 26, "nodeName": "Tokenizer", "type": "Type[rasa_nlu.tokenizers.Tokenizer]"}, {"lineNumber": 11, "col_offset": 37, "nodeName": "Component", "type": "Type[rasa_nlu.components.Component]"}, {"lineNumber": 16, "col_offset": 4, "nodeName": "train", "type": "Callable[..., None]"}, {"lineNumber": 22, "col_offset": 4, "nodeName": "process", "type": "Callable[..., None]"}, {"lineNumber": 27, "col_offset": 4, "nodeName": "tokenize", "type": "Callable[[Any, Union[str, unicode]], List[rasa_nlu.tokenizers.Token]]"}, {"lineNumber": 12, "col_offset": 4, "nodeName": "name", "type": "str"}, {"lineNumber": 14, "col_offset": 4, "nodeName": "provides", "type": "List[str]"}, {"lineNumber": 19, "col_offset": 12, "nodeName": "example", "type": "Any"}, {"lineNumber": 19, "col_offset": 23, "nodeName": "training_examples", "type": "Any"}, {"lineNumber": 32, "col_offset": 8, "nodeName": "words", "type": "List[str]"}, {"lineNumber": 34, "col_offset": 8, "nodeName": "running_offset", "type": "int"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "tokens", "type": "List[rasa_nlu.tokenizers.Token]"}, {"lineNumber": 36, "col_offset": 12, "nodeName": "word", "type": "str"}, {"lineNumber": 36, "col_offset": 20, "nodeName": "words", "type": "List[str]"}, {"lineNumber": 41, "col_offset": 15, "nodeName": "tokens", "type": "List[rasa_nlu.tokenizers.Token]"}, {"lineNumber": 19, "col_offset": 23, "nodeName": "training_data", "type": "rasa_nlu.training_data.training_data.TrainingData"}, {"lineNumber": 25, "col_offset": 8, "nodeName": "set", "type": "Callable[..., None]"}, {"lineNumber": 32, "col_offset": 16, "nodeName": "split", "type": "Callable[..., List[str]]"}, {"lineNumber": 37, "col_offset": 12, "nodeName": "word_offset", "type": "int"}, {"lineNumber": 38, "col_offset": 12, "nodeName": "word_len", "type": "int"}, {"lineNumber": 39, "col_offset": 12, "nodeName": "running_offset", "type": "int"}, {"lineNumber": 20, "col_offset": 12, "nodeName": "set", "type": "Any"}, {"lineNumber": 25, "col_offset": 8, "nodeName": "message", "type": "rasa_nlu.training_data.message.Message"}, {"lineNumber": 25, "col_offset": 30, "nodeName": "tokenize", "type": "Callable[[Union[str, unicode]], List[rasa_nlu.tokenizers.Token]]"}, {"lineNumber": 25, "col_offset": 44, "nodeName": "text", "type": "Any"}, {"lineNumber": 37, "col_offset": 26, "nodeName": "index", "type": "Callable[..., int]"}, {"lineNumber": 37, "col_offset": 37, "nodeName": "word", "type": "str"}, {"lineNumber": 37, "col_offset": 43, "nodeName": "running_offset", "type": "int"}, {"lineNumber": 38, "col_offset": 23, "nodeName": "len", "type": "Callable[[Sized], int]"}, {"lineNumber": 38, "col_offset": 27, "nodeName": "word", "type": "str"}, {"lineNumber": 39, "col_offset": 29, "nodeName": "word_offset", "type": "int"}, {"lineNumber": 39, "col_offset": 43, "nodeName": "word_len", "type": "int"}, {"lineNumber": 40, "col_offset": 12, "nodeName": "append", "type": "Callable"}, {"lineNumber": 20, "col_offset": 12, "nodeName": "example", "type": "Any"}, {"lineNumber": 20, "col_offset": 34, "nodeName": "tokenize", "type": "Callable[[Union[str, unicode]], List[rasa_nlu.tokenizers.Token]]"}, {"lineNumber": 20, "col_offset": 48, "nodeName": "text", "type": "Any"}, {"lineNumber": 25, "col_offset": 30, "nodeName": "self", "type": "WhitespaceTokenizer"}, {"lineNumber": 25, "col_offset": 44, "nodeName": "message", "type": "rasa_nlu.training_data.message.Message"}, {"lineNumber": 32, "col_offset": 16, "nodeName": "sub", "type": "Callable"}, {"lineNumber": 32, "col_offset": 46, "nodeName": "text", "type": "Union[str, unicode]"}, {"lineNumber": 37, "col_offset": 26, "nodeName": "text", "type": "Union[str, unicode]"}, {"lineNumber": 40, "col_offset": 12, "nodeName": "tokens", "type": "List[rasa_nlu.tokenizers.Token]"}, {"lineNumber": 40, "col_offset": 26, "nodeName": "Token", "type": "Type[rasa_nlu.tokenizers.Token]"}, {"lineNumber": 40, "col_offset": 32, "nodeName": "word", "type": "str"}, {"lineNumber": 40, "col_offset": 38, "nodeName": "word_offset", "type": "int"}, {"lineNumber": 20, "col_offset": 34, "nodeName": "self", "type": "WhitespaceTokenizer"}, {"lineNumber": 20, "col_offset": 48, "nodeName": "example", "type": "Any"}, {"lineNumber": 32, "col_offset": 16, "nodeName": "re", "type": "module"}]