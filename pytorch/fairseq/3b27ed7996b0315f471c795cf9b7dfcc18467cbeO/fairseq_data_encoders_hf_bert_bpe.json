[{"lineNumber": 10, "col_offset": 14, "nodeName": "object", "type": "Type[object]"}, {"lineNumber": 39, "col_offset": 32, "nodeName": "str", "type": "Type[str]"}, {"lineNumber": 42, "col_offset": 32, "nodeName": "str", "type": "Type[str]"}, {"lineNumber": 47, "col_offset": 46, "nodeName": "bool", "type": "Type[bool]"}, {"lineNumber": 14, "col_offset": 8, "nodeName": "add_argument", "type": "Any"}, {"lineNumber": 17, "col_offset": 8, "nodeName": "add_argument", "type": "Any"}, {"lineNumber": 24, "col_offset": 15, "nodeName": "ImportError", "type": "Type[ImportError]"}, {"lineNumber": 29, "col_offset": 31, "nodeName": "args", "type": "Any"}, {"lineNumber": 37, "col_offset": 12, "nodeName": "bert_tokenizer", "type": "Any"}, {"lineNumber": 39, "col_offset": 24, "nodeName": "str", "type": "Type[str]"}, {"lineNumber": 40, "col_offset": 15, "nodeName": "join", "type": "Callable"}, {"lineNumber": 42, "col_offset": 24, "nodeName": "str", "type": "Type[str]"}, {"lineNumber": 43, "col_offset": 15, "nodeName": "clean_up_tokenization", "type": "Any"}, {"lineNumber": 47, "col_offset": 38, "nodeName": "str", "type": "Type[str]"}, {"lineNumber": 14, "col_offset": 8, "nodeName": "parser", "type": "Any"}, {"lineNumber": 17, "col_offset": 8, "nodeName": "parser", "type": "Any"}, {"lineNumber": 17, "col_offset": 53, "nodeName": "str", "type": "Type[str]"}, {"lineNumber": 30, "col_offset": 34, "nodeName": "BertTokenizer", "type": "Any"}, {"lineNumber": 31, "col_offset": 16, "nodeName": "bpe_vocab_file", "type": "Any"}, {"lineNumber": 35, "col_offset": 37, "nodeName": "bpe_cased", "type": "Any"}, {"lineNumber": 37, "col_offset": 12, "nodeName": "self", "type": "Any"}, {"lineNumber": 37, "col_offset": 34, "nodeName": "from_pretrained", "type": "Any"}, {"lineNumber": 37, "col_offset": 64, "nodeName": "vocab_file_name", "type": "str"}, {"lineNumber": 40, "col_offset": 24, "nodeName": "tokenize", "type": "Any"}, {"lineNumber": 40, "col_offset": 53, "nodeName": "x", "type": "str"}, {"lineNumber": 43, "col_offset": 15, "nodeName": "bert_tokenizer", "type": "Any"}, {"lineNumber": 44, "col_offset": 12, "nodeName": "convert_tokens_to_string", "type": "Any"}, {"lineNumber": 48, "col_offset": 19, "nodeName": "startswith", "type": "Callable[..., bool]"}, {"lineNumber": 25, "col_offset": 18, "nodeName": "ImportError", "type": "Type[ImportError]"}, {"lineNumber": 31, "col_offset": 16, "nodeName": "args", "type": "Any"}, {"lineNumber": 35, "col_offset": 37, "nodeName": "args", "type": "Any"}, {"lineNumber": 37, "col_offset": 34, "nodeName": "BertTokenizer", "type": "Any"}, {"lineNumber": 40, "col_offset": 24, "nodeName": "bert_tokenizer", "type": "Any"}, {"lineNumber": 43, "col_offset": 15, "nodeName": "self", "type": "Any"}, {"lineNumber": 44, "col_offset": 12, "nodeName": "bert_tokenizer", "type": "Any"}, {"lineNumber": 44, "col_offset": 57, "nodeName": "split", "type": "Callable[..., List[str]]"}, {"lineNumber": 48, "col_offset": 19, "nodeName": "x", "type": "str"}, {"lineNumber": 31, "col_offset": 55, "nodeName": "bpe_cased", "type": "Any"}, {"lineNumber": 40, "col_offset": 24, "nodeName": "self", "type": "Any"}, {"lineNumber": 44, "col_offset": 12, "nodeName": "self", "type": "Any"}, {"lineNumber": 44, "col_offset": 57, "nodeName": "x", "type": "str"}, {"lineNumber": 31, "col_offset": 55, "nodeName": "args", "type": "Any"}]