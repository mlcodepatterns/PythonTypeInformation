[{"lineNumber": 1, "col_offset": 0, "nodeName": "embedding_size", "type": "int"}, {"lineNumber": 2, "col_offset": 0, "nodeName": "num_layers", "type": "int"}, {"lineNumber": 3, "col_offset": 0, "nodeName": "rnn_size", "type": "int"}, {"lineNumber": 4, "col_offset": 0, "nodeName": "dropout", "type": "float"}, {"lineNumber": 6, "col_offset": 0, "nodeName": "learning_rate", "type": "float"}, {"lineNumber": 7, "col_offset": 0, "nodeName": "learning_rate_decay_after", "type": "int"}, {"lineNumber": 8, "col_offset": 0, "nodeName": "learning_rate_decay", "type": "float"}, {"lineNumber": 10, "col_offset": 0, "nodeName": "batch_size", "type": "int"}, {"lineNumber": 11, "col_offset": 0, "nodeName": "max_epoch", "type": "int"}, {"lineNumber": 12, "col_offset": 0, "nodeName": "grad_clipping", "type": "int"}, {"lineNumber": 13, "col_offset": 0, "nodeName": "validation_fraction", "type": "float"}, {"lineNumber": 14, "col_offset": 0, "nodeName": "validate_every", "type": "int"}, {"lineNumber": 16, "col_offset": 0, "nodeName": "save_every", "type": "int"}]