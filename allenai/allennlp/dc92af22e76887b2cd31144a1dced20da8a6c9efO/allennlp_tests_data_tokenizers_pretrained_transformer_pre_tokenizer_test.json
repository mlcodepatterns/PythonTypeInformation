[{"lineNumber": 8, "col_offset": 29, "nodeName": "AllenNlpTestCase", "type": "Type[allennlp.common.testing.test_case.AllenNlpTestCase]"}, {"lineNumber": 9, "col_offset": 4, "nodeName": "setUp", "type": "Callable[[Any], Any]"}, {"lineNumber": 13, "col_offset": 4, "nodeName": "test_tokenize_handles_complex_punctuation", "type": "Callable[[Any], Any]"}, {"lineNumber": 20, "col_offset": 27, "nodeName": "AllenNlpTestCase", "type": "Type[allennlp.common.testing.test_case.AllenNlpTestCase]"}, {"lineNumber": 21, "col_offset": 4, "nodeName": "setUp", "type": "Callable[[Any], Any]"}, {"lineNumber": 25, "col_offset": 4, "nodeName": "test_never_split", "type": "Callable[[Any], Any]"}, {"lineNumber": 31, "col_offset": 4, "nodeName": "test_do_lower_case", "type": "Callable[[Any], Any]"}, {"lineNumber": 11, "col_offset": 8, "nodeName": "word_tokenizer", "type": "Any"}, {"lineNumber": 14, "col_offset": 8, "nodeName": "sentence", "type": "str"}, {"lineNumber": 15, "col_offset": 8, "nodeName": "expected_tokens", "type": "List[str]"}, {"lineNumber": 16, "col_offset": 8, "nodeName": "tokens", "type": "List[Any]"}, {"lineNumber": 23, "col_offset": 8, "nodeName": "word_tokenizer", "type": "Any"}, {"lineNumber": 26, "col_offset": 8, "nodeName": "sentence", "type": "str"}, {"lineNumber": 27, "col_offset": 8, "nodeName": "expected_tokens", "type": "List[str]"}, {"lineNumber": 28, "col_offset": 8, "nodeName": "tokens", "type": "List[Any]"}, {"lineNumber": 33, "col_offset": 8, "nodeName": "word_tokenizer", "type": "Any"}, {"lineNumber": 34, "col_offset": 8, "nodeName": "sentence", "type": "str"}, {"lineNumber": 35, "col_offset": 8, "nodeName": "expected_tokens", "type": "List[str]"}, {"lineNumber": 36, "col_offset": 8, "nodeName": "tokens", "type": "List[Any]"}, {"lineNumber": 10, "col_offset": 8, "nodeName": "setUp", "type": "Any"}, {"lineNumber": 11, "col_offset": 8, "nodeName": "self", "type": "TestOpenAiPreTokenizer"}, {"lineNumber": 11, "col_offset": 30, "nodeName": "OpenAIPreTokenizer", "type": "Any"}, {"lineNumber": 16, "col_offset": 18, "nodeName": "text", "type": "Any"}, {"lineNumber": 17, "col_offset": 15, "nodeName": "tokens", "type": "List[Any]"}, {"lineNumber": 17, "col_offset": 25, "nodeName": "expected_tokens", "type": "List[str]"}, {"lineNumber": 22, "col_offset": 8, "nodeName": "setUp", "type": "Any"}, {"lineNumber": 23, "col_offset": 8, "nodeName": "self", "type": "TestBertPreTokenizer"}, {"lineNumber": 23, "col_offset": 30, "nodeName": "BertPreTokenizer", "type": "Any"}, {"lineNumber": 28, "col_offset": 18, "nodeName": "text", "type": "Any"}, {"lineNumber": 29, "col_offset": 15, "nodeName": "tokens", "type": "List[Any]"}, {"lineNumber": 29, "col_offset": 25, "nodeName": "expected_tokens", "type": "List[str]"}, {"lineNumber": 33, "col_offset": 25, "nodeName": "BertPreTokenizer", "type": "Any"}, {"lineNumber": 36, "col_offset": 18, "nodeName": "text", "type": "Any"}, {"lineNumber": 37, "col_offset": 15, "nodeName": "tokens", "type": "List[Any]"}, {"lineNumber": 37, "col_offset": 25, "nodeName": "expected_tokens", "type": "List[str]"}, {"lineNumber": 16, "col_offset": 18, "nodeName": "t", "type": "Any"}, {"lineNumber": 16, "col_offset": 29, "nodeName": "t", "type": "Any"}, {"lineNumber": 28, "col_offset": 18, "nodeName": "token", "type": "Any"}, {"lineNumber": 28, "col_offset": 33, "nodeName": "token", "type": "Any"}, {"lineNumber": 36, "col_offset": 18, "nodeName": "token", "type": "Any"}, {"lineNumber": 36, "col_offset": 33, "nodeName": "token", "type": "Any"}, {"lineNumber": 10, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 16, "col_offset": 34, "nodeName": "tokenize", "type": "Any"}, {"lineNumber": 16, "col_offset": 63, "nodeName": "sentence", "type": "str"}, {"lineNumber": 22, "col_offset": 8, "nodeName": "super", "type": "Type[super]"}, {"lineNumber": 28, "col_offset": 42, "nodeName": "tokenize", "type": "Any"}, {"lineNumber": 28, "col_offset": 71, "nodeName": "sentence", "type": "str"}, {"lineNumber": 36, "col_offset": 42, "nodeName": "tokenize", "type": "Any"}, {"lineNumber": 36, "col_offset": 66, "nodeName": "sentence", "type": "str"}, {"lineNumber": 16, "col_offset": 34, "nodeName": "word_tokenizer", "type": "Any"}, {"lineNumber": 28, "col_offset": 42, "nodeName": "word_tokenizer", "type": "Any"}, {"lineNumber": 36, "col_offset": 42, "nodeName": "word_tokenizer", "type": "Any"}, {"lineNumber": 16, "col_offset": 34, "nodeName": "self", "type": "TestOpenAiPreTokenizer"}, {"lineNumber": 28, "col_offset": 42, "nodeName": "self", "type": "TestBertPreTokenizer"}]